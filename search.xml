<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>GNN-读书笔记</title>
      <link href="/2021/03/06/gnn-du-shu-bi-ji/"/>
      <url>/2021/03/06/gnn-du-shu-bi-ji/</url>
      
        <content type="html"><![CDATA[<h1 id="《Graph-Neural-Networks-A-Review-of-Methods-and-Applications》–-读书笔记"><a href="#《Graph-Neural-Networks-A-Review-of-Methods-and-Applications》–-读书笔记" class="headerlink" title="《Graph Neural Networks A Review of Methods and Applications》– 读书笔记"></a>《Graph Neural Networks A Review of Methods and Applications》– 读书笔记</h1><p><img src="GNN1.jpg" alt="1"></p><p><img src="GNN2.jpg" alt="2"></p><p><img src="GNN3.jpg" alt="3"></p><p><img src="GNN4.jpg" alt="4"></p><p><img src="GNN5.jpg" alt="5"></p><p><img src="GNN6.jpg" alt="6"></p><p><img src="GNN7.jpg" alt="7"></p><p><img src="GNN8.jpg" alt="8"></p><p><img src="GNN9.jpg" alt="9"></p><p><img src="GNN10.jpg" alt="10"></p><p><img src="GNN1.jpg" alt="11"></p><p><img src="GNN12.jpg" alt="12"></p><p><img src="GNN13.jpg" alt="13"></p><p><img src="GNN14.jpg" alt="14"></p><p><img src="GNN15.jpg" alt="15"></p><p><img src="GNN16.jpg" alt="16"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 图嵌入 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>概率图模型</title>
      <link href="/2021/03/06/gai-lu-tu-mo-xing/"/>
      <url>/2021/03/06/gai-lu-tu-mo-xing/</url>
      
        <content type="html"><![CDATA[<h3 id="概率图模型"><a href="#概率图模型" class="headerlink" title="概率图模型"></a>概率图模型</h3><p>​        概率图模型是用图来表示变量概率依赖关系的理论，结合概率论与图论的知识，利用图来表示与模型有关的变量的联合概率分布。由图灵奖获得者Pearl开发出来。概率图模型(Probabilistic Graphical Model)构建了这样一幅图，用观测结点表示观测到的数据，用隐含结点表示潜在的知识，用边来描述知识与数据的相互关系，<strong>最后基于这样的关系图获得一个概率分布</strong>，非常“优雅”地解决了问题。</p><p>​        概率图中的节点分为隐含节点和观测节点，边分为有向边和无向边。从概率论的角度，节点对应于随机变量，边对应于随机变量的依赖或相关关系，其中<strong>有向边表示单向的依赖，无向边表示相互依赖关系</strong>。</p><p>​        概率图模型分为<strong>贝叶斯网络（Bayesian Network）和马尔可夫网络（Markov Network）</strong>两大类。贝叶斯网络可以用一个有向图结构表示，马尔可夫网络可以表 示成一个无向图的网络结构。更详细地说，概率图模型包括了朴素贝叶斯模型、最大熵模型、隐马尔可夫模型、条件随机场、主题模型等，在机器学习的诸多场景中都有着广泛的应用。</p><h4 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h4><p>​        <strong>条件概率</strong>（又称后验概率）就是事件A在另外一个事件B已经发生条件下的发生概率。条件概率表示为P(A|B)，读作“在B条件下A的概率”。</p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9nc3MzLmJkc3RhdGljLmNvbS83UG8zZFNhZ194STRraEdrcG9XSzFIRjZoaHkvYmFpa2UvYzAlM0RiYWlrZTgwJTJDNSUyQzUlMkM4MCUyQzI2L3NpZ249MjhjY2QwNzg3ZTMxMGE1NWQwMjlkNmE2ZDYyYzI4Y2MvNTI0M2ZiZjJiMjExOTMxMzZmODRiNTNiNjIzODBjZDc5MDIzOGQ3Mi5qcGc" alt="img" style="zoom: 50%;"><p>​        比如上图，在同一个样本空间Ω中的事件或者子集A与B，如果随机从Ω中选出的一个元素属于B，那么这个随机选择的元素还属于A的概率就定义为在B的前提下A的条件概率：</p><p><img src="gln1.png"></p><p><strong>联合概率</strong>：联合概率指的是包含多个条件且<strong>所有条件同时成立</strong>的概率，记作P(X=a,Y=b)或P(a,b)</p><p><strong>边缘概率</strong>(先验概率)：边缘概率是与联合概率对应的，P(X=a)或P(Y=b)，这类仅与单个随机变量有关的概率称为边缘概率</p><p><strong>条件概率</strong>：条件概率表示在条件Y=b成立的情况下，X=a的概率，记作P(X=a|Y=b)或P(a|b)</p><p>联合概率与边缘概率的关系：<img src="gln2.png"></p><p>联合概率、边缘概率、条件概率之间的关系：<img src="gln3.png"></p><h4 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h4><ul><li>先验概率：知道原因推结果的，P(原因)、P(结果|原因)等</li><li>后验概率：根据结果推原因的，P(原因|结果)等</li></ul><p>​         贝叶斯公式解决的是<strong>一些原因X无法直接观测、测量，而我们希望通过其结果Y来反推出原因X的问题</strong>，也就是知道一部分先验概率，来求后验概率的问题。</p><p>先来推导一下贝叶斯公式：</p><p><img src="gln4.png"></p><p>举个列子理解一下：</p><p><strong>问</strong>：打到怪物就能获得宝箱，但是宝箱有2/3的概率是陷阱，玩家可以通过魔法来检查，但是有1/4的误判概率，问：假设玩家利用魔法判定此宝箱没有陷阱，求宝箱有陷阱的概率？</p><p>已知先验概率：</p><p>​        P(有陷阱)=2/3；P(没有发现|有陷阱)=1/4；P（发现了|没有陷阱)=1/4</p><p>要求的后验概率为：</p><p>​        P(有陷阱|没有发现)</p><img src="https://img-blog.csdn.net/20180410203614292?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RpY2tfdG9jazk3/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom: 25%;"><p>可以推出：</p><p>​        </p><p><img src="gln5.png"></p><p>所以：</p><p><img src="gln6.png"></p><h4 id="贝叶斯网络"><a href="#贝叶斯网络" class="headerlink" title="贝叶斯网络"></a>贝叶斯网络</h4><p>​          贝叶斯网络(Bayesian network)，又称信念网络(Belief Network)，或有向无环图模型(directed acyclic graphical model)，是一种概率图模型，它是一种模拟人类推理过程中因果关系的不确定性处理模型，其网络拓朴结构是一个有向无环图(DAG)。</p><p>​                                          <img src="https://imgconvert.csdnimg.cn/aHR0cDovL3d4MS5zaW5haW1nLmNuL213NjkwLzAwNjMwRGVmZ3kxZzR3c3gzemYwNWozMDZvMDZ4Z2xtLmpwZw" alt="img" style="zoom: 80%;"><img src="gln7.png">      </p><p>​        图中的节点表示随机变量<img src="C:\Users\43790\AppData\Roaming\Typora\typora-user-images\image-20210307220120014.png" alt="image-20210307220120014">，它们可以是可观察到的变量或隐变量、未知参数等。认为有因果关系（或非条件独立）的变量或命题则用箭头来连接。若两个节点间以一个单箭头连接在一起，表示其中一个节点是“因(parents)”，另一个是“果(children)”，两节点就会产生一个条件概率值。</p><p>​        简言之，把某个研究系统中涉及的随机变量，根据是否条件独立绘制在一个有向图中，就形成了贝叶斯网络。此外，对于任意的随机变量，其联合概率可由各自的局部条件概率分布相乘而得出：</p><p><img src="gln8.png">)</p><h4 id="贝叶斯网络的基本结构形式"><a href="#贝叶斯网络的基本结构形式" class="headerlink" title="贝叶斯网络的基本结构形式"></a>贝叶斯网络的基本结构形式</h4><p><strong>1. head-to-head</strong><img src="gln9.png" alt="3"></p><p>​        由上图可知：P(a,b,c)=P(a)P(b)P(c|a,b)成立。a，b为独立的。</p><p><strong>2. tail-to-tail</strong><img src="gln10.png"></p><p>​        c未知的情况下：P(a,b,c)=P(c)P(a|c)P(b|c)，此时没法得出P(a,b) = P(a)P(b),所以a，b不独立</p><p>​        c已知的情况下：P(a,b|c)=P(a,b,c)/P(c)，a，b独立。</p><p><strong>3. head-to-tail</strong><img src="gln11.png"></p><p>​        c未知的情况：P(a,b,c)=P(a)P(c|a)P(b|c)，但不能推出P(a,b) = P(a)P(b)，a，b不独立。</p><p>​        c已知的情况：a，b独立。                </p><p>​        即在xi给定的条件下，xi+1的分布和x1,x2…xi-1条件独立，意味着xi+1的分布状态只和xi有关，和其他变量条件独立。通俗点说，当前状态只跟上一状态有关，跟上上或上上之前的状态无关。这种顺次演变的随机过程，就叫做<strong>马尔科夫链</strong>（Markov chain）。</p><h4 id="因子图"><a href="#因子图" class="headerlink" title="因子图"></a>因子图</h4><p>​        维基百科的定义：将一个具有多变量的全局函数因子分解，得到几个局部函数的乘积，以此为基础得到的一个双向图叫做因子图（Factor Graph）。<br>​        通俗来讲，所谓因子图就是对函数进行因子分解得到的<strong>一种概率图</strong>。一般内含两种节点：变量节点和函数节点。我们知道，一个全局函数通过因式分解能够分解为多个局部函数的乘积，这些局部函数和对应的变量关系就体现在因子图上。</p><p>​        举个例子，现在有一个全局函数，其因式分解方程为：</p><p><img src="gln12.png"> ==》<img src="gln13.png"></p><p>​        其中fA,fB,fC,fD,fE为各函数，表示变量之间的关系，可以是条件概率也可以是其他关系。其对应的因子图为：</p><p>​                                                      <img src="gln14.png"></p><p>​                                    <img src="gln15.png">   </p><p>​        在概率图中，求某个变量的边缘分布是常见的问题。这问题有很多求解方法，其中之一就是把贝叶斯网络或马尔科夫随机场转换成因子图，然后用sum-product等算法求解。</p><p><strong>loopy Belief Propagation</strong>（置信度传播）</p><p><strong>Three Different Algorithm for LBP</strong></p><ul><li>sum-product</li><li>max-product</li><li>min-sum</li></ul><p><strong>sum-product原理：</strong></p><p>​        对于由贝叶斯网络或马尔可夫随机场转化而来的因子图如下左图，其全局函数如下右图。</p><p><img src="https://img-blog.csdn.net/20141111093045895" alt="img"><img src="https://img-blog.csdn.net/20141111093054537" alt="img"></p><p>​        此时，如何利用其联合概率分布求其边缘概率分布？事实上，某个随机变量 <strong>fk</strong> 的边缘概率可由x1,x2,x3, …, xn的联合概率求到，具体公式为：</p><p><img src="https://img-blog.csdn.net/20141111235305570" alt="img"></p><p>​        如果有<img src="https://img-blog.csdn.net/20141111235735656" alt="img" style="zoom:80%;">，那么</p><img src="https://img-blog.csdn.net/20141111235745640" alt="img" style="zoom:80%;"><p><strong>举个实例体验一下：</strong> 假如我们需要计算如下式子的结果</p><p>​                                        <img src="https://img-blog.csdn.net/20141112000434217" alt="img"></p><p>同时全局函数分解后的因子图为：</p><img src="https://img-blog.csdn.net/20141112000519707" alt="img" style="zoom:80%;"><p>我们对其全局的每个子任务进行剖析如下：</p><p><img src="https://img-blog.csdn.net/20141112000839984" alt="img"></p><p>因为变量的边缘概率等于所有与他相连的函数传递过来的消息的积，所以计算得到：</p><img src="https://img-blog.csdn.net/20141112000843006" alt="img" style="zoom:80%;"><p>仔细观察上述计算过程，可以发现，其中用到了类似“<strong>消息传递</strong>”的观点，且总共两个步骤。</p><ul><li>第一步、对于f 的分解图，根据蓝色虚线框、红色虚线框围住的两个box外面的消息传递</li><li>第二步、根据蓝色虚线框、红色虚线框围住的两个box内部的消息传递：</li></ul><p><img src="https://img-blog.csdn.net/20141112001129256" alt="img"></p><p>​        根据<img src="https://img-blog.csdn.net/20141112001819443" alt="img">，我们有</p><p><img src="https://img-blog.csdn.net/20141112001830316" alt="img"></p><p>​        即</p><p><img src="https://img-blog.csdn.net/20141112001150643" alt="img"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GMN-complement-tensorflow</title>
      <link href="/2021/01/16/gmn-code/"/>
      <url>/2021/01/16/gmn-code/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python">注：该代码为DeepMind公布的基于Tensorflow实现的GMN模型，理论与实现相配合，若需基于pytorch框架的GMN模型实现代码，请关注我的GitHub。Refference：DeepMind</code></pre><h1 id="Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects"><a href="#Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects" class="headerlink" title="Graph Matching Networks for Learning the Similarity of Graph Structured Objects"></a>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</h1><p>This is the example code for our ICML 2019 paper.  Please refer to the paper for more details:</p><blockquote><p>Yujia Li, Chenjie Gu, Thomas Dullien, Oriol Vinyals, Pushmeet Kohli.  <em>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</em>.  ICML 2019.  <a href="https://arxiv.org/abs/1904.12787">[arXiv]</a></p></blockquote><h2 id="Graph-similarity-learning"><a href="#Graph-similarity-learning" class="headerlink" title="Graph similarity learning"></a>Graph similarity learning</h2><p>Our goal is to learn a similarity function between graphs.  Given two graphs $G_1, G_2$, a graph similarity model can be written as a function $f(G_1, G_2)$ that computes a scalar similarity value.</p><p>In this project we build models to learn such a similarity function based on examples of similar / dissimilar pairs or triplets.  Because of learning, our model can adapt to different notions of similarity and to different types of graph structure, as long as training data is available.</p><p>In the following we will sometimes use the term “distance” and say the model learns a “distance function” $d(G_1, G_2)$ between graphs when convenient.  But this is just the opposite of a similarity function, and you may simply say $f(G_1, G_2) = - d(G_1, G_2)$.</p><h2 id="Some-dependencies-and-imports"><a href="#Some-dependencies-and-imports" class="headerlink" title="Some dependencies and imports"></a>Some dependencies and imports</h2><p>If you want to run the notebook locally, make sure you have all the dependencies first.  You can use the following command</p><pre><code>pip3 install --user -r requirements.txt</code></pre><p>Note the code should work for both python 3 and 2, but python 3 is recommended.</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Let's disable all the warnings first</span><span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>simplefilter<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span></code></pre><p>These are all the dependencies that will be used in this notebook.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> abc<span class="token keyword">import</span> collections<span class="token keyword">import</span> contextlib<span class="token keyword">import</span> copy<span class="token keyword">import</span> random<span class="token keyword">import</span> time<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> six<span class="token keyword">import</span> sonnet <span class="token keyword">as</span> snt<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf</code></pre><h2 id="The-models"><a href="#The-models" class="headerlink" title="The models"></a>The models</h2><h3 id="The-graph-embedding-model"><a href="#The-graph-embedding-model" class="headerlink" title="The graph embedding model"></a>The graph embedding model</h3><p>The simpler variant of our model is based on embedding each graph <strong>independently</strong> into a vector and then use an existing distance (or similarity) metric in the vector space to compute the distance between graphs.  More concretely, we define</p><p>$$d(G_1, G_2) = d_H(embed(G_1), embed(G_2)),$$</p><p>where $embed$ is a model that maps any graph $G$ into an $H$-dimensional vector, and $d_H$ is a distance metric in that vector space.  Typical examples are Euclidean distance in $\mathbb{R}^H$, i.e. $d_H(x, y) = \sqrt{\sum_{i=1}^H (x_i - y_i)^2}$, or Hamming distance in $H$-dimensional space of binary vectors, i.e. $d_H(x, y)=\sum_{i=1}^H \mathbb{I}[x_i \ne y_i]$.</p><p>Each graph input contains a set of nodes $V$ and edges $E$.  Each node $i\in V$ may have a feature vector $x_i$ associated with it, and each edge $(i, j)\in E$ may also have a feature vector $x_{ij}$ encoding e.g. edge type or attributes.  The embedding model will therefore jointly reason about the graph structure as well as the graph features to come up with an embedding that reflects the notion of similarity described by the training examples.</p><p>The embedding model is composed of 3 parts:</p><ol><li><p>An encoder that maps $x_i$ and $x_{ij}$ into a nice hidden representation space.  Here we use separate MLPs (fully connected neural nets) for node and edge representations:<br>$$\begin{array}{rcl}<br>h_i^{(0)} &amp;=&amp; \mathrm{MLP_{node}}(x_i) \<br>e_{ij} &amp;=&amp; \mathrm{MLP_{edge}}(x_{ij})<br>\end{array}<br>$$</p></li><li><p>A graph neural network (GNN) that communicates information across the graph and computes node representations that encode local neighborhood structure and semantics.  More concretely, the GNN computes node representations through an iterative message passing process.  In the $t$-th round of message passing, we compute a message vector on each edge, and then each node aggregates all the incoming messages and updates its own representation:<br>$$\begin{array}{rcl}<br>m_{i\rightarrow j} &amp;=&amp; f_\mathrm{message}(h_i^{(t)}, h_j^{(t)}, e_{ij}) \<br>h_i^{(t+1)} &amp;=&amp; f_\mathrm{node}(h_i^{(t)}, \sum_{j:(j,i)\in E} m_{j\rightarrow i})<br>\end{array}<br>$$<br>Here both $f_\mathrm{message}$ and $f_\mathrm{node}$ are neural modules.  We use MLPs for $f_\mathrm{message}$, while $f_\mathrm{node}$ can also be MLPs or even recurrent neural network cores like LSTMs or GRUs.  The GNNs have the nice property of being equivariant to node permutations, and nodes on isomorphic graphs (with the same node and edge features) will have the same representations regardless of the ordering.</p></li><li><p>After we obtained the final node representations after $T$ rounds of message passing, we aggregate across them to get graph representations $h_G=f_G({h_i^{(T)}}<em>{i\in V})$.  This could be implemented by a simple sum that reduces the node representations into a single vector and then transform it:<br>$$h_G = \mathrm{MLP_G}\left(\sum</em>{i\in V} h_i^{(T)}\right).$$<br>We used the following gated aggregation module proposed in <a href="https://arxiv.org/abs/1511.05493">Li et al., 2015</a> which we found to work consistently better:<br>$$h_G = \mathrm{MLP_G}\left(\sum_{i\in V} \sigma(\mathrm{MLP_{gate}}(h_i^{(T)})) \odot \mathrm{MLP}(h_i^{(T)})\right).$$<br>The key to this function is to make sure it is invariant to node orderings, both the above forms satisfy this condition.  The gated variant gives the model the capacity to explicitly modulate each node’s contribution to the graph representation.</p></li></ol><h4 id="The-graph-encoder"><a href="#The-graph-encoder" class="headerlink" title="The graph encoder"></a>The graph encoder</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphEncoder</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Encoder module that projects node and edge features to some embeddings."""</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               node_hidden_sizes<span class="token operator">=</span>None<span class="token punctuation">,</span>               edge_hidden_sizes<span class="token operator">=</span>None<span class="token punctuation">,</span>               name<span class="token operator">=</span><span class="token string">'graph-encoder'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Constructor.    Args:      node_hidden_sizes: if provided should be a list of ints, hidden sizes of        node encoder network, the last element is the size of the node outputs.        If not provided, node features will pass through as is.      edge_hidden_sizes: if provided should be a list of ints, hidden sizes of        edge encoder network, the last element is the size of the edge outptus.        If not provided, edge features will pass through as is.      name: name of this module.    """</span>    super<span class="token punctuation">(</span>GraphEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># this also handles the case of an empty list</span>    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes <span class="token keyword">if</span> node_hidden_sizes <span class="token keyword">else</span> None    self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token operator">=</span> edge_hidden_sizes  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Encode node and edge features.    Args:      node_features: [n_nodes, node_feat_dim] float tensor.      edge_features: if provided, should be [n_edges, edge_feat_dim] float        tensor.    Returns:      node_outputs: [n_nodes, node_embedding_dim] float tensor, node embeddings.      edge_outputs: if edge_features is not None and edge_hidden_sizes is not        None, this is [n_edges, edge_embedding_dim] float tensor, edge        embeddings; otherwise just the input edge_features.    """</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token keyword">is</span> None<span class="token punctuation">:</span>      node_outputs <span class="token operator">=</span> node_features    <span class="token keyword">else</span><span class="token punctuation">:</span>      node_outputs <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>          self<span class="token punctuation">.</span>_node_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'node-feature-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>node_features<span class="token punctuation">)</span>    <span class="token keyword">if</span> edge_features <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token keyword">is</span> None<span class="token punctuation">:</span>      edge_outputs <span class="token operator">=</span> edge_features    <span class="token keyword">else</span><span class="token punctuation">:</span>      edge_outputs <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>          self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'edge-feature-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>edge_features<span class="token punctuation">)</span>    <span class="token keyword">return</span> node_outputs<span class="token punctuation">,</span> edge_outputs</code></pre><h4 id="The-message-passing-layers"><a href="#The-message-passing-layers" class="headerlink" title="The message passing layers"></a>The message passing layers</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">graph_prop_once</span><span class="token punctuation">(</span>node_states<span class="token punctuation">,</span>                    from_idx<span class="token punctuation">,</span>                    to_idx<span class="token punctuation">,</span>                    message_net<span class="token punctuation">,</span>                    aggregation_module<span class="token operator">=</span>tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>                    edge_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""One round of propagation (message passing) in a graph.  Args:    node_states: [n_nodes, node_state_dim] float tensor, node state vectors, one      row for each node.    from_idx: [n_edges] int tensor, index of the from nodes.    to_idx: [n_edges] int tensor, index of the to nodes.    message_net: a network that maps concatenated edge inputs to message      vectors.    aggregation_module: a module that aggregates messages on edges to aggregated      messages for each node.  Should be a callable and can be called like the      following,      `aggregated_messages = aggregation_module(messages, to_idx, n_nodes)`,      where messages is [n_edges, edge_message_dim] tensor, to_idx is the index      of the to nodes, i.e. where each message should go to, and n_nodes is an      int which is the number of nodes to aggregate into.    edge_features: if provided, should be a [n_edges, edge_feature_dim] float      tensor, extra features for each edge.  Returns:    aggregated_messages: an [n_nodes, edge_message_dim] float tensor, the      aggregated messages, one row for each node.  """</span>  from_states <span class="token operator">=</span> tf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">)</span>  to_states <span class="token operator">=</span> tf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> to_idx<span class="token punctuation">)</span>  edge_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>from_states<span class="token punctuation">,</span> to_states<span class="token punctuation">]</span>  <span class="token keyword">if</span> edge_features <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>    edge_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>edge_features<span class="token punctuation">)</span>  edge_inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>edge_inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  messages <span class="token operator">=</span> message_net<span class="token punctuation">(</span>edge_inputs<span class="token punctuation">)</span>  <span class="token keyword">return</span> aggregation_module<span class="token punctuation">(</span>messages<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>node_states<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">GraphPropLayer</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Implementation of a graph propagation (message passing) layer."""</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               node_state_dim<span class="token punctuation">,</span>               edge_hidden_sizes<span class="token punctuation">,</span>               node_hidden_sizes<span class="token punctuation">,</span>               edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>               node_update_type<span class="token operator">=</span><span class="token string">'residual'</span><span class="token punctuation">,</span>               use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>               name<span class="token operator">=</span><span class="token string">'graph-net'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Constructor.    Args:      node_state_dim: int, dimensionality of node states.      edge_hidden_sizes: list of ints, hidden sizes for the edge message        net, the last element in the list is the size of the message vectors.      node_hidden_sizes: list of ints, hidden sizes for the node update        net.      edge_net_init_scale: initialization scale for the edge networks.  This        is typically set to a small value such that the gradient does not blow        up.      node_update_type: type of node updates, one of &amp;#123;mlp, gru, residual&amp;#125;.      use_reverse_direction: set to True to also propagate messages in the        reverse direction.      reverse_dir_param_different: set to True to have the messages computed        using a different set of parameters than for the forward direction.      layer_norm: set to True to use layer normalization in a few places.      name: name of this module.    """</span>    super<span class="token punctuation">(</span>GraphPropLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>_node_state_dim <span class="token operator">=</span> node_state_dim    self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token operator">=</span> edge_hidden_sizes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># output size is node_state_dim</span>    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>node_state_dim<span class="token punctuation">]</span>    self<span class="token punctuation">.</span>_edge_net_init_scale <span class="token operator">=</span> edge_net_init_scale    self<span class="token punctuation">.</span>_node_update_type <span class="token operator">=</span> node_update_type    self<span class="token punctuation">.</span>_use_reverse_direction <span class="token operator">=</span> use_reverse_direction    self<span class="token punctuation">.</span>_reverse_dir_param_different <span class="token operator">=</span> reverse_dir_param_different    self<span class="token punctuation">.</span>_layer_norm <span class="token operator">=</span> layer_norm  <span class="token keyword">def</span> <span class="token function">_compute_aggregated_messages</span><span class="token punctuation">(</span>      self<span class="token punctuation">,</span> node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Compute aggregated messages for each node.    Args:      node_states: [n_nodes, input_node_state_dim] float tensor, node states.      from_idx: [n_edges] int tensor, from node indices for each edge.      to_idx: [n_edges] int tensor, to node indices for each edge.      edge_features: if not None, should be [n_edges, edge_embedding_dim]        tensor, edge features.    Returns:      aggregated_messages: [n_nodes, aggregated_message_dim] float tensor, the        aggregated messages for each node.    """</span>    self<span class="token punctuation">.</span>_message_net <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>        self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span>        initializers<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>            <span class="token string">'w'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>variance_scaling_initializer<span class="token punctuation">(</span>                scale<span class="token operator">=</span>self<span class="token punctuation">.</span>_edge_net_init_scale<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token string">'b'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>zeros_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>        name<span class="token operator">=</span><span class="token string">'message-mlp'</span><span class="token punctuation">)</span>    aggregated_messages <span class="token operator">=</span> graph_prop_once<span class="token punctuation">(</span>        node_states<span class="token punctuation">,</span>        from_idx<span class="token punctuation">,</span>        to_idx<span class="token punctuation">,</span>        self<span class="token punctuation">.</span>_message_net<span class="token punctuation">,</span>        aggregation_module<span class="token operator">=</span>tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>        edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># optionally compute message vectors in the reverse direction</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_use_reverse_direction<span class="token punctuation">:</span>      <span class="token keyword">if</span> self<span class="token punctuation">.</span>_reverse_dir_param_different<span class="token punctuation">:</span>        self<span class="token punctuation">.</span>_reverse_message_net <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span>            initializers<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>                <span class="token string">'w'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>variance_scaling_initializer<span class="token punctuation">(</span>                    scale<span class="token operator">=</span>self<span class="token punctuation">.</span>_edge_net_init_scale<span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token string">'b'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>zeros_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>            name<span class="token operator">=</span><span class="token string">'reverse-message-mlp'</span><span class="token punctuation">)</span>      <span class="token keyword">else</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>_reverse_message_net <span class="token operator">=</span> self<span class="token punctuation">.</span>_message_net      reverse_aggregated_messages <span class="token operator">=</span> graph_prop_once<span class="token punctuation">(</span>          node_states<span class="token punctuation">,</span>          to_idx<span class="token punctuation">,</span>          from_idx<span class="token punctuation">,</span>          self<span class="token punctuation">.</span>_reverse_message_net<span class="token punctuation">,</span>          aggregation_module<span class="token operator">=</span>tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>          edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>      aggregated_messages <span class="token operator">+=</span> reverse_aggregated_messages    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_layer_norm<span class="token punctuation">:</span>      aggregated_messages <span class="token operator">=</span> snt<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>aggregated_messages<span class="token punctuation">)</span>    <span class="token keyword">return</span> aggregated_messages  <span class="token keyword">def</span> <span class="token function">_compute_node_update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                           node_states<span class="token punctuation">,</span>                           node_state_inputs<span class="token punctuation">,</span>                           node_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Compute node updates.    Args:      node_states: [n_nodes, node_state_dim] float tensor, the input node        states.      node_state_inputs: a list of tensors used to compute node updates.  Each        element tensor should have shape [n_nodes, feat_dim], where feat_dim can        be different.  These tensors will be concatenated along the feature        dimension.      node_features: extra node features if provided, should be of size        [n_nodes, extra_node_feat_dim] float tensor, can be used to implement        different types of skip connections.    Returns:      new_node_states: [n_nodes, node_state_dim] float tensor, the new node        state tensor.    Raises:      ValueError: if node update type is not supported.    """</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_update_type <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'mlp'</span><span class="token punctuation">,</span> <span class="token string">'residual'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      node_state_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_states<span class="token punctuation">)</span>    <span class="token keyword">if</span> node_features <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>      node_state_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_features<span class="token punctuation">)</span>    <span class="token keyword">if</span> len<span class="token punctuation">(</span>node_state_inputs<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>      node_state_inputs <span class="token operator">=</span> node_state_inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>      node_state_inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>node_state_inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_update_type <span class="token operator">==</span> <span class="token string">'gru'</span><span class="token punctuation">:</span>      _<span class="token punctuation">,</span> new_node_states <span class="token operator">=</span> snt<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_node_state_dim<span class="token punctuation">)</span><span class="token punctuation">(</span>          node_state_inputs<span class="token punctuation">,</span> node_states<span class="token punctuation">)</span>      <span class="token keyword">return</span> new_node_states    <span class="token keyword">else</span><span class="token punctuation">:</span>      mlp_output <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>          self<span class="token punctuation">.</span>_node_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'node-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>node_state_inputs<span class="token punctuation">)</span>      <span class="token keyword">if</span> self<span class="token punctuation">.</span>_layer_norm<span class="token punctuation">:</span>        mlp_output <span class="token operator">=</span> snt<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>mlp_output<span class="token punctuation">)</span>      <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_update_type <span class="token operator">==</span> <span class="token string">'mlp'</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> mlp_output      <span class="token keyword">elif</span> self<span class="token punctuation">.</span>_node_update_type <span class="token operator">==</span> <span class="token string">'residual'</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> node_states <span class="token operator">+</span> mlp_output      <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown node update type %s'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>_node_update_type<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>             node_states<span class="token punctuation">,</span>             from_idx<span class="token punctuation">,</span>             to_idx<span class="token punctuation">,</span>             edge_features<span class="token operator">=</span>None<span class="token punctuation">,</span>             node_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Run one propagation step.    Args:      node_states: [n_nodes, input_node_state_dim] float tensor, node states.      from_idx: [n_edges] int tensor, from node indices for each edge.      to_idx: [n_edges] int tensor, to node indices for each edge.      edge_features: if not None, should be [n_edges, edge_embedding_dim]        tensor, edge features.      node_features: extra node features if provided, should be of size        [n_nodes, extra_node_feat_dim] float tensor, can be used to implement        different types of skip connections.    Returns:      node_states: [n_nodes, node_state_dim] float tensor, new node states.    """</span>    aggregated_messages <span class="token operator">=</span> self<span class="token punctuation">.</span>_compute_aggregated_messages<span class="token punctuation">(</span>        node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_compute_node_update<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span>                                     <span class="token punctuation">[</span>aggregated_messages<span class="token punctuation">]</span><span class="token punctuation">,</span>                                     node_features<span class="token operator">=</span>node_features<span class="token punctuation">)</span></code></pre><h4 id="Graph-aggregator"><a href="#Graph-aggregator" class="headerlink" title="Graph aggregator"></a>Graph aggregator</h4><pre class=" language-python"><code class="language-python">AGGREGATION_TYPE <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">'sum'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>    <span class="token string">'mean'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_mean<span class="token punctuation">,</span>    <span class="token string">'sqrt_n'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_sqrt_n<span class="token punctuation">,</span>    <span class="token string">'max'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_max<span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token keyword">class</span> <span class="token class-name">GraphAggregator</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""This module computes graph representations by aggregating from parts."""</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               node_hidden_sizes<span class="token punctuation">,</span>               graph_transform_sizes<span class="token operator">=</span>None<span class="token punctuation">,</span>               gated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               aggregation_type<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">,</span>               name<span class="token operator">=</span><span class="token string">'graph-aggregator'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Constructor.    Args:      node_hidden_sizes: the hidden layer sizes of the node transformation nets.        The last element is the size of the aggregated graph representation.      graph_transform_sizes: sizes of the transformation layers on top of the        graph representations.  The last element of this list is the final        dimensionality of the output graph representations.      gated: set to True to do gated aggregation, False not to.      aggregation_type: one of &amp;#123;sum, max, mean, sqrt_n&amp;#125;.      name: name of this module.    """</span>    super<span class="token punctuation">(</span>GraphAggregator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes    self<span class="token punctuation">.</span>_graph_transform_sizes <span class="token operator">=</span> graph_transform_sizes    self<span class="token punctuation">.</span>_graph_state_dim <span class="token operator">=</span> node_hidden_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    self<span class="token punctuation">.</span>_gated <span class="token operator">=</span> gated    self<span class="token punctuation">.</span>_aggregation_type <span class="token operator">=</span> aggregation_type    self<span class="token punctuation">.</span>_aggregation_op <span class="token operator">=</span> AGGREGATION_TYPE<span class="token punctuation">[</span>aggregation_type<span class="token punctuation">]</span>  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_states<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Compute aggregated graph representations.    Args:      node_states: [n_nodes, node_state_dim] float tensor, node states of a        batch of graphs concatenated together along the first dimension.      graph_idx: [n_nodes] int tensor, graph ID for each node.      n_graphs: integer, number of graphs in this batch.    Returns:      graph_states: [n_graphs, graph_state_dim] float tensor, graph        representations, one row for each graph.    """</span>    node_hidden_sizes <span class="token operator">=</span> self<span class="token punctuation">.</span>_node_hidden_sizes    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_gated<span class="token punctuation">:</span>      node_hidden_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_graph_state_dim <span class="token operator">*</span> <span class="token number">2</span>    node_states_g <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>        node_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'node-state-g-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>node_states<span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_gated<span class="token punctuation">:</span>      gates <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>node_states_g<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>self<span class="token punctuation">.</span>_graph_state_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>      node_states_g <span class="token operator">=</span> node_states_g<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_graph_state_dim<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> gates    graph_states <span class="token operator">=</span> self<span class="token punctuation">.</span>_aggregation_op<span class="token punctuation">(</span>node_states_g<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># unsorted_segment_max does not handle empty graphs in the way we want</span>    <span class="token comment" spellcheck="true"># it assigns the lowest possible float to empty segments, we want to reset</span>    <span class="token comment" spellcheck="true"># them to zero.</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_aggregation_type <span class="token operator">==</span> <span class="token string">'max'</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># reset everything that's smaller than -1e5 to 0.</span>      graph_states <span class="token operator">*=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>graph_states <span class="token operator">></span> <span class="token operator">-</span><span class="token number">1e5</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># transform the reduced graph states further</span>    <span class="token comment" spellcheck="true"># pylint: disable=g-explicit-length-test</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_graph_transform_sizes <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span>        len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_graph_transform_sizes<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      graph_states <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>          self<span class="token punctuation">.</span>_graph_transform_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'graph-transform-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>graph_states<span class="token punctuation">)</span>    <span class="token keyword">return</span> graph_states</code></pre><h4 id="Putting-them-together"><a href="#Putting-them-together" class="headerlink" title="Putting them together"></a>Putting them together</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphEmbeddingNet</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""A graph to embedding mapping network."""</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               encoder<span class="token punctuation">,</span>               aggregator<span class="token punctuation">,</span>               node_state_dim<span class="token punctuation">,</span>               edge_hidden_sizes<span class="token punctuation">,</span>               node_hidden_sizes<span class="token punctuation">,</span>               n_prop_layers<span class="token punctuation">,</span>               share_prop_params<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>               edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>               node_update_type<span class="token operator">=</span><span class="token string">'residual'</span><span class="token punctuation">,</span>               use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>               name<span class="token operator">=</span><span class="token string">'graph-embedding-net'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Constructor.    Args:      encoder: GraphEncoder, encoder that maps features to embeddings.      aggregator: GraphAggregator, aggregator that produces graph        representations.      node_state_dim: dimensionality of node states.      edge_hidden_sizes: sizes of the hidden layers of the edge message nets.      node_hidden_sizes: sizes of the hidden layers of the node update nets.      n_prop_layers: number of graph propagation layers.      share_prop_params: set to True to share propagation parameters across all        graph propagation layers, False not to.      edge_net_init_scale: scale of initialization for the edge message nets.      node_update_type: type of node updates, one of &amp;#123;mlp, gru, residual&amp;#125;.      use_reverse_direction: set to True to also propagate messages in the        reverse direction.      reverse_dir_param_different: set to True to have the messages computed        using a different set of parameters than for the forward direction.      layer_norm: set to True to use layer normalization in a few places.      name: name of this module.    """</span>    super<span class="token punctuation">(</span>GraphEmbeddingNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>_encoder <span class="token operator">=</span> encoder    self<span class="token punctuation">.</span>_aggregator <span class="token operator">=</span> aggregator    self<span class="token punctuation">.</span>_node_state_dim <span class="token operator">=</span> node_state_dim    self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token operator">=</span> edge_hidden_sizes    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes    self<span class="token punctuation">.</span>_n_prop_layers <span class="token operator">=</span> n_prop_layers    self<span class="token punctuation">.</span>_share_prop_params <span class="token operator">=</span> share_prop_params    self<span class="token punctuation">.</span>_edge_net_init_scale <span class="token operator">=</span> edge_net_init_scale    self<span class="token punctuation">.</span>_node_update_type <span class="token operator">=</span> node_update_type    self<span class="token punctuation">.</span>_use_reverse_direction <span class="token operator">=</span> use_reverse_direction    self<span class="token punctuation">.</span>_reverse_dir_param_different <span class="token operator">=</span> reverse_dir_param_different    self<span class="token punctuation">.</span>_layer_norm <span class="token operator">=</span> layer_norm    self<span class="token punctuation">.</span>_prop_layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    self<span class="token punctuation">.</span>_layer_class <span class="token operator">=</span> GraphPropLayer  <span class="token keyword">def</span> <span class="token function">_build_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> layer_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Build one layer in the network."""</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_layer_class<span class="token punctuation">(</span>        self<span class="token punctuation">.</span>_node_state_dim<span class="token punctuation">,</span>        self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span>        self<span class="token punctuation">.</span>_node_hidden_sizes<span class="token punctuation">,</span>        edge_net_init_scale<span class="token operator">=</span>self<span class="token punctuation">.</span>_edge_net_init_scale<span class="token punctuation">,</span>        node_update_type<span class="token operator">=</span>self<span class="token punctuation">.</span>_node_update_type<span class="token punctuation">,</span>        use_reverse_direction<span class="token operator">=</span>self<span class="token punctuation">.</span>_use_reverse_direction<span class="token punctuation">,</span>        reverse_dir_param_different<span class="token operator">=</span>self<span class="token punctuation">.</span>_reverse_dir_param_different<span class="token punctuation">,</span>        layer_norm<span class="token operator">=</span>self<span class="token punctuation">.</span>_layer_norm<span class="token punctuation">,</span>        name<span class="token operator">=</span><span class="token string">'graph-prop-%d'</span> <span class="token operator">%</span> layer_id<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">_apply_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                   layer<span class="token punctuation">,</span>                   node_states<span class="token punctuation">,</span>                   from_idx<span class="token punctuation">,</span>                   to_idx<span class="token punctuation">,</span>                   graph_idx<span class="token punctuation">,</span>                   n_graphs<span class="token punctuation">,</span>                   edge_features<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Apply one layer on the given inputs."""</span>    <span class="token keyword">del</span> graph_idx<span class="token punctuation">,</span> n_graphs    <span class="token keyword">return</span> layer<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>             node_features<span class="token punctuation">,</span>             edge_features<span class="token punctuation">,</span>             from_idx<span class="token punctuation">,</span>             to_idx<span class="token punctuation">,</span>             graph_idx<span class="token punctuation">,</span>             n_graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Compute graph representations.    Args:      node_features: [n_nodes, node_feat_dim] float tensor.      edge_features: [n_edges, edge_feat_dim] float tensor.      from_idx: [n_edges] int tensor, index of the from node for each edge.      to_idx: [n_edges] int tensor, index of the to node for each edge.      graph_idx: [n_nodes] int tensor, graph id for each node.      n_graphs: int, number of graphs in the batch.    Returns:      graph_representations: [n_graphs, graph_representation_dim] float tensor,        graph representations.    """</span>    <span class="token keyword">if</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_n_prop_layers<span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># build the layers</span>      <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n_prop_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>_share_prop_params<span class="token punctuation">:</span>          layer <span class="token operator">=</span> self<span class="token punctuation">.</span>_build_layer<span class="token punctuation">(</span>i<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>          layer <span class="token operator">=</span> self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>    node_features<span class="token punctuation">,</span> edge_features <span class="token operator">=</span> self<span class="token punctuation">.</span>_encoder<span class="token punctuation">(</span>node_features<span class="token punctuation">,</span> edge_features<span class="token punctuation">)</span>    node_states <span class="token operator">=</span> node_features    layer_outputs <span class="token operator">=</span> <span class="token punctuation">[</span>node_states<span class="token punctuation">]</span>    <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># node_features could be wired in here as well, leaving it out for now as</span>      <span class="token comment" spellcheck="true"># it is already in the inputs</span>      node_states <span class="token operator">=</span> self<span class="token punctuation">.</span>_apply_layer<span class="token punctuation">(</span>          layer<span class="token punctuation">,</span>          node_states<span class="token punctuation">,</span>          from_idx<span class="token punctuation">,</span>          to_idx<span class="token punctuation">,</span>          graph_idx<span class="token punctuation">,</span>          n_graphs<span class="token punctuation">,</span>          edge_features<span class="token punctuation">)</span>      layer_outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_states<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># these tensors may be used e.g. for visualization</span>    self<span class="token punctuation">.</span>_layer_outputs <span class="token operator">=</span> layer_outputs    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_aggregator<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">reset_n_prop_layers</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_prop_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Set n_prop_layers to the provided new value.    This allows us to train with certain number of propagation layers and    evaluate with a different number of propagation layers.    This only works if n_prop_layers is smaller than the number used for    training, or when share_prop_params is set to True, in which case this can    be arbitrarily large.    Args:      n_prop_layers: the new number of propagation layers to set.    """</span>    self<span class="token punctuation">.</span>_n_prop_layers <span class="token operator">=</span> n_prop_layers  @property  <span class="token keyword">def</span> <span class="token function">n_prop_layers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_n_prop_layers  <span class="token keyword">def</span> <span class="token function">get_layer_outputs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Get the outputs at each layer."""</span>    <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_layer_outputs'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">return</span> self<span class="token punctuation">.</span>_layer_outputs    <span class="token keyword">else</span><span class="token punctuation">:</span>      <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'No layer outputs available.'</span><span class="token punctuation">)</span></code></pre><h3 id="The-graph-matching-networks"><a href="#The-graph-matching-networks" class="headerlink" title="The graph matching networks"></a>The graph matching networks</h3><p>The graph matching networks (GMNs) compute the similarity score for a pair of graphs jointly on the pair.  In our current formulation, it still computes a representation for each graph, but the representations for a pair of graphs are computed jointly on the pair, through a cross-graph attention-based matching mechanism.</p><p>More concretely, the graph matching model can be formulated as</p><p>$$d(G_1, G_2) = d_H(embed_and_match(G_1, G_2))$$</p><p>where $embed_and_match(G_1, G_2)$ returns a pair of graph representations.</p><p>Similar to the embedding model, our GMNs computes graph representations through 3 steps.  The difference to the embedding model is in the message passing step, where each node not only gets messages from within the same graph, but also gets cross-graph messages by attending to all the nodes in the other graph.  This can be formulated as follows.</p><p>We first have within-graph messages as before:<br>$$<br>m_{i\rightarrow j} = f_\mathrm{message}(h_i^{(t)}, h_j^{(t)}, e_{ij}).<br>$$</p><p>In addition, we also allow each node in one graph to attend to all the other nodes in the other graph.  The cross graph attention weight (node $i$ in one graph attending to node $j$ in the other graph, and vice versa) is computed as<br>$$\begin{array}{rcl}<br>a_{i\rightarrow j} &amp;=&amp; \frac{\exp(s(h_i^{(t)}, h_j^{(t)}))}{\sum_j \exp(s(h_i^{(t)}, h_j^{(t)}))} \<br>a_{j\rightarrow i} &amp;=&amp; \frac{\exp(s(h_i^{(t)}, h_j^{(t)}))}{\sum_i \exp(s(h_i^{(t)}, h_j^{(t)}))},<br>\end{array}<br>$$<br>where $s(., .)$ is again a vector space similarity function, like Euclidean, dot-product or cosine.  Also note the different indices being summed over in the normalizers.</p><p>The cross-graph message is then computed as<br>$$\begin{array}{rcl}<br>\mu_i &amp;=&amp; \sum_j a_{i\rightarrow j} (h_i^{(t)} - h_j^{(t)}) = h_i^{(t)} - \sum_j a_{i\rightarrow j} h_j^{(t)}, \<br>\mu_j &amp;=&amp; \sum_i a_{j\rightarrow i} (h_j^{(t)} - h_i^{(t)}) = h_j^{(t)} - \sum_i a_{j\rightarrow i} h_i^{(t)}.<br>\end{array}<br>$$<br>Here we are computing an attention-weighted sum of all the node representations from the other graph, and then take the difference.  This is essentially <strong>matching</strong> one node in one graph to nodes most similar to it in the other graph, and then compute the difference.</p><p>The node updates are then computed as<br>$$<br>h_i^{(t+1)} = f_\mathrm{node}\left(h_i^{(t)}, \sum_{j:(j,i)\in E} m_{j\rightarrow i}, \mu_i\right).<br>$$</p><p>The graph encoder and the graph aggregators are the same as in the embedding model.</p><h4 id="A-few-similarity-functions"><a href="#A-few-similarity-functions" class="headerlink" title="A few similarity functions"></a>A few similarity functions</h4><p>These are the functions $s(., .)$ that will be used in the cross-graph attention.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pairwise_euclidean_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute the pairwise Euclidean similarity between x and y.  This function computes the following similarity value between each pair of x_i  and y_j: s(x_i, y_j) = -|x_i - y_j|^2.  Args:    x: NxD float tensor.    y: MxD float tensor.  Returns:    s: NxM float tensor, the pairwise euclidean similarity.  """</span>  s <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  diag_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>x <span class="token operator">*</span> x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  diag_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>y <span class="token operator">*</span> y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> s <span class="token operator">-</span> diag_x <span class="token operator">-</span> diag_y<span class="token keyword">def</span> <span class="token function">pairwise_dot_product_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute the dot product similarity between x and y.  This function computes the following similarity value between each pair of x_i  and y_j: s(x_i, y_j) = x_i^T y_j.  Args:    x: NxD float tensor.    y: MxD float tensor.  Returns:    s: NxM float tensor, the pairwise dot product similarity.  """</span>  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">pairwise_cosine_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute the cosine similarity between x and y.  This function computes the following similarity value between each pair of x_i  and y_j: s(x_i, y_j) = x_i^T y_j / (|x_i||y_j|).  Args:    x: NxD float tensor.    y: MxD float tensor.  Returns:    s: NxM float tensor, the pairwise cosine similarity.  """</span>  x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>PAIRWISE_SIMILARITY_FUNCTION <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">'euclidean'</span><span class="token punctuation">:</span> pairwise_euclidean_similarity<span class="token punctuation">,</span>    <span class="token string">'dotproduct'</span><span class="token punctuation">:</span> pairwise_dot_product_similarity<span class="token punctuation">,</span>    <span class="token string">'cosine'</span><span class="token punctuation">:</span> pairwise_cosine_similarity<span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token keyword">def</span> <span class="token function">get_pairwise_similarity</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Get pairwise similarity metric by name.  Args:    name: string, name of the similarity metric, one of &amp;#123;dot-product, cosine,      euclidean&amp;#125;.  Returns:    similarity: a (x, y) -> sim function.  Raises:    ValueError: if name is not supported.  """</span>  <span class="token keyword">if</span> name <span class="token operator">not</span> <span class="token keyword">in</span> PAIRWISE_SIMILARITY_FUNCTION<span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Similarity metric name "%s" not supported.'</span> <span class="token operator">%</span> name<span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> PAIRWISE_SIMILARITY_FUNCTION<span class="token punctuation">[</span>name<span class="token punctuation">]</span></code></pre><h4 id="The-cross-graph-attention"><a href="#The-cross-graph-attention" class="headerlink" title="The cross-graph attention"></a>The cross-graph attention</h4><p>We implement this cross-graph attention in batches of pairs.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_cross_attention</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> sim<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute cross attention.  x_i attend to y_j:  a_&amp;#123;i->j&amp;#125; = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))  y_j attend to x_i:  a_&amp;#123;j->i&amp;#125; = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))  attention_x = sum_j a_&amp;#123;i->j&amp;#125; y_j  attention_y = sum_i a_&amp;#123;j->i&amp;#125; x_i  Args:    x: NxD float tensor.    y: MxD float tensor.    sim: a (x, y) -> similarity function.  Returns:    attention_x: NxD float tensor.    attention_y: NxD float tensor.  """</span>  a <span class="token operator">=</span> sim<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  a_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># i->j</span>  a_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># j->i</span>  attention_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a_x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  attention_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a_y<span class="token punctuation">,</span> x<span class="token punctuation">,</span> transpose_a<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> attention_x<span class="token punctuation">,</span> attention_y<span class="token keyword">def</span> <span class="token function">batch_block_pair_attention</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>                               block_idx<span class="token punctuation">,</span>                               n_blocks<span class="token punctuation">,</span>                               similarity<span class="token operator">=</span><span class="token string">'dotproduct'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute batched attention between pairs of blocks.  This function partitions the batch data into blocks according to block_idx.  For each pair of blocks, x = data[block_idx == 2i], and  y = data[block_idx == 2i+1], we compute  x_i attend to y_j:  a_&amp;#123;i->j&amp;#125; = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))  y_j attend to x_i:  a_&amp;#123;j->i&amp;#125; = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))  and  attention_x = sum_j a_&amp;#123;i->j&amp;#125; y_j  attention_y = sum_i a_&amp;#123;j->i&amp;#125; x_i.  Args:    data: NxD float tensor.    block_idx: N-dim int tensor.    n_blocks: integer.    similarity: a string, the similarity metric.  Returns:    attention_output: NxD float tensor, each x_i replaced by attention_x_i.  Raises:    ValueError: if n_blocks is not an integer or not a multiple of 2.  """</span>  <span class="token keyword">if</span> <span class="token operator">not</span> isinstance<span class="token punctuation">(</span>n_blocks<span class="token punctuation">,</span> int<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'n_blocks (%s) has to be an integer.'</span> <span class="token operator">%</span> str<span class="token punctuation">(</span>n_blocks<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">if</span> n_blocks <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'n_blocks (%d) must be a multiple of 2.'</span> <span class="token operator">%</span> n_blocks<span class="token punctuation">)</span>  sim <span class="token operator">=</span> get_pairwise_similarity<span class="token punctuation">(</span>similarity<span class="token punctuation">)</span>  results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># This is probably better than doing boolean_mask for each i</span>  partitions <span class="token operator">=</span> tf<span class="token punctuation">.</span>dynamic_partition<span class="token punctuation">(</span>data<span class="token punctuation">,</span> block_idx<span class="token punctuation">,</span> n_blocks<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># It is rather complicated to allow n_blocks be a tf tensor and do this in a</span>  <span class="token comment" spellcheck="true"># dynamic loop, and probably unnecessary to do so.  Therefore we are</span>  <span class="token comment" spellcheck="true"># restricting n_blocks to be a integer constant here and using the plain for</span>  <span class="token comment" spellcheck="true"># loop.</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_blocks<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    x <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i<span class="token punctuation">]</span>    y <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>    attention_x<span class="token punctuation">,</span> attention_y <span class="token operator">=</span> compute_cross_attention<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> sim<span class="token punctuation">)</span>    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>attention_x<span class="token punctuation">)</span>    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>attention_y<span class="token punctuation">)</span>  results <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>results<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># the shape of the first dimension is lost after concat, reset it back</span>  results<span class="token punctuation">.</span>set_shape<span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token keyword">return</span> results</code></pre><h4 id="Graph-matching-layer-and-graph-matching-networks"><a href="#Graph-matching-layer-and-graph-matching-networks" class="headerlink" title="Graph matching layer and graph matching networks"></a>Graph matching layer and graph matching networks</h4><p>This only involves a small set of changes from the graph embedding model.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphPropMatchingLayer</span><span class="token punctuation">(</span>GraphPropLayer<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""A graph propagation layer that also does cross graph matching.  It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1  forms the first pair and graph 2 and 3 are the second pair etc., and computes  cross-graph attention-based matching for each pair.  """</span>  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>             node_states<span class="token punctuation">,</span>             from_idx<span class="token punctuation">,</span>             to_idx<span class="token punctuation">,</span>             graph_idx<span class="token punctuation">,</span>             n_graphs<span class="token punctuation">,</span>             similarity<span class="token operator">=</span><span class="token string">'dotproduct'</span><span class="token punctuation">,</span>             edge_features<span class="token operator">=</span>None<span class="token punctuation">,</span>             node_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Run one propagation step with cross-graph matching.    Args:      node_states: [n_nodes, node_state_dim] float tensor, node states.      from_idx: [n_edges] int tensor, from node indices for each edge.      to_idx: [n_edges] int tensor, to node indices for each edge.      graph_idx: [n_onodes] int tensor, graph id for each node.      n_graphs: integer, number of graphs in the batch.      similarity: type of similarity to use for the cross graph attention.      edge_features: if not None, should be [n_edges, edge_feat_dim] tensor,        extra edge features.      node_features: if not None, should be [n_nodes, node_feat_dim] tensor,        extra node features.    Returns:      node_states: [n_nodes, node_state_dim] float tensor, new node states.    Raises:      ValueError: if some options are not provided correctly.    """</span>    aggregated_messages <span class="token operator">=</span> self<span class="token punctuation">.</span>_compute_aggregated_messages<span class="token punctuation">(</span>        node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># new stuff here</span>    cross_graph_attention <span class="token operator">=</span> batch_block_pair_attention<span class="token punctuation">(</span>        node_states<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span> similarity<span class="token operator">=</span>similarity<span class="token punctuation">)</span>    attention_input <span class="token operator">=</span> node_states <span class="token operator">-</span> cross_graph_attention    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_compute_node_update<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span>                                     <span class="token punctuation">[</span>aggregated_messages<span class="token punctuation">,</span> attention_input<span class="token punctuation">]</span><span class="token punctuation">,</span>                                     node_features<span class="token operator">=</span>node_features<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">GraphMatchingNet</span><span class="token punctuation">(</span>GraphEmbeddingNet<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Graph matching net.  This class uses graph matching layers instead of the simple graph prop layers.  It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1  forms the first pair and graph 2 and 3 are the second pair etc., and computes  cross-graph attention-based matching for each pair.  """</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               encoder<span class="token punctuation">,</span>               aggregator<span class="token punctuation">,</span>               node_state_dim<span class="token punctuation">,</span>               edge_hidden_sizes<span class="token punctuation">,</span>               node_hidden_sizes<span class="token punctuation">,</span>               n_prop_layers<span class="token punctuation">,</span>               share_prop_params<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>               edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>               node_update_type<span class="token operator">=</span><span class="token string">'residual'</span><span class="token punctuation">,</span>               use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>               similarity<span class="token operator">=</span><span class="token string">'dotproduct'</span><span class="token punctuation">,</span>               name<span class="token operator">=</span><span class="token string">'graph-matching-net'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    super<span class="token punctuation">(</span>GraphMatchingNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>        encoder<span class="token punctuation">,</span>        aggregator<span class="token punctuation">,</span>        node_state_dim<span class="token punctuation">,</span>        edge_hidden_sizes<span class="token punctuation">,</span>        node_hidden_sizes<span class="token punctuation">,</span>        n_prop_layers<span class="token punctuation">,</span>        share_prop_params<span class="token operator">=</span>share_prop_params<span class="token punctuation">,</span>        edge_net_init_scale<span class="token operator">=</span>edge_net_init_scale<span class="token punctuation">,</span>        node_update_type<span class="token operator">=</span>node_update_type<span class="token punctuation">,</span>        use_reverse_direction<span class="token operator">=</span>use_reverse_direction<span class="token punctuation">,</span>        reverse_dir_param_different<span class="token operator">=</span>reverse_dir_param_different<span class="token punctuation">,</span>        layer_norm<span class="token operator">=</span>layer_norm<span class="token punctuation">,</span>        name<span class="token operator">=</span>name<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>_similarity <span class="token operator">=</span> similarity    self<span class="token punctuation">.</span>_layer_class <span class="token operator">=</span> GraphPropMatchingLayer  <span class="token keyword">def</span> <span class="token function">_apply_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                   layer<span class="token punctuation">,</span>                   node_states<span class="token punctuation">,</span>                   from_idx<span class="token punctuation">,</span>                   to_idx<span class="token punctuation">,</span>                   graph_idx<span class="token punctuation">,</span>                   n_graphs<span class="token punctuation">,</span>                   edge_features<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Apply one layer on the given inputs."""</span>    <span class="token keyword">return</span> layer<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span>                 similarity<span class="token operator">=</span>self<span class="token punctuation">.</span>_similarity<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span></code></pre><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><h3 id="Labeled-data-examples"><a href="#Labeled-data-examples" class="headerlink" title="Labeled data examples"></a>Labeled data examples</h3><p>We train on either pairs of graphs or triplets of graphs.  For pairs of graphs, we assume each pair $(G_1, G_2)$ comes with a label $t\in{-1, 1}$.  $t=1$ if $G_1$ and $G_2$ are similar, and $t=-1$ otherwise.</p><p>For triplets of graphs, we assume within each triplet $(G_1, G_2, G_3)$, $G_1$ is similar to $G_2$ but not similar to $G_3$.</p><p>The goal of training is to learn the parameters of the function $f(G_1, G_2)$ such that similar graphs have high similarity (or small distance) and dissimilar graphs have low similarity (or high distance).</p><h3 id="Training-on-pairs"><a href="#Training-on-pairs" class="headerlink" title="Training on pairs"></a>Training on pairs</h3><p>Given a dataset of pairs $(G_1, G_2)$ and labels $t\in{-1, 1}$, we can use the following margin-based loss if using Euclidean distance:</p><p>$$<br>L_\mathrm{pair} = \mathbb{E}_{(G_1, G_2, t)}[\max{0, \gamma - t(1 - d(G_1, G_2))}]<br>$$</p><p>This loss encourages similar graphs to have distance smaller than $1-\gamma$, and dissimilar graphs to have distance greater than $1 + \gamma$, where $\gamma$ is a margin parameter.</p><p>Alternatively, for many applications it is beneficial to have the representation of graphs be binary which allows efficient indexing and hashing.  In this case, Hamming distance (similarity) is more appropriate.  On the other hand, the Hamming distance is not differentiable, so we use a smooth approximation<br>$$<br>s(G_1, G_2) = \frac{1}{H}\sum_{i=1}^H \tanh(h_{G_1, i}) \cdot \tanh(h_{G_2, i}),<br>$$<br>where $s$ is now a similarity (rather than distance) function, $h_{G, i}$ is the i-th dimension of the smooth representation vector for G.  We get binary codes by thresholding $h_{G,i}$ at 0, i.e. $\hat{h}<em>{G,i}=1$ if $h</em>{G,i}\ge 0$ and $-1$ otherwise.</p><p>The loss we use with these binary representations is defined as</p><p>$$<br>L_\mathrm{pair} = \mathbb{E}_{(G_1, G_2, t)}[(t - s(G_1, G_2))^2] / 4.<br>$$</p><p>The factor of $1/4$ is used to normalize the loss to between 0 and 1.</p><p>These are just two possible losses, many other types of losses could also be used.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">euclidean_distance</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""This is the squared Euclidean distance."""</span>  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">approximate_hamming_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Approximate Hamming similarity."""</span>  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">pairwise_loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> loss_type<span class="token operator">=</span><span class="token string">'margin'</span><span class="token punctuation">,</span> margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute pairwise loss.  Args:    x: [N, D] float tensor, representations for N examples.    y: [N, D] float tensor, representations for another N examples.    labels: [N] int tensor, with values in -1 or +1.  labels[i] = +1 if x[i]      and y[i] are similar, and -1 otherwise.    loss_type: margin or hamming.    margin: float scalar, margin for the margin loss.  Returns:    loss: [N] float tensor.  Loss for each pair of representations.  """</span>  labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>  <span class="token keyword">if</span> loss_type <span class="token operator">==</span> <span class="token string">'margin'</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>margin <span class="token operator">-</span> labels <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> euclidean_distance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">elif</span> loss_type <span class="token operator">==</span> <span class="token string">'hamming'</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">0.25</span> <span class="token operator">*</span> <span class="token punctuation">(</span>labels <span class="token operator">-</span> approximate_hamming_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown loss_type %s'</span> <span class="token operator">%</span> loss_type<span class="token punctuation">)</span></code></pre><h3 id="Training-on-triplets"><a href="#Training-on-triplets" class="headerlink" title="Training on triplets"></a>Training on triplets</h3><p>Given a dataset of triplets $(G_1, G_2, G_3)$ where $G_1$ is similar to $G_2$ but not similar to $G_3$, we can again use a margin loss or Hamming similarity-based loss.</p><p>The following margin loss can be used with Euclidean distance:</p><p>$$<br>L_\mathrm{triplet} = \mathbb{E}_{(G_1, G_2, G_3)}[\max{0, d(G_1, G_2) - d(G_1, G_3) + \gamma}],<br>$$<br>which encourages $d(G_1, G_2)$ to be smaller by $d(G_1, G_3)$ by at least a margin of $\gamma$.</p><p>If using Hamming distance (similarity) we could use the following loss:</p><p>$$<br>L_\mathrm{triplet} = \mathbb{E}_{(G_1, G_2, G_3)}[(s(G_1, G_2) - 1)^2 + (s(G_1, G_3) + 1)^2] / 8<br>$$</p><p>The factor of $1/8$ is again used to normalize the loss to within 0 and 1.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">triplet_loss</span><span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">,</span> loss_type<span class="token operator">=</span><span class="token string">'margin'</span><span class="token punctuation">,</span> margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute triplet loss.  This function computes loss on a triplet of inputs (x, y, z).  A similarity or  distance value is computed for each pair of (x, y) and (x, z).  Since the  representations for x can be different in the two pairs (like our matching  model) we distinguish the two x representations by x_1 and x_2.  Args:    x_1: [N, D] float tensor.    y: [N, D] float tensor.    x_2: [N, D] float tensor.    z: [N, D] float tensor.    loss_type: margin or hamming.    margin: float scalar, margin for the margin loss.  Returns:    loss: [N] float tensor.  Loss for each pair of representations.  """</span>  <span class="token keyword">if</span> loss_type <span class="token operator">==</span> <span class="token string">'margin'</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>margin <span class="token operator">+</span>                      euclidean_distance<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">-</span>                      euclidean_distance<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">elif</span> loss_type <span class="token operator">==</span> <span class="token string">'hamming'</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">0.125</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>approximate_hamming_similarity<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span>                    <span class="token punctuation">(</span>approximate_hamming_similarity<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown loss_type %s'</span> <span class="token operator">%</span> loss_type<span class="token punctuation">)</span></code></pre><h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>We use an abstract <code>GraphSimilarityDataset</code> class to define the general interface for the training and evaluatin data used in graph similarity learning.</p><p>We also assume a certain format for packing the graphs into tensors as described below.</p><pre class=" language-python"><code class="language-python">GraphData <span class="token operator">=</span> collections<span class="token punctuation">.</span>namedtuple<span class="token punctuation">(</span><span class="token string">'GraphData'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>    <span class="token string">'from_idx'</span><span class="token punctuation">,</span>    <span class="token string">'to_idx'</span><span class="token punctuation">,</span>    <span class="token string">'node_features'</span><span class="token punctuation">,</span>    <span class="token string">'edge_features'</span><span class="token punctuation">,</span>    <span class="token string">'graph_idx'</span><span class="token punctuation">,</span>    <span class="token string">'n_graphs'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>@six<span class="token punctuation">.</span>add_metaclass<span class="token punctuation">(</span>abc<span class="token punctuation">.</span>ABCMeta<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">GraphSimilarityDataset</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Base class for all the graph similarity learning datasets.  This class defines some common interfaces a graph similarity dataset can have,  in particular the functions that creates iterators over pairs and triplets.  """</span>  @abc<span class="token punctuation">.</span>abstractmethod  <span class="token keyword">def</span> <span class="token function">triplets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Create an iterator over triplets.    Args:      batch_size: int, number of triplets in a batch.    Yields:      graphs: a `GraphData` instance.  The batch of triplets put together.  Each        triplet has 3 graphs (x, y, z).  Here the first graph is duplicated once        so the graphs for each triplet are ordered as (x, y, x, z) in the batch.        The batch contains `batch_size` number of triplets, hence `4*batch_size`        many graphs.    """</span>    <span class="token keyword">pass</span>  @abc<span class="token punctuation">.</span>abstractmethod  <span class="token keyword">def</span> <span class="token function">pairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Create an iterator over pairs.    Args:      batch_size: int, number of pairs in a batch.    Yields:      graphs: a `GraphData` instance.  The batch of pairs put together.  Each        pair has 2 graphs (x, y).  The batch contains `batch_size` number of        pairs, hence `2*batch_size` many graphs.      labels: [batch_size] int labels for each pair, +1 for similar, -1 for not.    """</span>    <span class="token keyword">pass</span></code></pre><h2 id="The-graph-edit-distance-task"><a href="#The-graph-edit-distance-task" class="headerlink" title="The graph edit distance task"></a>The graph edit distance task</h2><p>Here we use the synthetic task of learning approximate graph edit distances (GEDs) to test the effectiveness of the graph similarity learning models.</p><p>Given two graphs $G_1$ and $G_2$, we say the edit distance between them is the number of actions needed to transform one into another.  Since the difference in graph size (number of nodes, number of edges) is trivial to identify, we only consider the case of substituting one edge with another edge, and define the edit distance between two equal-size graphs to be the number of edge changes needed to make them identical (or isomorphic).</p><p>We train a graph similarity or distance model that aligns with the GED, by giving graphs with small edit distance a high similarity score or low learned distance, and otherwise low similarity score or high learned distance.  Note that we don’t try to match the learned graph distance with the actual GED, as we don’t assume the exact scale of the GED is available during training.</p><p>To get training data, we sample graph $G$ from the Erdos-Renyi model (other random graph models could be used as well), and then:</p><ul><li>apply a node permutation to $G$ to get $G_1$,</li><li>apply $k_1$ edge changes to $G$ to get $G_2$,</li><li>apply $k_2$ edge changes to $G$ to get $G_3$.</li></ul><p>Each edge change action substitutes one edge $(i,j)$ by another edge $(i’, j’)$ where $i’$ and $j’$ are picked randomly.  In this case, we have roughly $GED(G_1, G_2)\approx k_1$ and $GED(G_1, G_3)\approx k_2$.  We make $k_1 &lt; k_2$ and say $(G_1, G_2)$ is a positive pair that are similar and $(G_1, G_3)$ is a negative pair hence not similar.</p><p>Note that the above GED for $G_1, G_2$ and $G_3$ only holds approximately, and $GED(G_1, G_2)\le k_1$ and $GED(G_1, G_3)\le k_2$, because of the potential symmetry in $G$, i.e. it is possible that changing one edge may only change the graph into another isomorphic graph.  However the probability of this happening is relatively small and decreases with increasing graph size.  So we ignore this possibility in this task.</p><h3 id="A-few-graph-manipulation-primitives"><a href="#A-few-graph-manipulation-primitives" class="headerlink" title="A few graph manipulation primitives"></a>A few graph manipulation primitives</h3><p>These primitives assume the incoming graphs are instances of <code>networkx.Graph</code>.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">permute_graph_nodes</span><span class="token punctuation">(</span>g<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Permute node ordering of a graph, returns a new graph."""</span>  n <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>  new_g <span class="token operator">=</span> nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>  new_g<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span>  perm <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>n<span class="token punctuation">)</span>  edges <span class="token operator">=</span> g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span>  new_edges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> edges<span class="token punctuation">:</span>    new_edges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>perm<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span> perm<span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  new_g<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>new_edges<span class="token punctuation">)</span>  <span class="token keyword">return</span> new_g<span class="token keyword">def</span> <span class="token function">substitute_random_edges</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Substitutes n edges from graph g with another n randomly picked edges."""</span>  g <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>g<span class="token punctuation">)</span>  n_nodes <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>  edges <span class="token operator">=</span> list<span class="token punctuation">(</span>g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># sample n edges without replacement</span>  e_remove <span class="token operator">=</span> <span class="token punctuation">[</span>edges<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>      np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>len<span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  edge_set <span class="token operator">=</span> set<span class="token punctuation">(</span>edges<span class="token punctuation">)</span>  e_add <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">while</span> len<span class="token punctuation">(</span>e_add<span class="token punctuation">)</span> <span class="token operator">&lt;</span> n<span class="token punctuation">:</span>    e <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># make sure e does not exist and is not already chosen to be added</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> edge_set <span class="token operator">and</span> <span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> edge_set <span class="token operator">and</span>        <span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> e_add <span class="token operator">and</span> <span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> e_add<span class="token punctuation">)</span><span class="token punctuation">:</span>      e_add<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> e_remove<span class="token punctuation">:</span>    g<span class="token punctuation">.</span>remove_edge<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j<span class="token punctuation">)</span>  <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> e_add<span class="token punctuation">:</span>    g<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j<span class="token punctuation">)</span>  <span class="token keyword">return</span> g</code></pre><h3 id="Dataset-for-training-fixed-dataset-for-evaluation"><a href="#Dataset-for-training-fixed-dataset-for-evaluation" class="headerlink" title="Dataset for training, fixed dataset for evaluation"></a>Dataset for training, fixed dataset for evaluation</h3><p>For training we use a procedure to generate graphs in pairs or triplets on the fly, and wrap this process into a <code>Dataset</code> instance.  For evaluation we need to<br>use a fixed set to make sure the evaluation results are consistent and comparable, and we do that by controlling random seeds.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphEditDistanceDataset</span><span class="token punctuation">(</span>GraphSimilarityDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Graph edit distance dataset."""</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               n_nodes_range<span class="token punctuation">,</span>               p_edge_range<span class="token punctuation">,</span>               n_changes_positive<span class="token punctuation">,</span>               n_changes_negative<span class="token punctuation">,</span>               permute<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Constructor.    Args:      n_nodes_range: a tuple (n_min, n_max).  The minimum and maximum number of        nodes in a graph to generate.      p_edge_range: a tuple (p_min, p_max).  The minimum and maximum edge        probability.      n_changes_positive: the number of edge substitutions for a pair to be        considered positive (similar).      n_changes_negative: the number of edge substitutions for a pair to be        considered negative (not similar).      permute: if True (default), permute node orderings in addition to        changing edges; if False, the node orderings across a pair or triplet of        graphs will be the same, useful for visualization.    """</span>    self<span class="token punctuation">.</span>_n_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_n_max <span class="token operator">=</span> n_nodes_range    self<span class="token punctuation">.</span>_p_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_p_max <span class="token operator">=</span> p_edge_range    self<span class="token punctuation">.</span>_k_pos <span class="token operator">=</span> n_changes_positive    self<span class="token punctuation">.</span>_k_neg <span class="token operator">=</span> n_changes_negative    self<span class="token punctuation">.</span>_permute <span class="token operator">=</span> permute  <span class="token keyword">def</span> <span class="token function">_get_graph</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Generate one graph."""</span>    n_nodes <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_n_max <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>    p_edge <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_p_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_p_max<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># do a little bit of filtering</span>    n_trials <span class="token operator">=</span> <span class="token number">100</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_trials<span class="token punctuation">)</span><span class="token punctuation">:</span>      g <span class="token operator">=</span> nx<span class="token punctuation">.</span>erdos_renyi_graph<span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> p_edge<span class="token punctuation">)</span>      <span class="token keyword">if</span> nx<span class="token punctuation">.</span>is_connected<span class="token punctuation">(</span>g<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> g    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Failed to generate a connected graph.'</span><span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">_get_pair</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> positive<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Generate one pair of graphs."""</span>    g <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_permute<span class="token punctuation">:</span>      permuted_g <span class="token operator">=</span> permute_graph_nodes<span class="token punctuation">(</span>g<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>      permuted_g <span class="token operator">=</span> g    n_changes <span class="token operator">=</span> self<span class="token punctuation">.</span>_k_pos <span class="token keyword">if</span> positive <span class="token keyword">else</span> self<span class="token punctuation">.</span>_k_neg    changed_g <span class="token operator">=</span> substitute_random_edges<span class="token punctuation">(</span>g<span class="token punctuation">,</span> n_changes<span class="token punctuation">)</span>    <span class="token keyword">return</span> permuted_g<span class="token punctuation">,</span> changed_g  <span class="token keyword">def</span> <span class="token function">_get_triplet</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Generate one triplet of graphs."""</span>    g <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_permute<span class="token punctuation">:</span>      permuted_g <span class="token operator">=</span> permute_graph_nodes<span class="token punctuation">(</span>g<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>      permuted_g <span class="token operator">=</span> g    pos_g <span class="token operator">=</span> substitute_random_edges<span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_k_pos<span class="token punctuation">)</span>    neg_g <span class="token operator">=</span> substitute_random_edges<span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_k_neg<span class="token punctuation">)</span>    <span class="token keyword">return</span> permuted_g<span class="token punctuation">,</span> pos_g<span class="token punctuation">,</span> neg_g  <span class="token keyword">def</span> <span class="token function">triplets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Yields batches of triplet data."""</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>      batch_graphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>      <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_triplet<span class="token punctuation">(</span><span class="token punctuation">)</span>        batch_graphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g1<span class="token punctuation">,</span> g3<span class="token punctuation">)</span><span class="token punctuation">)</span>      <span class="token keyword">yield</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>  <span class="token keyword">def</span> <span class="token function">pairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Yields batches of pair data."""</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>      batch_graphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>      batch_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>      positive <span class="token operator">=</span> <span class="token boolean">True</span>      <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        g1<span class="token punctuation">,</span> g2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_pair<span class="token punctuation">(</span>positive<span class="token punctuation">)</span>        batch_graphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">)</span><span class="token punctuation">)</span>        batch_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> positive <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        positive <span class="token operator">=</span> <span class="token operator">not</span> positive      packed_graphs <span class="token operator">=</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>      labels <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>batch_labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>      <span class="token keyword">yield</span> packed_graphs<span class="token punctuation">,</span> labels  <span class="token keyword">def</span> <span class="token function">_pack_batch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Pack a batch of graphs into a single `GraphData` instance.    Args:      graphs: a list of generated networkx graphs.    Returns:      graph_data: a `GraphData` instance, with node and edge indices properly        shifted.    """</span>    graphs <span class="token operator">=</span> tf<span class="token punctuation">.</span>nest<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span>    from_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    to_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    graph_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    n_total_nodes <span class="token operator">=</span> <span class="token number">0</span>    n_total_edges <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> g <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>      n_nodes <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>      n_edges <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_edges<span class="token punctuation">(</span><span class="token punctuation">)</span>      edges <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># shift the node indices for the edges</span>      from_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> n_total_nodes<span class="token punctuation">)</span>      to_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> n_total_nodes<span class="token punctuation">)</span>      graph_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> <span class="token operator">*</span> i<span class="token punctuation">)</span>      n_total_nodes <span class="token operator">+=</span> n_nodes      n_total_edges <span class="token operator">+=</span> n_edges    <span class="token keyword">return</span> GraphData<span class="token punctuation">(</span>        from_idx<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>from_idx<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        to_idx<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>to_idx<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment" spellcheck="true"># this task only cares about the structures, the graphs have no features</span>        node_features<span class="token operator">=</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n_total_nodes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>        edge_features<span class="token operator">=</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n_total_edges<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>        graph_idx<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>graph_idx<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        n_graphs<span class="token operator">=</span>len<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token punctuation">)</span>@contextlib<span class="token punctuation">.</span>contextmanager<span class="token keyword">def</span> <span class="token function">reset_random_state</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""This function creates a context that uses the given seed."""</span>  np_rnd_state <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>get_state<span class="token punctuation">(</span><span class="token punctuation">)</span>  rnd_state <span class="token operator">=</span> random<span class="token punctuation">.</span>getstate<span class="token punctuation">(</span><span class="token punctuation">)</span>  np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>  random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token keyword">try</span><span class="token punctuation">:</span>    <span class="token keyword">yield</span>  <span class="token keyword">finally</span><span class="token punctuation">:</span>    random<span class="token punctuation">.</span>setstate<span class="token punctuation">(</span>rnd_state<span class="token punctuation">)</span>    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_state<span class="token punctuation">(</span>np_rnd_state<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">FixedGraphEditDistanceDataset</span><span class="token punctuation">(</span>GraphEditDistanceDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""A fixed dataset of pairs or triplets for the graph edit distance task.  This dataset can be used for evaluation.  """</span>  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>               n_nodes_range<span class="token punctuation">,</span>               p_edge_range<span class="token punctuation">,</span>               n_changes_positive<span class="token punctuation">,</span>               n_changes_negative<span class="token punctuation">,</span>               dataset_size<span class="token punctuation">,</span>               permute<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               seed<span class="token operator">=</span><span class="token number">1234</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    super<span class="token punctuation">(</span>FixedGraphEditDistanceDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>        n_nodes_range<span class="token punctuation">,</span> p_edge_range<span class="token punctuation">,</span> n_changes_positive<span class="token punctuation">,</span> n_changes_negative<span class="token punctuation">,</span>        permute<span class="token operator">=</span>permute<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>_dataset_size <span class="token operator">=</span> dataset_size    self<span class="token punctuation">.</span>_seed <span class="token operator">=</span> seed  <span class="token keyword">def</span> <span class="token function">triplets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Yield triplets."""</span>    <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_triplets'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      triplets <span class="token operator">=</span> self<span class="token punctuation">.</span>_triplets    <span class="token keyword">else</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># get a fixed set of triplets</span>      <span class="token keyword">with</span> reset_random_state<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_seed<span class="token punctuation">)</span><span class="token punctuation">:</span>        triplets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_dataset_size<span class="token punctuation">)</span><span class="token punctuation">:</span>          g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_triplet<span class="token punctuation">(</span><span class="token punctuation">)</span>          triplets<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g1<span class="token punctuation">,</span> g3<span class="token punctuation">)</span><span class="token punctuation">)</span>      self<span class="token punctuation">.</span>_triplets <span class="token operator">=</span> triplets    ptr <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> ptr <span class="token operator">+</span> batch_size <span class="token operator">&lt;=</span> len<span class="token punctuation">(</span>triplets<span class="token punctuation">)</span><span class="token punctuation">:</span>      batch_graphs <span class="token operator">=</span> triplets<span class="token punctuation">[</span>ptr<span class="token punctuation">:</span>ptr <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>      <span class="token keyword">yield</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>      ptr <span class="token operator">+=</span> batch_size  <span class="token keyword">def</span> <span class="token function">pairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Yield pairs and labels."""</span>    <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_pairs'</span><span class="token punctuation">)</span> <span class="token operator">and</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_labels'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      pairs <span class="token operator">=</span> self<span class="token punctuation">.</span>_pairs      labels <span class="token operator">=</span> self<span class="token punctuation">.</span>_labels    <span class="token keyword">else</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># get a fixed set of pairs first</span>      <span class="token keyword">with</span> reset_random_state<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_seed<span class="token punctuation">)</span><span class="token punctuation">:</span>        pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        positive <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_dataset_size<span class="token punctuation">)</span><span class="token punctuation">:</span>          pairs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_pair<span class="token punctuation">(</span>positive<span class="token punctuation">)</span><span class="token punctuation">)</span>          labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> positive <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>          positive <span class="token operator">=</span> <span class="token operator">not</span> positive      labels <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>      self<span class="token punctuation">.</span>_pairs <span class="token operator">=</span> pairs      self<span class="token punctuation">.</span>_labels <span class="token operator">=</span> labels    ptr <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> ptr <span class="token operator">+</span> batch_size <span class="token operator">&lt;=</span> len<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">:</span>      batch_graphs <span class="token operator">=</span> pairs<span class="token punctuation">[</span>ptr<span class="token punctuation">:</span>ptr <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>      packed_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>      <span class="token keyword">yield</span> packed_batch<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>ptr<span class="token punctuation">:</span>ptr <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>      ptr <span class="token operator">+=</span> batch_size</code></pre><h2 id="Building-the-model-and-the-training-and-evaluation-pipelines"><a href="#Building-the-model-and-the-training-and-evaluation-pipelines" class="headerlink" title="Building the model, and the training and evaluation pipelines"></a>Building the model, and the training and evaluation pipelines</h2><h3 id="Configs"><a href="#Configs" class="headerlink" title="Configs"></a>Configs</h3><p>We put all the configs for model building and training into a single <code>dict</code>, but any part of our code can also be used separately with separate configs if you want.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_default_config</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""The default configs."""</span>  node_state_dim <span class="token operator">=</span> <span class="token number">32</span>  graph_rep_dim <span class="token operator">=</span> <span class="token number">128</span>  graph_embedding_net_config <span class="token operator">=</span> dict<span class="token punctuation">(</span>      node_state_dim<span class="token operator">=</span>node_state_dim<span class="token punctuation">,</span>      edge_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>node_state_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> node_state_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      node_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>node_state_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      n_prop_layers<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># set to False to not share parameters across message passing layers</span>      share_prop_params<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># initialize message MLP with small parameter weights to prevent</span>      <span class="token comment" spellcheck="true"># aggregated message vectors blowing up, alternatively we could also use</span>      <span class="token comment" spellcheck="true"># e.g. layer normalization to keep the scale of these under control.</span>      edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># other types of update like `mlp` and `residual` can also be used here.</span>      node_update_type<span class="token operator">=</span><span class="token string">'gru'</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># set to False if your graph already contains edges in both directions.</span>      use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># set to True if your graph is directed</span>      reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># we didn't use layer norm in our experiments but sometimes this can help.</span>      layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  graph_matching_net_config <span class="token operator">=</span> graph_embedding_net_config<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>  graph_matching_net_config<span class="token punctuation">[</span><span class="token string">'similarity'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'dotproduct'</span>  <span class="token keyword">return</span> dict<span class="token punctuation">(</span>      encoder<span class="token operator">=</span>dict<span class="token punctuation">(</span>          node_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>node_state_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>          edge_hidden_sizes<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>      aggregator<span class="token operator">=</span>dict<span class="token punctuation">(</span>          node_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>graph_rep_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>          graph_transform_sizes<span class="token operator">=</span><span class="token punctuation">[</span>graph_rep_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>          gated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>          aggregation_type<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      graph_embedding_net<span class="token operator">=</span>graph_embedding_net_config<span class="token punctuation">,</span>      graph_matching_net<span class="token operator">=</span>graph_matching_net_config<span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># Set to `embedding` to use the graph embedding net.</span>      model_type<span class="token operator">=</span><span class="token string">'matching'</span><span class="token punctuation">,</span>      data<span class="token operator">=</span>dict<span class="token punctuation">(</span>          problem<span class="token operator">=</span><span class="token string">'graph_edit_distance'</span><span class="token punctuation">,</span>          dataset_params<span class="token operator">=</span>dict<span class="token punctuation">(</span>              <span class="token comment" spellcheck="true"># always generate graphs with 20 nodes and p_edge=0.2.</span>              n_nodes_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              p_edge_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              n_changes_positive<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>              n_changes_negative<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>              validation_dataset_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      training<span class="token operator">=</span>dict<span class="token punctuation">(</span>          batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>          learning_rate<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span>          mode<span class="token operator">=</span><span class="token string">'pair'</span><span class="token punctuation">,</span>          loss<span class="token operator">=</span><span class="token string">'margin'</span><span class="token punctuation">,</span>          margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># A small regularizer on the graph vector scales to avoid the graph</span>          <span class="token comment" spellcheck="true"># vectors blowing up.  If numerical issues is particularly bad in the</span>          <span class="token comment" spellcheck="true"># model we can add `snt.LayerNorm` to the outputs of each layer, the</span>          <span class="token comment" spellcheck="true"># aggregated messages and aggregated node representations to</span>          <span class="token comment" spellcheck="true"># keep the network activation scale in a reasonable range.</span>          graph_vec_regularizer_weight<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># Add gradient clipping to avoid large gradients.</span>          clip_value<span class="token operator">=</span><span class="token number">10.0</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># Increase this to train longer.</span>          n_training_steps<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># Print training information every this many training steps.</span>          print_after<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>          <span class="token comment" spellcheck="true"># Evaluate on validation set every `eval_after * print_after` steps.</span>          eval_after<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      evaluation<span class="token operator">=</span>dict<span class="token punctuation">(</span>          batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      seed<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>      <span class="token punctuation">)</span></code></pre><h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>We evaluate the performance of the models by measuring how well they do on held-out data.  We look at two metrics, triplet accuracy and pair AUC.</p><p>For each triplet $(G_1, G_2, G_3)$, a model is said to make a correct prediction if it predicts $d(G_1, G_2) &lt; d(G_1, G_3)$, i.e. similar graphs have a smaller distance (or larger similarity) than dissimilar graphs.  We average the accuracy across a dataset to get the <strong>triplet accuracy</strong> metric.</p><p>For each pair $(G_1, G_2)$ a model computes a distance $d(G_1, G_2)$.  To compute the <strong>pair AUC</strong> metric, we rank all the pairs by the distance from low to high (similarity from high to low), and then compute the area under the ROC curve for positive pairs.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">exact_hamming_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute the binary Hamming similarity."""</span>  match <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>x <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">,</span> y <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>match<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">compute_similarity</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute the distance between x and y vectors.  The distance will be computed based on the training loss type.  Args:    config: a config dict.    x: [n_examples, feature_dim] float tensor.    y: [n_examples, feature_dim] float tensor.  Returns:    dist: [n_examples] float tensor.  Raises:    ValueError: if loss type is not supported.  """</span>  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'margin'</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># similarity is negative distance</span>    <span class="token keyword">return</span> <span class="token operator">-</span>euclidean_distance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token keyword">elif</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'hamming'</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> exact_hamming_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown loss type %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">auc</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> <span class="token operator">**</span>auc_args<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Compute the AUC for pair classification.  See `tf.metrics.auc` for more details about this metric.  Args:    scores: [n_examples] float.  Higher scores mean higher preference of being      assigned the label of +1.    labels: [n_examples] int.  Labels are either +1 or -1.    **auc_args: other arguments that can be used by `tf.metrics.auc`.  Returns:    auc: the area under the ROC curve.  """</span>  scores_max <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>  scores_min <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_min<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># normalize scores to [0, 1] and add a small epislon for safety</span>  scores <span class="token operator">=</span> <span class="token punctuation">(</span>scores <span class="token operator">-</span> scores_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>scores_max <span class="token operator">-</span> scores_min <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span>  labels <span class="token operator">=</span> <span class="token punctuation">(</span>labels <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>  <span class="token comment" spellcheck="true"># The following code should be used according to the tensorflow official</span>  <span class="token comment" spellcheck="true"># documentation:</span>  <span class="token comment" spellcheck="true"># value, _ = tf.metrics.auc(labels, scores, **auc_args)</span>  <span class="token comment" spellcheck="true"># However `tf.metrics.auc` is currently (as of July 23, 2019) buggy so we have</span>  <span class="token comment" spellcheck="true"># to use the following:</span>  _<span class="token punctuation">,</span> value <span class="token operator">=</span> tf<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>auc<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> scores<span class="token punctuation">,</span> <span class="token operator">**</span>auc_args<span class="token punctuation">)</span>  <span class="token keyword">return</span> value</code></pre><h3 id="Build-the-model"><a href="#Build-the-model" class="headerlink" title="Build the model"></a>Build the model</h3><p>We need to:</p><ul><li>set up the placeholders</li><li>build the model</li><li>build the computation graphs for training and evaluation</li><li>build the metrics and statistics to monitor</li></ul><p>We assume the graphs are batched, if a batch contains pairs $(G_1^1, G_2^1), (G_1^2, G_2^2), …$, then the graphs will be packed in a batch as a sequence of graphs $(G_1^1, G_2^1, G_1^2, G_2^2, …)$.  If a batch contains triplets $(G_1^1, G_2^1, G_3^1), (G_1^2, G_2^2, G_3^2)$ then the graphs will be packed in a batch as a sequence of $(G_1^1, G_2^1, G_1^1, G_3^1, G_1^2, G_2^2, G_1^2, G_3^2), …$.  Note that the first graph in each triplet is duplicated once to make the cross-graph attention more easily computable as it requires the graphs to appear in pairs.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">reshape_and_split_tensor</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> n_splits<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Reshape and split a 2D tensor along the last dimension.  Args:    tensor: a [num_examples, feature_dim] tensor.  num_examples must be a      multiple of `n_splits`.    n_splits: int, number of splits to split the tensor into.  Returns:    splits: a list of `n_splits` tensors.  The first split is [tensor[0],      tensor[n_splits], tensor[n_splits * 2], ...], the second split is      [tensor[1], tensor[n_splits + 1], tensor[n_splits * 2 + 1], ...], etc..  """</span>  feature_dim <span class="token operator">=</span> tensor<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># feature dim must be known, otherwise you can provide that as an input</span>  <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>feature_dim<span class="token punctuation">,</span> int<span class="token punctuation">)</span>  tensor <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> feature_dim <span class="token operator">*</span> n_splits<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> n_splits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">build_placeholders</span><span class="token punctuation">(</span>node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Build the placeholders needed for the model.  Args:    node_feature_dim: int.    edge_feature_dim: int.  Returns:    placeholders: a placeholder name -> placeholder tensor dict.  """</span>  <span class="token comment" spellcheck="true"># `n_graphs` must be specified as an integer, as `tf.dynamic_partition`</span>  <span class="token comment" spellcheck="true"># requires so.</span>  <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>      <span class="token string">'node_features'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">,</span> node_feature_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token string">'edge_features'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token string">'from_idx'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token string">'to_idx'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token string">'graph_idx'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token comment" spellcheck="true"># only used for pairwise training and evaluation</span>      <span class="token string">'labels'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token keyword">def</span> <span class="token function">build_model</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Create model for training and evaluation.  Args:    config: a dictionary of configs, like the one created by the      `get_default_config` function.    node_feature_dim: int, dimensionality of node features.    edge_feature_dim: int, dimensionality of edge features.  Returns:    tensors: a (potentially nested) name => tensor dict.    placeholders: a (potentially nested) name => tensor dict.    model: a GraphEmbeddingNet or GraphMatchingNet instance.  Raises:    ValueError: if the specified model or training settings are not supported.  """</span>  encoder <span class="token operator">=</span> GraphEncoder<span class="token punctuation">(</span><span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'encoder'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  aggregator <span class="token operator">=</span> GraphAggregator<span class="token punctuation">(</span><span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'aggregator'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'model_type'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'embedding'</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> GraphEmbeddingNet<span class="token punctuation">(</span>        encoder<span class="token punctuation">,</span> aggregator<span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'graph_embedding_net'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token keyword">elif</span> config<span class="token punctuation">[</span><span class="token string">'model_type'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'matching'</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> GraphMatchingNet<span class="token punctuation">(</span>        encoder<span class="token punctuation">,</span> aggregator<span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'graph_matching_net'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown model type: %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'model_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  training_n_graphs_in_batch <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span>  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'pair'</span><span class="token punctuation">:</span>    training_n_graphs_in_batch <span class="token operator">*=</span> <span class="token number">2</span>  <span class="token keyword">elif</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'triplet'</span><span class="token punctuation">:</span>    training_n_graphs_in_batch <span class="token operator">*=</span> <span class="token number">4</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown training mode: %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  placeholders <span class="token operator">=</span> build_placeholders<span class="token punctuation">(</span>node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># training</span>  model_inputs <span class="token operator">=</span> placeholders<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">del</span> model_inputs<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>  model_inputs<span class="token punctuation">[</span><span class="token string">'n_graphs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> training_n_graphs_in_batch  graph_vectors <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'pair'</span><span class="token punctuation">:</span>    x<span class="token punctuation">,</span> y <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>graph_vectors<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> pairwise_loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                         loss_type<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                         margin<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'margin'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># optionally monitor the similarity between positive and negative pairs</span>    is_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>    is_neg <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> is_pos    n_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>is_pos<span class="token punctuation">)</span>    n_neg <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>is_neg<span class="token punctuation">)</span>    sim <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>    sim_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>sim <span class="token operator">*</span> is_pos<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>n_pos <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span>    sim_neg <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>sim <span class="token operator">*</span> is_neg<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>n_neg <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>graph_vectors<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> triplet_loss<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">,</span>                        loss_type<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        margin<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'margin'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    sim_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>    sim_neg <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">)</span>  graph_vec_scale <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>graph_vectors<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'graph_vec_regularizer_weight'</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>    loss <span class="token operator">+=</span> <span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'graph_vec_regularizer_weight'</span><span class="token punctuation">]</span> <span class="token operator">*</span>             <span class="token number">0.5</span> <span class="token operator">*</span> graph_vec_scale<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># monitor scale of the parameters and gradients, these are typically helpful</span>  optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>      learning_rate<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'learning_rate'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  grads_and_params <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>compute_gradients<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>  grads<span class="token punctuation">,</span> params <span class="token operator">=</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>grads_and_params<span class="token punctuation">)</span>  grads<span class="token punctuation">,</span> _ <span class="token operator">=</span> tf<span class="token punctuation">.</span>clip_by_global_norm<span class="token punctuation">(</span>grads<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'clip_value'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  train_step <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>zip<span class="token punctuation">(</span>grads<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">)</span>  grad_scale <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_norm<span class="token punctuation">(</span>grads<span class="token punctuation">)</span>  param_scale <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_norm<span class="token punctuation">(</span>params<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># evaluation</span>  model_inputs<span class="token punctuation">[</span><span class="token string">'n_graphs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'evaluation'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span>  eval_pairs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>  x<span class="token punctuation">,</span> y <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>eval_pairs<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  similarity <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  pair_auc <span class="token operator">=</span> auc<span class="token punctuation">(</span>similarity<span class="token punctuation">,</span> placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  model_inputs<span class="token punctuation">[</span><span class="token string">'n_graphs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'evaluation'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span>  eval_triplets <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>  x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>eval_triplets<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>  sim_1 <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  sim_2 <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span>  triplet_acc <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>sim_1 <span class="token operator">></span> sim_2<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>      <span class="token string">'train_step'</span><span class="token punctuation">:</span> train_step<span class="token punctuation">,</span>      <span class="token string">'metrics'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>          <span class="token string">'training'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>              <span class="token string">'loss'</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span>              <span class="token string">'grad_scale'</span><span class="token punctuation">:</span> grad_scale<span class="token punctuation">,</span>              <span class="token string">'param_scale'</span><span class="token punctuation">:</span> param_scale<span class="token punctuation">,</span>              <span class="token string">'graph_vec_scale'</span><span class="token punctuation">:</span> graph_vec_scale<span class="token punctuation">,</span>              <span class="token string">'sim_pos'</span><span class="token punctuation">:</span> sim_pos<span class="token punctuation">,</span>              <span class="token string">'sim_neg'</span><span class="token punctuation">:</span> sim_neg<span class="token punctuation">,</span>              <span class="token string">'sim_diff'</span><span class="token punctuation">:</span> sim_pos <span class="token operator">-</span> sim_neg<span class="token punctuation">,</span>          <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>          <span class="token string">'validation'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>              <span class="token string">'pair_auc'</span><span class="token punctuation">:</span> pair_auc<span class="token punctuation">,</span>              <span class="token string">'triplet_acc'</span><span class="token punctuation">:</span> triplet_acc<span class="token punctuation">,</span>          <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>      <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;, placeholders, model</span></code></pre><h3 id="The-training-pipeline"><a href="#The-training-pipeline" class="headerlink" title="The training pipeline"></a>The training pipeline</h3><p>For this we need to build the datasets, handle <code>feed_dict</code>s and run some evaluation during training.</p><p>Note that this training pipeline is only supposed to be used as an example and you may want to add your own checkpointing or experiment monitoring tools (e.g. tensorboard).</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_datasets</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Build the training and evaluation datasets."""</span>  config <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>config<span class="token punctuation">)</span>  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'problem'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'graph_edit_distance'</span><span class="token punctuation">:</span>    dataset_params <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'dataset_params'</span><span class="token punctuation">]</span>    validation_dataset_size <span class="token operator">=</span> dataset_params<span class="token punctuation">[</span><span class="token string">'validation_dataset_size'</span><span class="token punctuation">]</span>    <span class="token keyword">del</span> dataset_params<span class="token punctuation">[</span><span class="token string">'validation_dataset_size'</span><span class="token punctuation">]</span>    training_set <span class="token operator">=</span> GraphEditDistanceDataset<span class="token punctuation">(</span><span class="token operator">**</span>dataset_params<span class="token punctuation">)</span>    dataset_params<span class="token punctuation">[</span><span class="token string">'dataset_size'</span><span class="token punctuation">]</span> <span class="token operator">=</span> validation_dataset_size    validation_set <span class="token operator">=</span> FixedGraphEditDistanceDataset<span class="token punctuation">(</span><span class="token operator">**</span>dataset_params<span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown problem type: %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'problem'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> training_set<span class="token punctuation">,</span> validation_set<span class="token keyword">def</span> <span class="token function">fill_feed_dict</span><span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Create a feed dict for the given batch of data.  Args:    placeholders: a dict of placeholders.    batch: a batch of data, should be either a single `GraphData` instance for      triplet training, or a tuple of (graphs, labels) for pairwise training.  Returns:    feed_dict: a feed_dict that can be used in a session run call.  """</span>  <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> GraphData<span class="token punctuation">)</span><span class="token punctuation">:</span>    graphs <span class="token operator">=</span> batch    labels <span class="token operator">=</span> None  <span class="token keyword">else</span><span class="token punctuation">:</span>    graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> batch  feed_dict <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>      placeholders<span class="token punctuation">[</span><span class="token string">'node_features'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>node_features<span class="token punctuation">,</span>      placeholders<span class="token punctuation">[</span><span class="token string">'edge_features'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>edge_features<span class="token punctuation">,</span>      placeholders<span class="token punctuation">[</span><span class="token string">'from_idx'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>from_idx<span class="token punctuation">,</span>      placeholders<span class="token punctuation">[</span><span class="token string">'to_idx'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>to_idx<span class="token punctuation">,</span>      placeholders<span class="token punctuation">[</span><span class="token string">'graph_idx'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>graph_idx<span class="token punctuation">,</span>  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>  <span class="token keyword">if</span> labels <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>    feed_dict<span class="token punctuation">[</span>placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels  <span class="token keyword">return</span> feed_dict<span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>sess<span class="token punctuation">,</span> eval_metrics<span class="token punctuation">,</span> placeholders<span class="token punctuation">,</span> validation_set<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Evaluate model performance on the given validation set.  Args:    sess: a `tf.Session` instance used to run the computation.    eval_metrics: a dict containing two tensors 'pair_auc' and 'triplet_acc'.    placeholders: a placeholder dict.    validation_set: a `GraphSimilarityDataset` instance, calling `pairs` and      `triplets` functions with `batch_size` creates iterators over a finite      sequence of batches to evaluate on.    batch_size: number of batches to use for each session run call.  Returns:    metrics: a dict of metric name => value mapping.  """</span>  accumulated_pair_auc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> batch <span class="token keyword">in</span> validation_set<span class="token punctuation">.</span>pairs<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    feed_dict <span class="token operator">=</span> fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>    pair_auc <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>eval_metrics<span class="token punctuation">[</span><span class="token string">'pair_auc'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>    accumulated_pair_auc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pair_auc<span class="token punctuation">)</span>  accumulated_triplet_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> batch <span class="token keyword">in</span> validation_set<span class="token punctuation">.</span>triplets<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>    feed_dict <span class="token operator">=</span> fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>    triplet_acc <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>eval_metrics<span class="token punctuation">[</span><span class="token string">'triplet_acc'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>    accumulated_triplet_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>triplet_acc<span class="token punctuation">)</span>  <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>      <span class="token string">'pair_auc'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>accumulated_pair_auc<span class="token punctuation">)</span><span class="token punctuation">,</span>      <span class="token string">'triplet_acc'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>accumulated_triplet_acc<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span></code></pre><h3 id="Let’s-run-it"><a href="#Let’s-run-it" class="headerlink" title="Let’s run it!"></a>Let’s run it!</h3><pre class=" language-python"><code class="language-python">config <span class="token operator">=</span> get_default_config<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Let's just run for a small number of training steps.  This may take you a few</span><span class="token comment" spellcheck="true"># minutes.</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'n_training_steps'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">5000</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Run this if you want to run the code again, otherwise tensorflow would</span><span class="token comment" spellcheck="true"># complain that you already created the same graph and the same variables.</span>tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Set random seeds</span>seed <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'seed'</span><span class="token punctuation">]</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>tf<span class="token punctuation">.</span>set_random_seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span>training_set<span class="token punctuation">,</span> validation_set <span class="token operator">=</span> build_datasets<span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'pair'</span><span class="token punctuation">:</span>  training_data_iter <span class="token operator">=</span> training_set<span class="token punctuation">.</span>pairs<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  first_batch_graphs<span class="token punctuation">,</span> _ <span class="token operator">=</span> next<span class="token punctuation">(</span>training_data_iter<span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>  training_data_iter <span class="token operator">=</span> training_set<span class="token punctuation">.</span>triplets<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  first_batch_graphs <span class="token operator">=</span> next<span class="token punctuation">(</span>training_data_iter<span class="token punctuation">)</span>node_feature_dim <span class="token operator">=</span> first_batch_graphs<span class="token punctuation">.</span>node_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>edge_feature_dim <span class="token operator">=</span> first_batch_graphs<span class="token punctuation">.</span>edge_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>tensors<span class="token punctuation">,</span> placeholders<span class="token punctuation">,</span> model <span class="token operator">=</span> build_model<span class="token punctuation">(</span>    config<span class="token punctuation">,</span> node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span>accumulated_metrics <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>t_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>init_ops <span class="token operator">=</span> <span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            tf<span class="token punctuation">.</span>local_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># If we already have a session instance, close it and start a new one</span><span class="token keyword">if</span> <span class="token string">'sess'</span> <span class="token keyword">in</span> globals<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># We will need to keep this session instance around for e.g. visualization.</span><span class="token comment" spellcheck="true"># But you should probably wrap it in a `with tf.Session() sess:` context if you</span><span class="token comment" spellcheck="true"># want to use the code elsewhere.</span>sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_ops<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># use xrange here if you are still on python 2</span><span class="token keyword">for</span> i_iter <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'n_training_steps'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  batch <span class="token operator">=</span> next<span class="token punctuation">(</span>training_data_iter<span class="token punctuation">)</span>  _<span class="token punctuation">,</span> train_metrics <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>      <span class="token punctuation">[</span>tensors<span class="token punctuation">[</span><span class="token string">'train_step'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tensors<span class="token punctuation">[</span><span class="token string">'metrics'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      feed_dict<span class="token operator">=</span>fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># accumulate over minibatches to reduce variance in the training metrics</span>  <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> train_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    accumulated_metrics<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>v<span class="token punctuation">)</span>  <span class="token keyword">if</span> <span class="token punctuation">(</span>i_iter <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'print_after'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>    metrics_to_print <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        k<span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> accumulated_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    info_str <span class="token operator">=</span> <span class="token string">', '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>        <span class="token punctuation">[</span><span class="token string">'%s %.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> metrics_to_print<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># reset the metrics</span>    accumulated_metrics <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>i_iter <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'print_after'</span><span class="token punctuation">]</span> <span class="token operator">%</span>        config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'eval_after'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      eval_metrics <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>          sess<span class="token punctuation">,</span> tensors<span class="token punctuation">[</span><span class="token string">'metrics'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'validation'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> placeholders<span class="token punctuation">,</span>          validation_set<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'evaluation'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      info_str <span class="token operator">+=</span> <span class="token string">', '</span> <span class="token operator">+</span> <span class="token string">', '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>          <span class="token punctuation">[</span><span class="token string">'%s %.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token string">'val/'</span> <span class="token operator">+</span> k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> eval_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter %d, %s, time %.2fs'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>        i_iter <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> info_str<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t_start<span class="token punctuation">)</span><span class="token punctuation">)</span>    t_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>iter 100, loss 0.9024, grad_scale 9.9039, param_scale 24.2281, graph_vec_scale 9.9295, sim_pos -0.5319, sim_neg -0.9309, sim_diff 0.3990, time 16.35siter 200, loss 0.8899, grad_scale 10.0000, param_scale 24.2434, graph_vec_scale 15.8820, sim_pos -0.5871, sim_neg -1.1029, sim_diff 0.5158, time 8.78siter 300, loss 0.9187, grad_scale 9.9720, param_scale 24.2605, graph_vec_scale 9.2189, sim_pos -0.5186, sim_neg -0.9006, sim_diff 0.3819, time 10.61siter 400, loss 0.8426, grad_scale 9.9700, param_scale 24.3224, graph_vec_scale 20.1333, sim_pos -0.5781, sim_neg -1.2868, sim_diff 0.7086, time 9.40siter 500, loss 0.8767, grad_scale 9.9918, param_scale 24.3770, graph_vec_scale 16.1800, sim_pos -0.6053, sim_neg -1.1185, sim_diff 0.5132, time 8.59siter 600, loss 0.8756, grad_scale 10.0000, param_scale 24.4452, graph_vec_scale 10.7137, sim_pos -0.5587, sim_neg -1.0466, sim_diff 0.4879, time 8.54siter 700, loss 0.8455, grad_scale 10.0000, param_scale 24.5081, graph_vec_scale 6.1303, sim_pos -0.6762, sim_neg -1.2543, sim_diff 0.5781, time 9.26siter 800, loss 0.8545, grad_scale 10.0000, param_scale 24.5715, graph_vec_scale 7.7584, sim_pos -0.6751, sim_neg -1.2628, sim_diff 0.5877, time 9.35siter 900, loss 0.8324, grad_scale 9.9734, param_scale 24.6531, graph_vec_scale 11.4416, sim_pos -0.6053, sim_neg -1.2179, sim_diff 0.6126, time 10.77siter 1000, loss 0.8502, grad_scale 10.0000, param_scale 24.7729, graph_vec_scale 21.2052, sim_pos -0.6276, sim_neg -1.1885, sim_diff 0.5610, val/pair_auc 0.6311, val/triplet_acc 0.6560, time 23.40siter 1100, loss 0.8568, grad_scale 10.0000, param_scale 24.9137, graph_vec_scale 9.9548, sim_pos -0.6038, sim_neg -1.1830, sim_diff 0.5791, time 9.38siter 1200, loss 0.8258, grad_scale 10.0000, param_scale 25.0311, graph_vec_scale 9.8263, sim_pos -0.6863, sim_neg -1.2977, sim_diff 0.6114, time 10.48siter 1300, loss 0.8167, grad_scale 10.0000, param_scale 25.1117, graph_vec_scale 7.9998, sim_pos -0.6577, sim_neg -1.2564, sim_diff 0.5987, time 9.64siter 1400, loss 0.8393, grad_scale 10.0000, param_scale 25.2091, graph_vec_scale 9.4814, sim_pos -0.6692, sim_neg -1.2338, sim_diff 0.5645, time 9.88siter 1500, loss 0.8124, grad_scale 10.0000, param_scale 25.3498, graph_vec_scale 10.8970, sim_pos -0.6629, sim_neg -1.2851, sim_diff 0.6222, time 10.24siter 1600, loss 0.7997, grad_scale 10.0000, param_scale 25.5068, graph_vec_scale 8.8850, sim_pos -0.6958, sim_neg -1.3773, sim_diff 0.6816, time 10.23siter 1700, loss 0.8036, grad_scale 10.0000, param_scale 25.6802, graph_vec_scale 9.1888, sim_pos -0.7241, sim_neg -1.3902, sim_diff 0.6660, time 10.28siter 1800, loss 0.8282, grad_scale 9.9726, param_scale 25.8778, graph_vec_scale 16.0597, sim_pos -0.7033, sim_neg -1.3089, sim_diff 0.6056, time 10.52siter 1900, loss 0.8561, grad_scale 9.9528, param_scale 26.1749, graph_vec_scale 16.8173, sim_pos -0.5827, sim_neg -1.1226, sim_diff 0.5399, time 11.16siter 2000, loss 0.8543, grad_scale 10.0000, param_scale 26.4489, graph_vec_scale 9.4414, sim_pos -0.6694, sim_neg -1.1820, sim_diff 0.5126, val/pair_auc 0.6423, val/triplet_acc 0.7120, time 15.30siter 2100, loss 0.8282, grad_scale 10.0000, param_scale 26.5936, graph_vec_scale 8.2912, sim_pos -0.6784, sim_neg -1.2598, sim_diff 0.5814, time 12.57siter 2200, loss 0.8040, grad_scale 10.0000, param_scale 26.8179, graph_vec_scale 8.7340, sim_pos -0.7254, sim_neg -1.3695, sim_diff 0.6441, time 10.05siter 2300, loss 0.8089, grad_scale 10.0000, param_scale 27.0014, graph_vec_scale 4.7856, sim_pos -0.7325, sim_neg -1.3514, sim_diff 0.6189, time 10.36siter 2400, loss 0.7894, grad_scale 10.0000, param_scale 27.1475, graph_vec_scale 5.3897, sim_pos -0.7178, sim_neg -1.3501, sim_diff 0.6323, time 10.36siter 2500, loss 0.8112, grad_scale 10.0000, param_scale 27.3124, graph_vec_scale 5.0839, sim_pos -0.7920, sim_neg -1.4146, sim_diff 0.6226, time 10.70siter 2600, loss 0.7852, grad_scale 10.0000, param_scale 27.5082, graph_vec_scale 3.7201, sim_pos -0.7722, sim_neg -1.5174, sim_diff 0.7452, time 10.81siter 2700, loss 0.7873, grad_scale 10.0000, param_scale 27.6644, graph_vec_scale 3.7121, sim_pos -0.7612, sim_neg -1.4150, sim_diff 0.6538, time 10.88siter 2800, loss 0.7846, grad_scale 10.0000, param_scale 27.8754, graph_vec_scale 4.0826, sim_pos -0.7242, sim_neg -1.3944, sim_diff 0.6703, time 9.64siter 2900, loss 0.7984, grad_scale 10.0000, param_scale 28.0754, graph_vec_scale 3.3628, sim_pos -0.7275, sim_neg -1.3811, sim_diff 0.6536, time 10.04siter 3000, loss 0.8040, grad_scale 10.0000, param_scale 28.2285, graph_vec_scale 4.7665, sim_pos -0.8204, sim_neg -1.4319, sim_diff 0.6115, val/pair_auc 0.6521, val/triplet_acc 0.7020, time 14.91siter 3100, loss 0.7661, grad_scale 10.0000, param_scale 28.4321, graph_vec_scale 4.5367, sim_pos -0.7861, sim_neg -1.5052, sim_diff 0.7192, time 12.70siter 3200, loss 0.7918, grad_scale 10.0000, param_scale 28.6223, graph_vec_scale 2.7951, sim_pos -0.7894, sim_neg -1.4368, sim_diff 0.6474, time 10.14siter 3300, loss 0.7888, grad_scale 10.0000, param_scale 28.7832, graph_vec_scale 2.5365, sim_pos -0.7737, sim_neg -1.4076, sim_diff 0.6339, time 11.14siter 3400, loss 0.7880, grad_scale 10.0000, param_scale 28.9723, graph_vec_scale 2.5840, sim_pos -0.8405, sim_neg -1.4963, sim_diff 0.6558, time 10.99siter 3500, loss 0.8063, grad_scale 10.0000, param_scale 29.1109, graph_vec_scale 1.5241, sim_pos -0.7049, sim_neg -1.3258, sim_diff 0.6209, time 10.09siter 3600, loss 0.7781, grad_scale 10.0000, param_scale 29.2500, graph_vec_scale 1.6339, sim_pos -0.8011, sim_neg -1.5460, sim_diff 0.7448, time 10.25siter 3700, loss 0.7626, grad_scale 10.0000, param_scale 29.3812, graph_vec_scale 2.0334, sim_pos -0.7765, sim_neg -1.5622, sim_diff 0.7857, time 11.35siter 3800, loss 0.7545, grad_scale 10.0000, param_scale 29.5007, graph_vec_scale 1.9816, sim_pos -0.7494, sim_neg -1.5253, sim_diff 0.7759, time 10.50siter 3900, loss 0.7786, grad_scale 10.0000, param_scale 29.6472, graph_vec_scale 2.2622, sim_pos -0.8190, sim_neg -1.5184, sim_diff 0.6994, time 10.94siter 4000, loss 0.7696, grad_scale 10.0000, param_scale 29.7945, graph_vec_scale 1.9066, sim_pos -0.7080, sim_neg -1.4729, sim_diff 0.7649, val/pair_auc 0.6588, val/triplet_acc 0.7110, time 15.44siter 4100, loss 0.7702, grad_scale 10.0000, param_scale 29.9186, graph_vec_scale 1.6492, sim_pos -0.7923, sim_neg -1.5920, sim_diff 0.7998, time 11.56siter 4200, loss 0.7618, grad_scale 10.0000, param_scale 30.0597, graph_vec_scale 1.3295, sim_pos -0.8183, sim_neg -1.5480, sim_diff 0.7297, time 12.56siter 4300, loss 0.7595, grad_scale 10.0000, param_scale 30.2331, graph_vec_scale 2.0479, sim_pos -0.8513, sim_neg -1.5582, sim_diff 0.7069, time 9.82siter 4400, loss 0.7722, grad_scale 10.0000, param_scale 30.3986, graph_vec_scale 1.1744, sim_pos -0.7996, sim_neg -1.4669, sim_diff 0.6674, time 10.90siter 4500, loss 0.7850, grad_scale 10.0000, param_scale 30.5059, graph_vec_scale 1.7279, sim_pos -0.8477, sim_neg -1.5368, sim_diff 0.6891, time 11.18siter 4600, loss 0.7562, grad_scale 10.0000, param_scale 30.6486, graph_vec_scale 1.4266, sim_pos -0.7782, sim_neg -1.5346, sim_diff 0.7564, time 10.92siter 4700, loss 0.7843, grad_scale 10.0000, param_scale 30.8270, graph_vec_scale 2.1109, sim_pos -0.7923, sim_neg -1.4582, sim_diff 0.6660, time 11.00siter 4800, loss 0.7712, grad_scale 10.0000, param_scale 30.9745, graph_vec_scale 1.9060, sim_pos -0.8056, sim_neg -1.4885, sim_diff 0.6830, time 11.01siter 4900, loss 0.7894, grad_scale 10.0000, param_scale 31.1943, graph_vec_scale 1.5744, sim_pos -0.7436, sim_neg -1.3567, sim_diff 0.6131, time 10.39siter 5000, loss 0.7866, grad_scale 10.0000, param_scale 31.4067, graph_vec_scale 1.4950, sim_pos -0.7812, sim_neg -1.4002, sim_diff 0.6190, val/pair_auc 0.6675, val/triplet_acc 0.7490, time 15.01s</code></pre><p>Note that albeit a bit noisy, the loss is going down, the similarity gap<br>between positive and negative pairs are growing and the evaluation results, i.e. pair AUC and triplet accuracies are going up as well.  Overall training seems to be working!</p><p>You can train this much longer.  We observed improvement in performance even after training for 500,000 steps, but didn’t push this much further as it is a synthetic task after all.</p><h2 id="Test-the-model-and-create-some-visualizations"><a href="#Test-the-model-and-create-some-visualizations" class="headerlink" title="Test the model and create some visualizations"></a>Test the model and create some visualizations</h2><p>Once the model is trained, we can test in on unseen data.  Our graph matching networks use cross-graph matching-based attention to compute graph similarity, we can visualize these attention weights to see where the model is attending to.</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># visualize on graphs of 10 nodes, bigger graphs become more difficult to</span><span class="token comment" spellcheck="true"># visualize</span>vis_dataset <span class="token operator">=</span> GraphEditDistanceDataset<span class="token punctuation">(</span>    <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> permute<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>pair_iter <span class="token operator">=</span> vis_dataset<span class="token punctuation">.</span>pairs<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> next<span class="token punctuation">(</span>pair_iter<span class="token punctuation">)</span></code></pre><p>Let’s split the batched graphs into individual graphs and visualize them first.</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">split_graphs</span><span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Split a batch of graphs into individual `nx.Graph` instances."""</span>  g <span class="token operator">=</span> <span class="token punctuation">[</span>nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>n_graphs<span class="token punctuation">)</span><span class="token punctuation">]</span>  node_ids <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>graph_idx<span class="token punctuation">.</span>size<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>n_graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>    nodes_in_graph <span class="token operator">=</span> node_ids<span class="token punctuation">[</span>graphs<span class="token punctuation">.</span>graph_idx <span class="token operator">==</span> i<span class="token punctuation">]</span>    n_nodes <span class="token operator">=</span> len<span class="token punctuation">(</span>nodes_in_graph<span class="token punctuation">)</span>    g<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n_nodes<span class="token punctuation">)</span><span class="token punctuation">)</span>    node_id_min <span class="token operator">=</span> nodes_in_graph<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span>    node_id_max <span class="token operator">=</span> nodes_in_graph<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>    edges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> u<span class="token punctuation">,</span> v <span class="token keyword">in</span> zip<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>from_idx<span class="token punctuation">,</span> graphs<span class="token punctuation">.</span>to_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">if</span> node_id_min <span class="token operator">&lt;=</span> u <span class="token operator">&lt;=</span> node_id_max <span class="token operator">and</span> node_id_min <span class="token operator">&lt;=</span> v <span class="token operator">&lt;=</span> node_id_max<span class="token punctuation">:</span>        edges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>u <span class="token operator">-</span> node_id_min<span class="token punctuation">,</span> v <span class="token operator">-</span> node_id_min<span class="token punctuation">)</span><span class="token punctuation">)</span>    g<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>edges<span class="token punctuation">)</span>  <span class="token keyword">return</span> g</code></pre><pre class=" language-python"><code class="language-python">nx_graphs <span class="token operator">=</span> split_graphs<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>nx_graphs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  label <span class="token operator">=</span> labels<span class="token punctuation">[</span>i <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">]</span>  g1 <span class="token operator">=</span> nx_graphs<span class="token punctuation">[</span>i<span class="token punctuation">]</span>  g2 <span class="token operator">=</span> nx_graphs<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>  plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Compute the positions of graphs first to make sure the visualizations are</span>  <span class="token comment" spellcheck="true"># consistent.</span>  pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>drawing<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>g1<span class="token punctuation">)</span>  nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>g1<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>  ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Graph 1'</span><span class="token punctuation">)</span>  ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>  ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>  nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>g2<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>  ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Graph 2'</span><span class="token punctuation">)</span>  ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span></code></pre><p><img src="output_55_0.png" alt="png"></p><p><img src="output_55_1.png" alt="png"></p><p>Build the computation graph for visualization.</p><pre class=" language-python"><code class="language-python">n_graphs <span class="token operator">=</span> graphs<span class="token punctuation">.</span>n_graphsmodel_inputs <span class="token operator">=</span> placeholders<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">del</span> model_inputs<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>graph_vectors <span class="token operator">=</span> model<span class="token punctuation">(</span>n_graphs<span class="token operator">=</span>n_graphs<span class="token punctuation">,</span> <span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>x<span class="token punctuation">,</span> y <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>graph_vectors<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>similarity <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>layer_outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>get_layer_outputs<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_matchings</span><span class="token punctuation">(</span>layer_outputs<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span> sim<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Build the matching attention matrices from layer outputs."""</span>  <span class="token keyword">assert</span> n_graphs <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span>  attention <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> h <span class="token keyword">in</span> layer_outputs<span class="token punctuation">:</span>    partitions <span class="token operator">=</span> tf<span class="token punctuation">.</span>dynamic_partition<span class="token punctuation">(</span>h<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span>    attention_in_layer <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      x <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i<span class="token punctuation">]</span>      y <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>      a <span class="token operator">=</span> sim<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>      a_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># i->j</span>      a_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># j->i</span>      attention_in_layer<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>a_x<span class="token punctuation">,</span> a_y<span class="token punctuation">)</span><span class="token punctuation">)</span>    attention<span class="token punctuation">.</span>append<span class="token punctuation">(</span>attention_in_layer<span class="token punctuation">)</span>  <span class="token keyword">return</span> attention</code></pre><pre class=" language-python"><code class="language-python">attentions <span class="token operator">=</span> build_matchings<span class="token punctuation">(</span>    layer_outputs<span class="token punctuation">,</span> placeholders<span class="token punctuation">[</span><span class="token string">'graph_idx'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span>    get_pairwise_similarity<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'graph_matching_net'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'similarity'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python">sim<span class="token punctuation">,</span> a <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>similarity<span class="token punctuation">,</span> attentions<span class="token punctuation">]</span><span class="token punctuation">,</span>                  feed_dict<span class="token operator">=</span>fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> <span class="token punctuation">(</span>graphs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>sim<span class="token punctuation">)</span></code></pre><pre><code>[ 1 -1][-0.19060427 -2.23995686]</code></pre><p>Similarity for positive pair is much higher than the similarity for the negative pair.</p><p>Remember that with a margin loss and Euclidean distance, which is how this model is trained, the similarity value is the negative distance.  In this case the distance for positive pair is quite small, while the distance between two graphs in the negative pair is large.</p><h3 id="Some-tools-for-visualizing-attention"><a href="#Some-tools-for-visualizing-attention" class="headerlink" title="Some tools for visualizing attention"></a>Some tools for visualizing attention</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_plot_graph_matching_on_axis</span><span class="token punctuation">(</span>ax<span class="token punctuation">,</span> g_base<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> att<span class="token punctuation">,</span> title<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Plot graph matching on an axis."""</span>  original_edges <span class="token operator">=</span> g_base<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span>  g <span class="token operator">=</span> g_base<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>  n1<span class="token punctuation">,</span> n2 <span class="token operator">=</span> att<span class="token punctuation">.</span>shape  alpha <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  att_edges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n1<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>n2<span class="token punctuation">)</span><span class="token punctuation">:</span>      g<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j <span class="token operator">+</span> n1<span class="token punctuation">)</span>      att_edges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> j <span class="token operator">+</span> n1<span class="token punctuation">)</span><span class="token punctuation">)</span>      alpha<span class="token punctuation">.</span>append<span class="token punctuation">(</span>att<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>  nx<span class="token punctuation">.</span>draw_networkx_nodes<span class="token punctuation">(</span>      g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> nodelist<span class="token operator">=</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">)</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'lavender'</span><span class="token punctuation">,</span> linewidths<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>  nx<span class="token punctuation">.</span>draw_networkx_nodes<span class="token punctuation">(</span>      g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> nodelist<span class="token operator">=</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">,</span> n1 <span class="token operator">+</span> n2<span class="token punctuation">)</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'wheat'</span><span class="token punctuation">,</span> linewidths<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>      ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>  nx<span class="token punctuation">.</span>draw_networkx_edges<span class="token punctuation">(</span>      g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> edgelist<span class="token operator">=</span>original_edges<span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>att_edges<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    nx<span class="token punctuation">.</span>draw_networkx_edges<span class="token punctuation">(</span>        g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> edgelist<span class="token operator">=</span>att_edges<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'g'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span>alpha<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>        ax<span class="token operator">=</span>ax<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>  ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>  <span class="token keyword">if</span> title<span class="token punctuation">:</span>    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># set xlim and ylim</span>  coords <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>list<span class="token punctuation">(</span>pos<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>  x_min<span class="token punctuation">,</span> y_min <span class="token operator">=</span> coords<span class="token punctuation">.</span>min<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  x_max<span class="token punctuation">,</span> y_max <span class="token operator">=</span> coords<span class="token punctuation">.</span>max<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  x_len <span class="token operator">=</span> x_max <span class="token operator">-</span> x_min  y_len <span class="token operator">=</span> y_max <span class="token operator">-</span> y_min  ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span>x_min <span class="token operator">-</span> x_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">,</span> x_max <span class="token operator">+</span> x_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span>y_min <span class="token operator">-</span> y_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">,</span> y_max <span class="token operator">+</span> y_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_graph_matching_pair</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> matchings<span class="token punctuation">,</span> pos<span class="token operator">=</span>None<span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token triple-quoted-string string">"""Plot a pair of graphs and the matchings between them.  Args:    g1: a networkx graph.    g2: a networkx graph.    matchings: a pair of n1 x n2 matrices.    pos: a position dictionary, if provided.  Returns:    pos: position dictionary, used for other plots between these two graphs.  """</span>  n1 <span class="token operator">=</span> g1<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>  n2 <span class="token operator">=</span> g2<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token keyword">assert</span> n1 <span class="token operator">>=</span> n2  <span class="token keyword">if</span> pos <span class="token keyword">is</span> None<span class="token punctuation">:</span>    <span class="token keyword">with</span> reset_random_state<span class="token punctuation">(</span>seed<span class="token operator">=</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>      pos1 <span class="token operator">=</span> nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>g1<span class="token punctuation">)</span>    pos1_values <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>list<span class="token punctuation">(</span>pos1<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>    pos1_values <span class="token operator">-=</span> pos1_values<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    pos2_values <span class="token operator">=</span> pos1_values<span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>        pos1_values<span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">-</span>        pos1_values<span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    pos <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;k: pos1_values[k] for k in pos1.keys()&amp;#125;</span>    pos<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;(k + n2): pos2_values[k-(n1-n2)]</span>                <span class="token keyword">for</span> k <span class="token keyword">in</span> list<span class="token punctuation">(</span>pos1<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>  g_base <span class="token operator">=</span> nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>  g_base<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">)</span><span class="token punctuation">)</span>  g_base<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">,</span> n1 <span class="token operator">+</span> n2<span class="token punctuation">)</span><span class="token punctuation">)</span>  g_base<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>g1<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  g_base<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> n1<span class="token punctuation">,</span> j <span class="token operator">+</span> n1<span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> g2<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">11.2</span><span class="token punctuation">,</span> <span class="token number">4.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  _plot_graph_matching_on_axis<span class="token punctuation">(</span>      ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> g_base<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> matchings<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'left attend to right'</span><span class="token punctuation">)</span>  _plot_graph_matching_on_axis<span class="token punctuation">(</span>      ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> g_base<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> matchings<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'right attend to left'</span><span class="token punctuation">)</span>  fig<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> h_pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> w_pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token keyword">return</span> pos</code></pre><h3 id="Visualize-how-the-attention-pattern-changes-across-layers"><a href="#Visualize-how-the-attention-pattern-changes-across-layers" class="headerlink" title="Visualize how the attention pattern changes across layers"></a>Visualize how the attention pattern changes across layers</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># visualize the attention across layers for the positive pair</span>plt<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token string">'all'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  _ <span class="token operator">=</span> plot_graph_matching_pair<span class="token punctuation">(</span>nx_graphs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nx_graphs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p><img src="output_66_0.png" alt="png"></p><p><img src="output_66_1.png" alt="png"></p><p><img src="output_66_2.png" alt="png"></p><p><img src="output_66_3.png" alt="png"></p><p><img src="output_66_4.png" alt="png"></p><p><img src="output_66_5.png" alt="png"></p><p>Note that the left-to-right and right-to-left attention patterns are slightly different.  Also the attention pattern starts almost uniform, and then gets more concentrated after a few layers.</p><p>If we train the model for longer, we can see a clearer matching pattern.</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># negative pair</span>plt<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token string">'all'</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  _ <span class="token operator">=</span> plot_graph_matching_pair<span class="token punctuation">(</span>nx_graphs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nx_graphs<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><p><img src="output_68_0.png" alt="png"></p><p><img src="output_68_1.png" alt="png"></p><p><img src="output_68_2.png" alt="png"></p><p><img src="output_68_3.png" alt="png"></p><p><img src="output_68_4.png" alt="png"></p><p><img src="output_68_5.png" alt="png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文学习 </tag>
            
            <tag> 图神经网络 </tag>
            
            <tag> 论文复现 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GMN</title>
      <link href="/2021/01/15/gmn/"/>
      <url>/2021/01/15/gmn/</url>
      
        <content type="html"><![CDATA[<h1 id="Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects"><a href="#Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects" class="headerlink" title="Graph Matching Networks for Learning the Similarity of Graph Structured Objects"></a>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</h1><p><strong>摘 要：</strong> 本文复现了DeepMind于2019年发表在PRML会议上的Graph Matching Networks for Learning the Similarity of Graph Structured Objects一文，该论文解决了图结构对象的检索和匹配这一具有挑战性的问题，并做出了两个关键贡献。首先，论文演示如何训练图神经网络（GNN），它已成为针对结构化数据定义的各种监督预测问题的有效模型，可以训练它们在向量空间中嵌入图数据从而实现有效的相似性推理。其次，论文提出了一种新颖的图匹配网络模型，该模型在给定一对图作为输入的情况下，通过共同推理来计算它们之间的相似度得分。通过基于注意力机制的新跨图匹配机制进行配对，论文展示了其模型在不同领域的有效性，包括基于控制流图的功能相似性搜索这一具有挑战性的问题，该问题在检测软件系统中的漏洞中起着重要作用。实验分析表明，改论文所提出的图匹配模型不仅可以在相似性学习的背景下利用结构，而且还可以胜过为解决这些问题而精心设计的特定领域基准系统。</p><p><strong>关键词：</strong>图神经网络；相似性计算；图嵌入；深度学习</p><p><strong>Research on TikTok Competitiveness Based on Fuzzy Multi-level Evaluation Method</strong></p><p><strong>Abstract:</strong> This article reproduces the article Graph Matching Networks for Learning the Similarity of Graph Structured Objects published by DeepMind at the PRML conference in 2019. This paper solves the challenging problem of retrieval and matching of graph structure objects, and makes Two key contributions. First, the paper demonstrates how to train graph neural network (GNN), which has become an effective model for various supervised prediction problems defined by structured data. They can be trained to embed graph data in vector space to achieve effective similarity inference. Secondly, the paper proposes a novel graph matching network model, which, given a pair of graphs as input, calculates the similarity score between them through common inference. Through the new cross-graph matching mechanism based on the attention mechanism for pairing, the paper demonstrated the effectiveness of its model in different fields, including the challenging problem of functional similarity search based on control flow graphs, which is in the detection of software systems Plays an important role in the loopholes in the. Experimental analysis shows that the graph matching model proposed in this paper can not only use the structure in the context of similarity learning, but also can outperform the domain-specific benchmark system carefully designed to solve these problems.</p><p><strong>Key words:</strong> Graph neural network; similarity calculation; graph embedding; deep learning</p><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1</strong> <strong>引言</strong></h2><p>现实的人类世界正如同一个整体的复杂系统，系统中无时不存在着人与人、组织与组织之间的联系与交互，而图网络的表示形式自然的契合了现实世界的此类特点，图网络中的节点及节点的属性表示真实世界的实体和实体的属性标签，节点间的连边表示了实体间的客观联系与交互，因此，利用图网络来研究和表示真实世界中的系统性问题具有合理性及可行性。图是用于编码在许多领域中遇到的关系结构的自然表示。Gilmer等人曾于2017计算在图结构化数据上定义的定义广泛用于从计算生物学和化学分子分析到知识图或图结构化解析的各种领域了解自然语言。</p><p>在过去的几年中，图神经网络（GNN）已经成为一类有效的模型，用于学习结构化数据的表示形式和解决图上的各种监督预测问题。这样的模型通过设计并通过迭代聚合局部结构信息的传播过程来计算图节点表示形式，从而不变于图元素的排列（Scarselli等，2009; Li等，2015; Gilmer等，2017）。这些节点表示然后直接用于节点分类，或合并到图形向量中进行图形分类，监督分类或回归之外的问题对于GNN的研究相对较少。DeppMind所发表的此篇论文研究了图结构化对象的相似性学习问题，这种问题出现在许多重要的现实应用中，尤其是在图数据库中基于相似性的检索中。一个有启发性的应用是二进制功能相似性搜索的计算机安全问题，其中给定一个二进制文件，该二进制文件可能包含或可能不包含具有已知漏洞的代码，我们希望检查该二进制文件中的任何控制流图是否都与该数据库的相似性足够。这有助于确定封闭源软件中易受攻击的静态链接库，这是一个经常发生的问题（CVE，2010；2018），目前尚无良好的解决方案。这种相似性学习问题极具挑战性，因为细微的差异会使两个图在语义上非常不同，而具有不同结构的图仍可能相似。因此，针对此问题的成功模型应该（1）利用图结构，并且（2）能够从图结构以及学习的语义中推断出图的相似性。</p><p>​    为了解决上述两个研究问题，改论文提出了两种解决方法，其一为利用GNNs模型解决图的嵌入问题，为了解决图的相似性学习问题，作者研究了GNNs在这种情况下的使用，探索它们如何被用来将图嵌入到向量空间中，并学习这种嵌入模型来使相似的图在向量空间中接近，而不相似的图远离。该模型的一个重要特性是，它将每个图独立地映射到一个嵌入向量，然后所有的相似度计算都在向量空间中进行。这种方法的好处是如果需要对数据库中大量的图进行比较的时候，只需要对数据库中图的这些embedding进行比较，可以利用已有的一些算法快速得到匹配，比如k-d trees、locality sensitive hashing。另外论文针对跨图间的相似性计算问题提出了GMN模型，该模型可作为对GNN模型的一种扩展模型，我们将其称为图匹配网络（GMN）以进行相似性学习。GMN通过跨图关注机制来计算跨图的节点并识别差异，而不是为每个图独立地计算图表示。</p><p>​    因此，基于以上介绍该论文的主要贡献有三点：（1）证明了GNNs可以用来生成图嵌入，用于图相似度学习；（2）提出了图匹配网络（Graph Matching Networks），可以通过交叉图注意力匹配来进行计算相似度；（3）实验表明相似度学习模型可以在一系列应用上实现好的性能。</p><h2 id="2-模型"><a href="#2-模型" class="headerlink" title="2 模型"></a><strong>2</strong> <strong>模型</strong></h2><p>本文提出了Graph Embedding Model和Graph Matching Network两个模型，分别如下图左边和右边。</p><p>​           <img src="image-20210115223227679.png">                    </p><p>​                                                 <strong>图</strong> <strong>1</strong> <strong>图嵌入图（左）和匹配模型图（右）</strong></p><h3 id="2-1-Graph-Embedding-Model"><a href="#2-1-Graph-Embedding-Model" class="headerlink" title="2.1 Graph Embedding Model"></a><strong>2.1 Graph Embedding Model</strong></h3><p>​    图嵌入模型主要基于GNN来提取图上的信息，然后通过若干轮，在图上相邻节点之间交换信息，然后再把所有节点上的信息聚合产生关于这个图的整体embedding。分为三步Encoder、Propagation Layers和Aggregator。其主要思路是用传统GNN把全图表征成一个向量，然后利用图的向量来计算图与图之间的相似性，模型由：编码层、传播层、聚合层构成。</p><p>（1）Encoder</p><p>​    对图上每一个节点和每一条边的特征进行编码，如果节点或者边没有更多额外能利用的信息的话，它们的原始特征可以设置为常数1，即Xi= 1 , Xij = 1 。其中Xi、Xij分别代表节点和边的特征，相应的MLP编码器就是简单的一个隐含层的神经网络。</p><p> <img src="image-20210115223320434.png"></p><p>（2）Propagation Layers</p><p>​    第二步是在图上进行多轮的信息传播。每轮中，每条连边都通过一个神经网络生成一个message，每个节点都接受来自相邻节点的message并且形成新的节点表示。将相邻节点信息汇聚到中间节点可以使用均值、最大值和注意力等方法。</p><p> <img src="image-20210115223351579.png"></p><p>（3）Aggregator</p><p>​    第三步是把得到的节点表示都聚合起来，形成关于整个图的embedding。转换节点表示，然后使用带有门控向量的加权和在节点之间进行聚合。加权和可以帮助过滤掉不相关的信息，它比简单的和功能更强大，在经验上也有显著的提高。</p><p> <img src="image-20210115223413591.png"></p><h3 id="2-2-Graph-Matching-Network"><a href="#2-2-Graph-Matching-Network" class="headerlink" title="2.2 Graph Matching Network"></a><strong>2.2 Graph Matching Network</strong></h3><p>​    该模型在第一步和第三步都和前一种模型相同，最主要的区别是第二步在message passing的过程</p><p>中会在两个图之间传递信息，每个节点都会去尽量匹配另一个图中的相似节点，并且产生图之间的信息传递。图匹配网络将一对图作为输入并计算它们之间的相似度得分。与嵌入模型相比，这些匹配模型在该对上共同计算相似性得分，而不是先将每个图独立映射到向量。因此，这些模型可能比嵌入模型更强大，但代价是一些额外的计算效率。</p><p>​    论文提出了以下图匹配网络，该图更改了每个传播层中的节点更新模块，不仅像以前一样考虑了每个图边缘上的聚合消息，而且还考虑了一个跨图匹配向量，该向量可以测量节点的性能即一个图中的一个可以与另一个图中的一个或多个节点匹配：</p><p> <img src="image-20210115223443207.png"></p><p> <img src="image-20210115223504833.png"></p><p>​    最关键的是 fmatch，即如何产生两个图之间的匹配并且在图之间传递信息，GMN的传播层就是增加了注意力机制后的传播层，fmatch做的就是跨图信息的计算，attention公式如下：</p><p> <img src="image-20210115223540126.png"></p><p>​    与嵌入模型相比，这些匹配模型联合计算对上的相似度评分，而不是首先独立地将每个图映射到一个向量。提出的模型不仅仅考虑单个图中的边的信息聚合，而且考虑一个图中的一个顶点与另一个图的其他顶点的匹配度向量。</p><p> <img src="image-20210115223554929.png"></p><h2 id="3-模型训练与损失函数"><a href="#3-模型训练与损失函数" class="headerlink" title="3 模型训练与损失函数"></a><strong>3</strong> <strong>模型训练与损失函数</strong></h2><p>​    图相似度模型可以在一对图和一组三个图上训练，损失函数有二元组和三元组，其都被设置在[0,1]范围内(由于图空间太大，所以如果将最后图的表示用一个二值向量会更加高效)，二元组构建了相同和不同的图对，相同图对的label=1，不同的label=-1，三元组的存了3个graph，在loss设计上将模型引导为拉近G1、G2的距离，拉远G1、G3之间的距离。在作者的实验中使用二元组或三元组的精度相似。</p><p> <img src="image-20210115223616809.png"></p><p>（1）成对数据（G1，G2，t），t为标签</p><p> <img src="image-20210115223629323.png"></p><p>（2）三元输入数据（G1，G2，G3）</p><p>​    G1与G2之间的相似度小于G1与G3，这个loss 约束<br>$$<br>d(G_1,G_2 )+γ&lt;d(G_1,G_3 )<br>$$<br> 用汉明距离作为距离度量，其约束目标为最小化positive pairs，最大化negative pairs。</p><h2 id="4-实验结果"><a href="#4-实验结果" class="headerlink" title="4 实验结果"></a><strong>4</strong> <strong>实验结果</strong></h2><h3 id="4-1-训练步骤"><a href="#4-1-训练步骤" class="headerlink" title="4.1 训练步骤"></a><strong>4.1</strong> <strong>训练步骤</strong></h3><p>​    我们通过对具有n个节点和随机链接概率p的随机二项式图G1进行采样来生成训练数据（(Erdös &amp; Rényi, 1959），然后通过以随机概率kp替换G1中的连边来创建正样本G2，以随机概率kn替换G1中的连边从而构建负样本G3，其中kp &lt;kn。 模型需要预测正样本对（G1、G2）比负样本对（G1、G3）具有更高的相似性评分。在整个实验中，我们无需进一步调整即可将节点矢量的维数固定为32，将图形矢量的维数固定为128。我们还尝试了从1到5的不同数量的传播步骤T，并且观察到随着T的增加性能也会随之提升，故在后续的实验中我们将T设置为5.</p><p> <img src="image-20210115223712195.png"></p><p> <img src="image-20210115223726702.png"></p><h3 id="4-2-Baseline"><a href="#4-2-Baseline" class="headerlink" title="4.2 Baseline"></a><strong>4.2 Baseline</strong></h3><p>​    我们将模型与流行的Weisfeiler Lehman（WL）内核（Shervashidze等人，2011）进行了比较，事实证明，该模型在图分类任务上具有很强的竞争力，而该内核背后的Weisfeiler Lehman算法是一种检查图同构的强大方法（编辑距离为0），这是一个紧密相关的任务（Weisfeiler＆Lehman，1968; Shervashidze 等人，2011）。</p><h3 id="4-3-评估"><a href="#4-3-评估" class="headerlink" title="4.3 评估"></a><strong>4.3</strong> <strong>评估</strong></h3><p>​    使用两个指标来评估不同模型的性能：（1）对AUC-ROC曲线下的区域，用于将图对在固定的1000对上分类为相似或不相似，（2）三元精度，在固定的1000个三元组上，三元组中的正对比负对具有更高的相似性。</p><p> <img src="image-20210115223741824.png"></p><h3 id="4-4-模型参数设置"><a href="#4-4-模型参数设置" class="headerlink" title="4.4 模型参数设置"></a><strong>4.4</strong> <strong>模型参数设置</strong></h3><p>（1）Embedding_net</p><p> <img src="image-20210115223755771.png"></p><p>（2）graph_matching_net</p><p> <img src="image-20210115223808558.png"></p><h3 id="4-5-实验结果"><a href="#4-5-实验结果" class="headerlink" title="4.5 实验结果"></a><strong>4.5</strong> <strong>实验结果</strong></h3><p>​    实证结果表现，在具有不同初始值n，p及kp = 1和kn = 2固定的一些特定分布图上训练和评估了GSL模型。评估结果如表所示。我们可以看到，通过学习特定分布图，GSL模型能够比通用基线做得更好，并且GMN始终优于嵌入模型（GNN）。因为我们正在学习相似性度量标准，而不是进行同构测试，因此我们的模型可以比学习的WL内核做得更好。</p><p>​    对于GMN模型，我们可以可视化交叉图注意力机制以进一步了解其工作方式。 下图显示了一个针对匹配模型的两个示例，该模型在n∈[20; 50]的图上进行训练，并在n=10的图上进行了测试。交叉图注意力权重以绿色显示，权重的比例显示为绿色边缘的透明度。我们可以看到，当两个图匹配时注意力权重可以使节点很好地对齐，而当两个图不匹配时，注意力权重往往会集中在具有较高程度的节点上。但这种模式不能像标准注意力模型那样被解释。</p><p> <img src="image-20210115223824308.png"></p><p>​    由于计算资源的限制，我对于此模型的复现效果略有偏差，其最高得分如下图所示，其pair_auc为0.9270，triplet_acc为0.9510.</p><p> <img src="image-20210115223841945.png"></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a><strong>参考文献</strong></h2><p>[1].  Li Y, Gu C, Dullien T, et al. Graph matching networks for learning the similarity of graph structured objects[J]. arXiv preprint arXiv:1904.12787, 2019.</p><p>[2].  Scarselli F, Gori M, Tsoi A C, et al. The graph neural network model[J]. IEEE Transactions on Neural Networks, 2008, 20(1): 61-80.</p><p>[3].  Veličković P, Cucurull G, Casanova A, et al. Graph attention networks[J]. arXiv preprint arXiv:1710.10903, 2017.</p><p>[4].  Al-Rfou R, Perozzi B, Zelle D. Ddgk: Learning graph representations for deep divergence graph kernels[C]//The World Wide Web Conference. 2019: 37-48.</p><p>[5].  Battaglia P W, Pascanu R, Lai M, et al. Interaction networks for learning about objects, relations and physics[J]. arXiv preprint arXiv:1612.00222, 2016.</p><p>[6].  M. Ou, P. Cui, J. Pei, Z. Zhang, W. Zhu, Asymmetric transitivity preserving graph embedding, in: Proc. of ACM SIGKDD, 2016, pp. 1105–1114.</p><p>[7].  涂存超,杨成,刘知远,孙茂松.网络表示学习综述[J].中国科学:信息科学,2017,47(08):980-996.</p><p>[8].  Battaglia P W, Hamrick J B, Bapst V, et al. Relational inductive biases, deep learning, and graph networks[J]. arXiv preprint arXiv:1806.01261, 2018.</p><p>[9].  Bronstein M M, Bruna J, LeCun Y, et al. Geometric deep learning: going beyond euclidean data[J]. IEEE Signal Processing Magazine, 2017, 34(4): 18-42.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文学习 </tag>
            
            <tag> 图神经网络 </tag>
            
            <tag> 论文复现 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图关系网络-阿里云</title>
      <link href="/2020/09/21/tu-guan-xi-wang-luo-a-li-yun/"/>
      <url>/2020/09/21/tu-guan-xi-wang-luo-a-li-yun/</url>
      
        <content type="html"><![CDATA[<h1 id="图关系网络-阿里云"><a href="#图关系网络-阿里云" class="headerlink" title="图关系网络-阿里云"></a>图关系网络-阿里云</h1><p><img src="aliyun1.jpg" alt="network1"></p><p><img src="aliyun2.jpg" alt="network2"></p><p><img src="aliyun3.jpg" alt="network3"></p><p><img src="aliyun4.jpg" alt="network4"></p><p><img src="aliyun5.jpg" alt="network5"></p><p><img src="aliyun6.jpg" alt="network6"></p><p><img src="aliyun7.jpg" alt="network7"></p><p><img src="aliyun8.jpg" alt="network8"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈对GCN的理解</title>
      <link href="/2020/09/21/qian-tan-dui-gcn-de-li-jie/"/>
      <url>/2020/09/21/qian-tan-dui-gcn-de-li-jie/</url>
      
        <content type="html"><![CDATA[<h1 id="Graph-Embedding-图嵌入-–【进阶篇】"><a href="#Graph-Embedding-图嵌入-–【进阶篇】" class="headerlink" title="Graph Embedding(图嵌入)–【进阶篇】"></a>Graph Embedding(图嵌入)–【进阶篇】</h1><h1 id="浅谈对GCN的理解"><a href="#浅谈对GCN的理解" class="headerlink" title="浅谈对GCN的理解"></a>浅谈对GCN的理解</h1><p><img src="GCN1.jpg" alt="GCN1"></p><p><img src="GCN2.jpg" alt="GCN2"></p><p><img src="GCN3.jpg" alt="GCN3"></p><p><img src="GCN4.jpg" alt="GCN4"></p><p><img src="GCN5.jpg" alt="GCN5"></p><p><img src="GCN6.jpg" alt="GCN6"></p><p><img src="GCN7.jpg" alt="GCN7"></p><p><img src="GCN8.jpg" alt="GCN8"></p><p><img src="GCN9.jpg" alt="GCN9"></p><p><img src="GCN10.jpg" alt="GCN10"></p><p><img src="GCN11.jpg" alt="GCN11"></p><p><img src="GCN12.jpg" alt="GCN12"></p><p><img src="GCN13.jpg" alt="GCN13"></p><p><img src="GCN14.jpg" alt="GCN14"></p><p><img src="GCN15.jpg" alt="GCN15"></p><p><img src="GCN16.jpg" alt="GCN16"></p><p><img src="GCN17.jpg" alt="GCN17"></p><p><img src="GCN18.jpg" alt="GCN18"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 图神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《Relational inductive biases, deep learning, and graph networks》 读书笔记</title>
      <link href="/2020/09/02/deepmind-relation/"/>
      <url>/2020/09/02/deepmind-relation/</url>
      
        <content type="html"><![CDATA[<h1 id="《Relational-inductive-biases-deep-learning-and-graph-networks》-读书笔记"><a href="#《Relational-inductive-biases-deep-learning-and-graph-networks》-读书笔记" class="headerlink" title="《Relational inductive biases, deep learning, and graph networks》 读书笔记"></a>《Relational inductive biases, deep learning, and graph networks》 读书笔记</h1><p><img src="relation1.jpg" alt="Relational1"></p><p><img src="relation2.jpg" alt="Relational2"></p><p><img src="relation3.jpg" alt="Relational3"></p><p><img src="relation4.jpg" alt="Relational4"></p><p><img src="relation5.jpg" alt="Relational5"></p><p><img src="relation6.jpg" alt="Relational6"></p><p><img src="relation7.jpg" alt="Relational7"></p><p><img src="relation8.jpg" alt="Relational8"></p><p><img src="relation9.jpg" alt="Relational9"></p><p><img src="relation11.jpg" alt="Relational11"></p><p><img src="relation12.jpg" alt="Relational12"></p><p><img src="relation13.jpg" alt="Relational13"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 论文学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集成学习</title>
      <link href="/2020/08/22/ji-cheng-xue-xi/"/>
      <url>/2020/08/22/ji-cheng-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="集成方法-ensemble-method（元算法-meta-algorithm）-概述"><a href="#集成方法-ensemble-method（元算法-meta-algorithm）-概述" class="headerlink" title="集成方法: ensemble method（元算法: meta algorithm） 概述"></a>集成方法: ensemble method（元算法: meta algorithm） 概述</h2><ul><li><p>概念：是对其他算法进行组合的一种形式。</p></li><li><p>通俗来说： 当做重要决定时，大家可能都会考虑吸取多个专家而不只是一个人的意见。<br>  机器学习处理问题时又何尝不是如此？ 这就是集成方法背后的思想。</p></li><li><p>集成方法：  </p><ol><li>投票选举(bagging: 自举汇聚法 bootstrap aggregating): 是基于数据随机重抽样分类器构造的方法</li><li>再学习(boosting): 是基于所有分类器的加权求和的方法</li></ol></li></ul><h2 id="集成方法-场景"><a href="#集成方法-场景" class="headerlink" title="集成方法 场景"></a>集成方法 场景</h2><p>目前 bagging 方法最流行的版本是: 随机森林(random forest)<br>选男友：美女选择择偶对象的时候，会问几个闺蜜的建议，最后选择一个综合得分最高的一个作为男朋友</p><p>目前 boosting 方法最流行的版本是: AdaBoost<br>追女友：3个帅哥追同一个美女，第1个帅哥失败-&gt;(传授经验：姓名、家庭情况) 第2个帅哥失败-&gt;(传授经验：兴趣爱好、性格特点) 第3个帅哥成功</p><blockquote><p>bagging 和 boosting 区别是什么？</p></blockquote><ol><li>bagging 是一种与 boosting 很类似的技术, 所使用的多个分类器的类型（数据量和特征量）都是一致的。</li><li>bagging 是由不同的分类器（1.数据随机化 2.特征随机化）经过训练，综合得出的出现最多分类结果；boosting 是通过调整已有分类器错分的那些数据来获得新的分类器，得出目前最优的结果。</li><li>bagging 中的分类器权重是相等的；而 boosting 中的分类器加权求和，所以权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。</li></ol><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><h3 id="随机森林-概述"><a href="#随机森林-概述" class="headerlink" title="随机森林 概述"></a>随机森林 概述</h3><ul><li>随机森林指的是利用多棵树对样本进行训练并预测的一种分类器。</li><li>决策树相当于一个大师，通过自己在数据集中学到的知识用于新数据的分类。但是俗话说得好，一个诸葛亮，玩不过三个臭皮匠。随机森林就是希望构建多个臭皮匠，希望最终的分类效果能够超过单个大师的一种算法。</li></ul><h3 id="随机森林-原理"><a href="#随机森林-原理" class="headerlink" title="随机森林 原理"></a>随机森林 原理</h3><p>那随机森林具体如何构建呢？<br>有两个方面：</p><ol><li>数据的随机性化</li><li>待选特征的随机化</li></ol><p>使得随机森林中的决策树都能够彼此不同，提升系统的多样性，从而提升分类性能。</p><blockquote><p>数据的随机化：使得随机森林中的决策树更普遍化一点，适合更多的场景。</p></blockquote><p>（有放回的准确率在：70% 以上， 无放回的准确率在：60% 以上）</p><ol><li>采取有放回的抽样方式 构造子数据集，保证不同子集之间的数量级一样（不同子集／同一子集 之间的元素可以重复）</li><li>利用子数据集来构建子决策树，将这个数据放到每个子决策树中，每个子决策树输出一个结果。</li><li>然后统计子决策树的投票结果，得到最终的分类 就是 随机森林的输出结果。</li><li>如下图，假设随机森林中有3棵子决策树，2棵子树的分类结果是A类，1棵子树的分类结果是B类，那么随机森林的分类结果就是A类。</li></ol><p><img src="1.jpg" alt="数据重抽样"></p><blockquote><p>待选特征的随机化</p></blockquote><ol><li>子树从所有的待选特征中随机选取一定的特征。</li><li>在选取的特征中选取最优的特征。</li></ol><p>下图中，蓝色的方块代表所有可以被选择的特征，也就是目前的待选特征；黄色的方块是分裂特征。<br><br>左边是一棵决策树的特征选取过程，通过在待选特征中选取最优的分裂特征（别忘了前文提到的ID3算法，C4.5算法，CART算法等等），完成分裂。<br><br>右边是一个随机森林中的子树的特征选取过程。<br></p><p><img src="2.jpg" alt="特征重抽样"></p><blockquote><p>随机森林 开发流程</p></blockquote><pre><code>收集数据：任何方法准备数据：转换样本集分析数据：任何方法训练算法：通过数据随机化和特征随机化，进行多实例的分类评估测试算法：计算错误率使用算法：输入样本数据，然后运行 随机森林 算法判断输入数据分类属于哪个分类，最后对计算出的分类执行后续处理</code></pre><blockquote><p>随机森林 算法特点</p></blockquote><pre><code>优点：几乎不需要输入准备、可实现隐式特征选择、训练速度非常快、其他模型很难超越、很难建立一个糟糕的随机森林模型、大量优秀、免费以及开源的实现。缺点：劣势在于模型大小、是个很难去解释的黑盒子。适用数据范围：数值型和标称型</code></pre><h3 id="项目案例-声纳信号分类"><a href="#项目案例-声纳信号分类" class="headerlink" title="项目案例: 声纳信号分类"></a>项目案例: 声纳信号分类</h3><h4 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h4><p>这是 Gorman 和 Sejnowski 在研究使用神经网络的声纳信号分类中使用的数据集。任务是训练一个模型来区分声纳信号。</p><h4 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h4><pre><code>收集数据：提供的文本文件准备数据：转换样本集分析数据：手工检查数据训练算法：在数据上，利用 random_forest() 函数进行优化评估，返回模型的综合分类结果测试算法：在采用自定义 n_folds 份随机重抽样 进行测试评估，得出综合的预测评分使用算法：若你感兴趣可以构建完整的应用程序，从案例进行封装，也可以参考我们的代码</code></pre><blockquote><p>收集数据：提供的文本文件</p></blockquote><p>样本数据：sonar-all-data.txt</p><pre><code>0.02,0.0371,0.0428,0.0207,0.0954,0.0986,0.1539,0.1601,0.3109,0.2111,0.1609,0.1582,0.2238,0.0645,0.066,0.2273,0.31,0.2999,0.5078,0.4797,0.5783,0.5071,0.4328,0.555,0.6711,0.6415,0.7104,0.808,0.6791,0.3857,0.1307,0.2604,0.5121,0.7547,0.8537,0.8507,0.6692,0.6097,0.4943,0.2744,0.051,0.2834,0.2825,0.4256,0.2641,0.1386,0.1051,0.1343,0.0383,0.0324,0.0232,0.0027,0.0065,0.0159,0.0072,0.0167,0.018,0.0084,0.009,0.0032,R0.0453,0.0523,0.0843,0.0689,0.1183,0.2583,0.2156,0.3481,0.3337,0.2872,0.4918,0.6552,0.6919,0.7797,0.7464,0.9444,1,0.8874,0.8024,0.7818,0.5212,0.4052,0.3957,0.3914,0.325,0.32,0.3271,0.2767,0.4423,0.2028,0.3788,0.2947,0.1984,0.2341,0.1306,0.4182,0.3835,0.1057,0.184,0.197,0.1674,0.0583,0.1401,0.1628,0.0621,0.0203,0.053,0.0742,0.0409,0.0061,0.0125,0.0084,0.0089,0.0048,0.0094,0.0191,0.014,0.0049,0.0052,0.0044,R0.0262,0.0582,0.1099,0.1083,0.0974,0.228,0.2431,0.3771,0.5598,0.6194,0.6333,0.706,0.5544,0.532,0.6479,0.6931,0.6759,0.7551,0.8929,0.8619,0.7974,0.6737,0.4293,0.3648,0.5331,0.2413,0.507,0.8533,0.6036,0.8514,0.8512,0.5045,0.1862,0.2709,0.4232,0.3043,0.6116,0.6756,0.5375,0.4719,0.4647,0.2587,0.2129,0.2222,0.2111,0.0176,0.1348,0.0744,0.013,0.0106,0.0033,0.0232,0.0166,0.0095,0.018,0.0244,0.0316,0.0164,0.0095,0.0078,R</code></pre><blockquote><p>准备数据：转换样本集</p></blockquote><pre class=" language-cpp"><code class="language-cpp"># 导入csv文件def <span class="token function">loadDataSet</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token operator">:</span>    dataset <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    with <span class="token function">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> as fr<span class="token operator">:</span>        <span class="token keyword">for</span> line in fr<span class="token punctuation">.</span><span class="token function">readlines</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>            <span class="token keyword">if</span> <span class="token operator">not</span> line<span class="token operator">:</span>                <span class="token keyword">continue</span>            lineArr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> featrue in line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">)</span><span class="token operator">:</span>                <span class="token macro property"># strip()返回移除字符串头尾指定的字符生成的新字符串</span>                str_f <span class="token operator">=</span> featrue<span class="token punctuation">.</span><span class="token function">strip</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> str_f<span class="token punctuation">.</span><span class="token function">isdigit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span> # 判断是否是数字                    # 将数据集的第column列转换成<span class="token keyword">float</span>形式                    lineArr<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">(</span>str_f<span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token operator">:</span>                    # 添加分类标签                    lineArr<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>str_f<span class="token punctuation">)</span>            dataset<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>lineArr<span class="token punctuation">)</span>    <span class="token keyword">return</span> dataset</code></pre><blockquote><p>分析数据：手工检查数据</p></blockquote><blockquote><p>训练算法：在数据上，利用 random_forest() 函数进行优化评估，返回模型的综合分类结果</p></blockquote><ul><li>样本数据随机无放回抽样-用于交叉验证</li></ul><pre class=" language-cpp"><code class="language-cpp">def <span class="token function">cross_validation_split</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> n_folds<span class="token punctuation">)</span><span class="token operator">:</span>    <span class="token string">""</span>"<span class="token function">cross_validation_split</span><span class="token punctuation">(</span>将数据集进行抽重抽样 n_folds 份，数据可以重复抽取<span class="token punctuation">)</span>    Args<span class="token operator">:</span>        dataset     原始数据集        n_folds     数据集dataset分成n_flods份    Returns<span class="token operator">:</span>        dataset_split    list集合，存放的是：将数据集进行抽重抽样 n_folds 份，数据可以重复抽取    <span class="token string">""</span>"    dataset_split <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    dataset_copy <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span>       # 复制一份 dataset<span class="token punctuation">,</span>防止 dataset 的内容改变    fold_size <span class="token operator">=</span> <span class="token function">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">/</span> n_folds    <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span>n_folds<span class="token punctuation">)</span><span class="token operator">:</span>        fold <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>                  # 每次循环 fold 清零，防止重复导入 dataset_split        <span class="token keyword">while</span> <span class="token function">len</span><span class="token punctuation">(</span>fold<span class="token punctuation">)</span> <span class="token operator">&lt;</span> fold_size<span class="token operator">:</span>   # 这里不能用 <span class="token keyword">if</span>，<span class="token keyword">if</span> 只是在第一次判断时起作用，<span class="token keyword">while</span> 执行循环，直到条件不成立 <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span># 有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此为自助采样法。从而保证每棵决策树训练集的差异性 <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>            index <span class="token operator">=</span> <span class="token function">randrange</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>dataset_copy<span class="token punctuation">)</span><span class="token punctuation">)</span>            # 将对应索引 index 的内容从 dataset_copy 中导出，并将该内容从 dataset_copy 中删除。            <span class="token macro property"># pop() 函数用于移除列表中的一个元素（默认最后一个元素），并且返回该元素的值。</span>            fold<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>dataset_copy<span class="token punctuation">.</span><span class="token function">pop</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span><span class="token punctuation">)</span>  # 无放回的方式            <span class="token macro property"># fold.append(dataset_copy[index])  # 有放回的方式</span>        dataset_split<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>fold<span class="token punctuation">)</span>    # 由dataset分割出的n_folds个数据构成的列表，为了用于交叉验证    <span class="token keyword">return</span> dataset_split</code></pre><ul><li>训练数据集随机化</li></ul><pre class=" language-cpp"><code class="language-cpp"><span class="token macro property"># Create a random subsample from the dataset with replacement</span>def <span class="token function">subsample</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> ratio<span class="token punctuation">)</span><span class="token operator">:</span>   # 创建数据集的随机子样本    <span class="token string">""</span>"<span class="token function">random_forest</span><span class="token punctuation">(</span>评估算法性能，返回模型得分<span class="token punctuation">)</span>    Args<span class="token operator">:</span>        dataset         训练数据集        ratio           训练数据集的样本比例    Returns<span class="token operator">:</span>        sample          随机抽样的训练样本    <span class="token string">""</span>"    sample <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    # 训练样本的按比例抽样。    <span class="token macro property"># round() 方法返回浮点数x的四舍五入值。</span>    n_sample <span class="token operator">=</span> <span class="token function">round</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span> <span class="token operator">*</span> ratio<span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token function">len</span><span class="token punctuation">(</span>sample<span class="token punctuation">)</span> <span class="token operator">&lt;</span> n_sample<span class="token operator">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span># 有放回的随机采样，有一些样本被重复采样，从而在训练集中多次出现，有的则从未在训练集中出现，此为自助采样法。从而保证每棵决策树训练集的差异性        index <span class="token operator">=</span> <span class="token function">randrange</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>        sample<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> sample</code></pre><ul><li>特征随机化</li></ul><pre class=" language-cpp"><code class="language-cpp"># 找出分割数据集的最优特征，得到最优的特征 index，特征值 row<span class="token punctuation">[</span>index<span class="token punctuation">]</span>，以及分割完的数据 groups（left<span class="token punctuation">,</span> right）def <span class="token function">get_split</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> n_features<span class="token punctuation">)</span><span class="token operator">:</span>    class_values <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token function">set</span><span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> row in dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>  # class_values <span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>    b_index<span class="token punctuation">,</span> b_value<span class="token punctuation">,</span> b_score<span class="token punctuation">,</span> b_groups <span class="token operator">=</span> <span class="token number">999</span><span class="token punctuation">,</span> <span class="token number">999</span><span class="token punctuation">,</span> <span class="token number">999</span><span class="token punctuation">,</span> None    features <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">while</span> <span class="token function">len</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span> <span class="token operator">&lt;</span> n_features<span class="token operator">:</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span>index <span class="token operator">=</span> <span class="token function">randrange</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  # 往 features 添加 n_features 个特征（ n_feature 等于特征数的个数），特征索引从 dataset 中随机取        <span class="token keyword">if</span> index <span class="token operator">not</span> in features<span class="token operator">:</span>            features<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>index<span class="token punctuation">)</span>    <span class="token keyword">for</span> index in features<span class="token operator">:</span>                    # 在 n_features 个特征中选出最优的特征索引，并没有遍历所有特征，从而保证了每课决策树的差异性        <span class="token keyword">for</span> row in dataset<span class="token operator">:</span>            groups <span class="token operator">=</span> <span class="token function">test_split</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> row<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> dataset<span class="token punctuation">)</span>  # groups<span class="token operator">=</span><span class="token punctuation">(</span>left<span class="token punctuation">,</span> right<span class="token punctuation">)</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span>index<span class="token punctuation">]</span> 遍历每一行 index 索引下的特征值作为分类值 value<span class="token punctuation">,</span> 找出最优的分类特征和特征值            gini <span class="token operator">=</span> <span class="token function">gini_index</span><span class="token punctuation">(</span>groups<span class="token punctuation">,</span> class_values<span class="token punctuation">)</span>            # 左右两边的数量越一样，说明数据区分度不高，gini系数越大            <span class="token keyword">if</span> gini <span class="token operator">&lt;</span> b_score<span class="token operator">:</span>                b_index<span class="token punctuation">,</span> b_value<span class="token punctuation">,</span> b_score<span class="token punctuation">,</span> b_groups <span class="token operator">=</span> index<span class="token punctuation">,</span> row<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> gini<span class="token punctuation">,</span> groups  # 最后得到最优的分类特征 b_index<span class="token punctuation">,</span>分类特征值 b_value<span class="token punctuation">,</span>分类结果 b_groups。b_value 为分错的代价成本    <span class="token macro property"># print b_score</span>    <span class="token keyword">return</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token string">'index'</span><span class="token operator">:</span> b_index<span class="token punctuation">,</span> <span class="token string">'value'</span><span class="token operator">:</span> b_value<span class="token punctuation">,</span> <span class="token string">'groups'</span><span class="token operator">:</span> b_groups<span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span></code></pre><ul><li>随机森林</li></ul><pre class=" language-cpp"><code class="language-cpp"><span class="token macro property"># Random Forest Algorithm</span>def <span class="token function">random_forest</span><span class="token punctuation">(</span>train<span class="token punctuation">,</span> test<span class="token punctuation">,</span> max_depth<span class="token punctuation">,</span> min_size<span class="token punctuation">,</span> sample_size<span class="token punctuation">,</span> n_trees<span class="token punctuation">,</span> n_features<span class="token punctuation">)</span><span class="token operator">:</span>    <span class="token string">""</span>"<span class="token function">random_forest</span><span class="token punctuation">(</span>评估算法性能，返回模型得分<span class="token punctuation">)</span>    Args<span class="token operator">:</span>        train           训练数据集        test            测试数据集        max_depth       决策树深度不能太深，不然容易导致过拟合        min_size        叶子节点的大小        sample_size     训练数据集的样本比例        n_trees         决策树的个数        n_features      选取的特征的个数    Returns<span class="token operator">:</span>        predictions     每一行的预测结果，bagging 预测最后的分类结果    <span class="token string">""</span>"    trees <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token macro property"># n_trees 表示决策树的数量</span>    <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span>n_trees<span class="token punctuation">)</span><span class="token operator">:</span>        # 随机抽样的训练样本， 随机采样保证了每棵决策树训练集的差异性        sample <span class="token operator">=</span> <span class="token function">subsample</span><span class="token punctuation">(</span>train<span class="token punctuation">,</span> sample_size<span class="token punctuation">)</span>        # 创建一个决策树        tree <span class="token operator">=</span> <span class="token function">build_tree</span><span class="token punctuation">(</span>sample<span class="token punctuation">,</span> max_depth<span class="token punctuation">,</span> min_size<span class="token punctuation">,</span> n_features<span class="token punctuation">)</span>        trees<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>tree<span class="token punctuation">)</span>    # 每一行的预测结果，bagging 预测最后的分类结果    predictions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token function">bagging_predict</span><span class="token punctuation">(</span>trees<span class="token punctuation">,</span> row<span class="token punctuation">)</span> <span class="token keyword">for</span> row in test<span class="token punctuation">]</span>    <span class="token keyword">return</span> predictions</code></pre><blockquote><p>测试算法：在采用自定义 n_folds 份随机重抽样 进行测试评估，得出综合的预测评分。</p></blockquote><ul><li>计算随机森林的预测结果的正确率</li></ul><pre class=" language-cpp"><code class="language-cpp"># 评估算法性能，返回模型得分def <span class="token function">evaluate_algorithm</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> algorithm<span class="token punctuation">,</span> n_folds<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token operator">:</span>    <span class="token string">""</span>"<span class="token function">evaluate_algorithm</span><span class="token punctuation">(</span>评估算法性能，返回模型得分<span class="token punctuation">)</span>    Args<span class="token operator">:</span>        dataset     原始数据集        algorithm   使用的算法        n_folds     数据的份数        <span class="token operator">*</span>args       其他的参数    Returns<span class="token operator">:</span>        scores      模型得分    <span class="token string">""</span>"    # 将数据集进行随机抽样，分成 n_folds 份，数据无重复的抽取    folds <span class="token operator">=</span> <span class="token function">cross_validation_split</span><span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> n_folds<span class="token punctuation">)</span>    scores <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    # 每次循环从 folds 从取出一个 fold 作为测试集，其余作为训练集，遍历整个 folds ，实现交叉验证    <span class="token keyword">for</span> fold in folds<span class="token operator">:</span>        train_set <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span>folds<span class="token punctuation">)</span>        train_set<span class="token punctuation">.</span><span class="token function">remove</span><span class="token punctuation">(</span>fold<span class="token punctuation">)</span>        # 将多个 fold 列表组合成一个 train_set 列表<span class="token punctuation">,</span> 类似 <span class="token keyword">union</span> all        <span class="token string">""</span>"        In <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token operator">:</span> l1<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        In <span class="token punctuation">[</span><span class="token number">21</span><span class="token punctuation">]</span><span class="token operator">:</span> l2<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        In <span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">]</span><span class="token operator">:</span> l<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span>        In <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token operator">:</span> l<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>l1<span class="token punctuation">)</span>        In <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token operator">:</span> l<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>l2<span class="token punctuation">)</span>        In <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token operator">:</span> l        Out<span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        In <span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token operator">:</span> <span class="token function">sum</span><span class="token punctuation">(</span>l<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        Out<span class="token punctuation">[</span><span class="token number">26</span><span class="token punctuation">]</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">,</span> <span class="token number">44</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token string">""</span>"        train_set <span class="token operator">=</span> <span class="token function">sum</span><span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        test_set <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token macro property"># fold 表示从原始数据集 dataset 提取出来的测试集</span>        <span class="token keyword">for</span> row in fold<span class="token operator">:</span>            row_copy <span class="token operator">=</span> <span class="token function">list</span><span class="token punctuation">(</span>row<span class="token punctuation">)</span>            row_copy<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> None             test_set<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>row_copy<span class="token punctuation">)</span>        predicted <span class="token operator">=</span> <span class="token function">algorithm</span><span class="token punctuation">(</span>train_set<span class="token punctuation">,</span> test_set<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span>        actual <span class="token operator">=</span> <span class="token punctuation">[</span>row<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> row in fold<span class="token punctuation">]</span>        # 计算随机森林的预测结果的正确率        accuracy <span class="token operator">=</span> <span class="token function">accuracy_metric</span><span class="token punctuation">(</span>actual<span class="token punctuation">,</span> predicted<span class="token punctuation">)</span>        scores<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>accuracy<span class="token punctuation">)</span>    <span class="token keyword">return</span> scores</code></pre><h2 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h2><h3 id="AdaBoost-adaptive-boosting-自适应-boosting-概述"><a href="#AdaBoost-adaptive-boosting-自适应-boosting-概述" class="headerlink" title="AdaBoost (adaptive boosting: 自适应 boosting) 概述"></a>AdaBoost (adaptive boosting: 自适应 boosting) 概述</h3><p><code>能否使用弱分类器和多个实例来构建一个强分类器？ 这是一个非常有趣的理论问题。</code></p><h3 id="AdaBoost-原理"><a href="#AdaBoost-原理" class="headerlink" title="AdaBoost 原理"></a>AdaBoost 原理</h3><blockquote><p>AdaBoost 工作原理</p></blockquote><p><img src="3.png" alt="AdaBoost 工作原理" title="AdaBoost 工作原理"></p><blockquote><p>AdaBoost 开发流程</p></blockquote><pre><code>收集数据：可以使用任意方法准备数据：依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。    当然也可以使用任意分类器作为弱分类器，第2章到第6章中的任一分类器都可以充当弱分类器。    作为弱分类器，简单分类器的效果更好。分析数据：可以使用任意方法。训练算法：AdaBoost 的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。测试算法：计算分类的错误率。使用算法：通SVM一样，AdaBoost 预测两个类别中的一个。如果想把它应用到多个类别的场景，那么就要像多类 SVM 中的做法一样对 AdaBoost 进行修改。</code></pre><blockquote><p>AdaBoost 算法特点</p></blockquote><pre><code>* 优点：泛化（由具体的、个别的扩大为一般的）错误率低，易编码，可以应用在大部分分类器上，无参数调节。* 缺点：对离群点敏感。* 适用数据类型：数值型和标称型数据。</code></pre><h3 id="项目案例-马疝病的预测"><a href="#项目案例-马疝病的预测" class="headerlink" title="项目案例: 马疝病的预测"></a>项目案例: 马疝病的预测</h3><blockquote><p>项目流程图</p></blockquote><p><img src="4.jpg" alt="AdaBoost代码流程图" title="AdaBoost代码流程图"></p><p>基于单层决策树构建弱分类器</p><ul><li>单层决策树(decision stump, 也称决策树桩)是一种简单的决策树。</li></ul><h4 id="项目概述-1"><a href="#项目概述-1" class="headerlink" title="项目概述"></a>项目概述</h4><p>预测患有疝气病的马的存活问题，这里的数据包括368个样本和28个特征，疝气病是描述马胃肠痛的术语，然而，这种病并不一定源自马的胃肠问题，其他问题也可能引发疝气病，该数据集中包含了医院检测马疝气病的一些指标，有的指标比较主观，有的指标难以测量，例如马的疼痛级别。另外，除了部分指标主观和难以测量之外，该数据还存在一个问题，数据集中有30%的值是缺失的。</p><h4 id="开发流程-1"><a href="#开发流程-1" class="headerlink" title="开发流程"></a>开发流程</h4><pre><code>收集数据：提供的文本文件准备数据：确保类别标签是+1和-1，而非1和0分析数据：统计分析训练算法：在数据上，利用 adaBoostTrainDS() 函数训练出一系列的分类器测试算法：我们拥有两个数据集。在不采用随机抽样的方法下，我们就会对 AdaBoost 和 Logistic 回归的结果进行完全对等的比较使用算法：观察该例子上的错误率。不过，也可以构建一个 Web 网站，让驯马师输入马的症状然后预测马是否会死去</code></pre><blockquote><p>收集数据：提供的文本文件</p></blockquote><p>训练数据：horseColicTraining.txt<br>测试数据：horseColicTest.txt</p><pre><code>2.000000    1.000000    38.500000    66.000000    28.000000    3.000000    3.000000    0.000000    2.000000    5.000000    4.000000    4.000000    0.000000    0.000000    0.000000    3.000000    5.000000    45.000000    8.400000    0.000000    0.000000    -1.0000001.000000    1.000000    39.200000    88.000000    20.000000    0.000000    0.000000    4.000000    1.000000    3.000000    4.000000    2.000000    0.000000    0.000000    0.000000    4.000000    2.000000    50.000000    85.000000    2.000000    2.000000    -1.0000002.000000    1.000000    38.300000    40.000000    24.000000    1.000000    1.000000    3.000000    1.000000    3.000000    3.000000    1.000000    0.000000    0.000000    0.000000    1.000000    1.000000    33.000000    6.700000    0.000000    0.000000    1.000000</code></pre><blockquote><p>准备数据：确保类别标签是+1和-1，而非1和0</p></blockquote><pre class=" language-cpp"><code class="language-cpp">def <span class="token function">loadDataSet</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token operator">:</span>    # 获取 feature 的数量<span class="token punctuation">,</span> 便于获取    numFeat <span class="token operator">=</span> <span class="token function">len</span><span class="token punctuation">(</span><span class="token function">open</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">readline</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    dataArr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    labelArr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    fr <span class="token operator">=</span> <span class="token function">open</span><span class="token punctuation">(</span>fileName<span class="token punctuation">)</span>    <span class="token keyword">for</span> line in fr<span class="token punctuation">.</span><span class="token function">readlines</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">:</span>        lineArr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        curLine <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">strip</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span>numFeat<span class="token number">-1</span><span class="token punctuation">)</span><span class="token operator">:</span>            lineArr<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">(</span>curLine<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        dataArr<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>lineArr<span class="token punctuation">)</span>        labelArr<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">(</span>curLine<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> dataArr<span class="token punctuation">,</span> labelArr</code></pre><blockquote><p>分析数据：统计分析</p></blockquote><p>过拟合(overfitting, 也称为过学习)</p><ul><li>发现测试错误率在达到一个最小值之后有开始上升，这种现象称为过拟合。</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/7.AdaBoost/%E8%BF%87%E6%8B%9F%E5%90%88.png" alt="过拟合"></p><ul><li>通俗来说：就是把一些噪音数据也拟合进去的，如下图。</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/7.AdaBoost/%E8%BF%87%E6%8B%9F%E5%90%88%E5%9B%BE%E8%A7%A3.png" alt="过拟合"></p><blockquote><p>训练算法：在数据上，利用 adaBoostTrainDS() 函数训练出一系列的分类器</p></blockquote><pre class=" language-cpp"><code class="language-cpp">def <span class="token function">adaBoostTrainDS</span><span class="token punctuation">(</span>dataArr<span class="token punctuation">,</span> labelArr<span class="token punctuation">,</span> numIt<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">)</span><span class="token operator">:</span>    <span class="token string">""</span>"<span class="token function">adaBoostTrainDS</span><span class="token punctuation">(</span>adaBoost训练过程放大<span class="token punctuation">)</span>    Args<span class="token operator">:</span>        dataArr   特征标签集合        labelArr  分类标签集合        numIt     实例数    Returns<span class="token operator">:</span>        weakClassArr  弱分类器的集合        aggClassEst   预测的分类结果值    <span class="token string">""</span>"    weakClassArr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    m <span class="token operator">=</span> <span class="token function">shape</span><span class="token punctuation">(</span>dataArr<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    # 初始化 D，设置每个样本的权重值，平均分为m份    D <span class="token operator">=</span> <span class="token function">mat</span><span class="token punctuation">(</span><span class="token function">ones</span><span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span>m<span class="token punctuation">)</span>    aggClassEst <span class="token operator">=</span> <span class="token function">mat</span><span class="token punctuation">(</span><span class="token function">zeros</span><span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span>numIt<span class="token punctuation">)</span><span class="token operator">:</span>        # 得到决策树的模型        bestStump<span class="token punctuation">,</span> error<span class="token punctuation">,</span> classEst <span class="token operator">=</span> <span class="token function">buildStump</span><span class="token punctuation">(</span>dataArr<span class="token punctuation">,</span> labelArr<span class="token punctuation">,</span> D<span class="token punctuation">)</span>        <span class="token macro property"># alpha目的主要是计算每一个分类器实例的权重(组合就是分类结果)</span>        # 计算每个分类器的alpha权重值        alpha <span class="token operator">=</span> <span class="token keyword">float</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token operator">*</span><span class="token function">log</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1.0</span><span class="token operator">-</span>error<span class="token punctuation">)</span><span class="token operator">/</span><span class="token function">max</span><span class="token punctuation">(</span>error<span class="token punctuation">,</span> <span class="token number">1e-16</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        bestStump<span class="token punctuation">[</span><span class="token string">'alpha'</span><span class="token punctuation">]</span> <span class="token operator">=</span> alpha        <span class="token macro property"># store Stump Params in Array</span>        weakClassArr<span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span>bestStump<span class="token punctuation">)</span>        print <span class="token string">"alpha=%s, classEst=%s, bestStump=%s, error=%s "</span> <span class="token operator">%</span> <span class="token punctuation">(</span>alpha<span class="token punctuation">,</span> classEst<span class="token punctuation">.</span>T<span class="token punctuation">,</span> bestStump<span class="token punctuation">,</span> error<span class="token punctuation">)</span>        # 分类正确：乘积为<span class="token number">1</span>，不会影响结果，<span class="token operator">-</span><span class="token number">1</span>主要是下面求e的<span class="token operator">-</span>alpha次方        # 分类错误：乘积为 <span class="token operator">-</span><span class="token number">1</span>，结果会受影响，所以也乘以 <span class="token operator">-</span><span class="token number">1</span>        expon <span class="token operator">=</span> <span class="token function">multiply</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token operator">*</span>alpha<span class="token operator">*</span><span class="token function">mat</span><span class="token punctuation">(</span>labelArr<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">,</span> classEst<span class="token punctuation">)</span>        print <span class="token string">'(-1取反)预测值expon='</span><span class="token punctuation">,</span> expon<span class="token punctuation">.</span>T        # 计算e的expon次方，然后计算得到一个综合的概率的值 <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span> <span class="token operator">&amp;</span>nbsp<span class="token punctuation">;</span># 结果发现： 判断错误的样本，D中相对应的样本权重值会变大。        D <span class="token operator">=</span> <span class="token function">multiply</span><span class="token punctuation">(</span>D<span class="token punctuation">,</span> <span class="token function">exp</span><span class="token punctuation">(</span>expon<span class="token punctuation">)</span><span class="token punctuation">)</span>        D <span class="token operator">=</span> D<span class="token operator">/</span>D<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        # 预测的分类结果值，在上一轮结果的基础上，进行加和操作        print <span class="token string">'当前的分类结果：'</span><span class="token punctuation">,</span> alpha<span class="token operator">*</span>classEst<span class="token punctuation">.</span>T        aggClassEst <span class="token operator">+</span><span class="token operator">=</span> alpha<span class="token operator">*</span>classEst        print <span class="token string">"叠加后的分类结果aggClassEst: "</span><span class="token punctuation">,</span> aggClassEst<span class="token punctuation">.</span>T        <span class="token macro property"># sign 判断正为1， 0为0， 负为-1，通过最终加和的权重值，判断符号。</span>        # 结果为：错误的样本标签集合，因为是 <span class="token operator">!=</span><span class="token punctuation">,</span>那么结果就是<span class="token number">0</span> 正<span class="token punctuation">,</span> <span class="token number">1</span> 负        aggErrors <span class="token operator">=</span> <span class="token function">multiply</span><span class="token punctuation">(</span><span class="token function">sign</span><span class="token punctuation">(</span>aggClassEst<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token function">mat</span><span class="token punctuation">(</span>labelArr<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">,</span> <span class="token function">ones</span><span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        errorRate <span class="token operator">=</span> aggErrors<span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>m        <span class="token macro property"># print "total error=%s " % (errorRate)</span>        <span class="token keyword">if</span> errorRate <span class="token operator">==</span> <span class="token number">0.0</span><span class="token operator">:</span>            <span class="token keyword">break</span>    <span class="token keyword">return</span> weakClassArr<span class="token punctuation">,</span> aggClassEst</code></pre><pre><code>发现：alpha （模型权重）目的主要是计算每一个分类器实例的权重(加和就是分类结果)  分类的权重值：最大的值= alpha 的加和，最小值=-最大值D （样本权重）的目的是为了计算错误概率： weightedError = D.T*errArr，求最佳分类器  样本的权重值：如果一个值误判的几率越小，那么 D 的样本权重越小</code></pre><p><img src="5.png" alt="AdaBoost算法权重计算公式" title="AdaBoost算法权重计算公式"></p><blockquote><p>测试算法：我们拥有两个数据集。在不采用随机抽样的方法下，我们就会对 AdaBoost 和 Logistic 回归的结果进行完全对等的比较。</p></blockquote><pre class=" language-cpp"><code class="language-cpp">def <span class="token function">adaClassify</span><span class="token punctuation">(</span>datToClass<span class="token punctuation">,</span> classifierArr<span class="token punctuation">)</span><span class="token operator">:</span>    <span class="token string">""</span>"<span class="token function">adaClassify</span><span class="token punctuation">(</span>ada分类测试<span class="token punctuation">)</span>    Args<span class="token operator">:</span>        datToClass     多个待分类的样例        classifierArr  弱分类器的集合    Returns<span class="token operator">:</span>        <span class="token function">sign</span><span class="token punctuation">(</span>aggClassEst<span class="token punctuation">)</span> 分类结果    <span class="token string">""</span>"    <span class="token macro property"># do stuff similar to last aggClassEst in adaBoostTrainDS</span>    dataMat <span class="token operator">=</span> <span class="token function">mat</span><span class="token punctuation">(</span>datToClass<span class="token punctuation">)</span>    m <span class="token operator">=</span> <span class="token function">shape</span><span class="token punctuation">(</span>dataMat<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    aggClassEst <span class="token operator">=</span> <span class="token function">mat</span><span class="token punctuation">(</span><span class="token function">zeros</span><span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    # 循环 多个分类器    <span class="token keyword">for</span> i in <span class="token function">range</span><span class="token punctuation">(</span><span class="token function">len</span><span class="token punctuation">(</span>classifierArr<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">:</span>        # 前提： 我们已经知道了最佳的分类器的实例        # 通过分类器来核算每一次的分类结果，然后通过alpha<span class="token operator">*</span>每一次的结果 得到最后的权重加和的值。        classEst <span class="token operator">=</span> <span class="token function">stumpClassify</span><span class="token punctuation">(</span>dataMat<span class="token punctuation">,</span> classifierArr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'dim'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> classifierArr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'thresh'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> classifierArr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'ineq'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        aggClassEst <span class="token operator">+</span><span class="token operator">=</span> classifierArr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'alpha'</span><span class="token punctuation">]</span><span class="token operator">*</span>classEst    <span class="token keyword">return</span> <span class="token function">sign</span><span class="token punctuation">(</span>aggClassEst<span class="token punctuation">)</span></code></pre><blockquote><p>使用算法：观察该例子上的错误率。不过，也可以构建一个 Web 网站，让驯马师输入马的症状然后预测马是否会死去。</p></blockquote><pre class=" language-cpp"><code class="language-cpp"># 马疝病数据集# 训练集合dataArr<span class="token punctuation">,</span> labelArr <span class="token operator">=</span> <span class="token function">loadDataSet</span><span class="token punctuation">(</span><span class="token string">"data/7.AdaBoost/horseColicTraining2.txt"</span><span class="token punctuation">)</span>weakClassArr<span class="token punctuation">,</span> aggClassEst <span class="token operator">=</span> <span class="token function">adaBoostTrainDS</span><span class="token punctuation">(</span>dataArr<span class="token punctuation">,</span> labelArr<span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">)</span>print weakClassArr<span class="token punctuation">,</span> <span class="token string">'\n-----\n'</span><span class="token punctuation">,</span> aggClassEst<span class="token punctuation">.</span>T# 计算ROC下面的AUC的面积大小<span class="token function">plotROC</span><span class="token punctuation">(</span>aggClassEst<span class="token punctuation">.</span>T<span class="token punctuation">,</span> labelArr<span class="token punctuation">)</span># 测试集合dataArrTest<span class="token punctuation">,</span> labelArrTest <span class="token operator">=</span> <span class="token function">loadDataSet</span><span class="token punctuation">(</span><span class="token string">"data/7.AdaBoost/horseColicTest2.txt"</span><span class="token punctuation">)</span>m <span class="token operator">=</span> <span class="token function">shape</span><span class="token punctuation">(</span>dataArrTest<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>predicting10 <span class="token operator">=</span> <span class="token function">adaClassify</span><span class="token punctuation">(</span>dataArrTest<span class="token punctuation">,</span> weakClassArr<span class="token punctuation">)</span>errArr <span class="token operator">=</span> <span class="token function">mat</span><span class="token punctuation">(</span><span class="token function">ones</span><span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span># 测试：计算总样本数，错误样本数，错误率print m<span class="token punctuation">,</span> errArr<span class="token punctuation">[</span>predicting10 <span class="token operator">!=</span> <span class="token function">mat</span><span class="token punctuation">(</span>labelArrTest<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> errArr<span class="token punctuation">[</span>predicting10 <span class="token operator">!=</span> <span class="token function">mat</span><span class="token punctuation">(</span>labelArrTest<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span>m</code></pre><h4 id="要点补充"><a href="#要点补充" class="headerlink" title="要点补充"></a>要点补充</h4><blockquote><p>非均衡现象：</p></blockquote><p><code>在分类器训练时，正例数目和反例数目不相等（相差很大）。或者发生在正负例分类错误的成本不同的时候。</code></p><ul><li>判断马是否能继续生存(不可误杀)</li><li>过滤垃圾邮件(不可漏判)</li><li>不能放过传染病的人</li><li>不能随便认为别人犯罪</li></ul><p>我们有多种方法来处理这个问题： 具体可参考<a href="https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/">此链接</a></p><p>再结合书中的方法，可以归为八大类：</p><h5 id="1-能否收集到更多的数据？"><a href="#1-能否收集到更多的数据？" class="headerlink" title="1.能否收集到更多的数据？"></a>1.能否收集到更多的数据？</h5><p>这个措施往往被人们所忽略，被认为很蠢。但是更大的数据集更能体现样本的分布，多样性。</p><h5 id="2-尝试使用其他的评价指标"><a href="#2-尝试使用其他的评价指标" class="headerlink" title="2.尝试使用其他的评价指标"></a>2.尝试使用其他的评价指标</h5><p>Accuracy 或者error rate 不能用于非均衡的数据集。这会误导人。这时候可以尝试其他的评价指标。</p><p>Confusion Matrix 混淆矩阵：使用一个表格对分类器所预测的类别与其真实的类别的样本统计，分别为：TP、FN、FP与TN。</p><p>Precision：精确度</p><p>Recall： 召回率</p><p>F1 Score (or F-Score)： 精确度和召回率的加权平均</p><p>或者使用</p><p>Kappa (Cohen’s kappa)</p><p>ROC Curves</p><blockquote><p>ROC 评估方法</p></blockquote><ul><li>ROC 曲线: 最佳的分类器应该尽可能地处于左上角</li></ul><p><img src="6.png" alt="ROC曲线"></p><ul><li><p>对不同的 ROC 曲线进行比较的一个指标是曲线下的面积(Area Unser the Curve, AUC). </p></li><li><p>AUC 给出的是分类器的平均性能值，当然它并不能完全代替对整条曲线的观察。</p></li><li><p>一个完美分类器的 AUC 为1，而随机猜测的 AUC 则为0.5。</p></li></ul><h5 id="3-尝试对样本重抽样"><a href="#3-尝试对样本重抽样" class="headerlink" title="3.尝试对样本重抽样"></a>3.尝试对样本重抽样</h5><p>欠抽样(undersampling)或者过抽样(oversampling)</p><pre><code>- 欠抽样: 意味着删除样例- 过抽样: 意味着复制样例(重复使用)</code></pre><p>对大类进行欠抽样</p><p>对小类进行过抽样</p><p>或者结合上述两种方法进行抽样</p><p>一些经验法则：</p><ul><li><p>考虑样本（超过1万、十万甚至更多）进行欠采样，即删除部分样本；</p></li><li><p>考虑样本（不足1为甚至更少）进行过采样，即添加部分样本的副本；</p></li><li><p>考虑尝试随机采样与非随机采样两种采样方法；</p></li><li><p>考虑对各类别尝试不同的采样比例，不一定是1:1</p></li><li><p>考虑同时使用过采样与欠采样</p></li></ul><h5 id="4-尝试产生人工生成的样本"><a href="#4-尝试产生人工生成的样本" class="headerlink" title="4.尝试产生人工生成的样本"></a>4.尝试产生人工生成的样本</h5><p>一种简单的方法就是随机抽样小类样本的属性（特征）来组成新的样本即属性值随机采样。你可以根据经验进行抽样，可以使用其他方式比如朴素贝叶斯方法假设各属性之间互相独立进行采样，这样便可得到更多的数据，但是无法保证属性之间的非线性关系。</p><p>当然也有系统性的算法。最常用的SMOTE(Synthetic Minority Over-Sampling Technique)。 顾名思义，这是一种over sampling（过抽样）的方式。它是产生人为的样本而不是制造样本副本。这个算法是选取2个或者2个以上相似的样本（根据距离度量 distance measure），然后每次选择其中一个样本，并随机选择一定数量的邻居样本对选择的那个样本的一个属性增加噪声(每次只处理一个属性)。这样就构造了更多的新生数据。具体可以参见<a href="http://www.jair.org/papers/paper953.html">原始论文</a>。</p><p>python实现可以查阅<a href="https://github.com/scikit-learn-contrib/imbalanced-learn">UnbalancedDataset</a></p><h5 id="5-尝试不同的算法"><a href="#5-尝试不同的算法" class="headerlink" title="5.尝试不同的算法"></a>5.尝试不同的算法</h5><p>强烈建议不要在每个问题上使用你最喜欢的算法。虽然这个算法带来较好的效果，但是它也会蒙蔽你观察数据内蕴含的其他的信息。至少你得在同一个问题上试试各种算法。具体可以参阅<a href="https://machinelearningmastery.com/why-you-should-be-spot-checking-algorithms-on-your-machine-learning-problems/">Why you should be Spot-Checking Algorithms on your Machine Learning Problems</a></p><p>比如说，决策树经常在非均衡数据集上表现良好。创建分类树时候使用基于类变量的划分规则强制使类别表达出来。如果有疑惑，可以尝试一些流行的决策树，比如, C4.5, C5.0, CART 和 Random Forrest。</p><h5 id="6-尝试使用惩罚的模型"><a href="#6-尝试使用惩罚的模型" class="headerlink" title="6.尝试使用惩罚的模型"></a>6.尝试使用惩罚的模型</h5><p>你可以使用同种算法但是以不同的角度对待这个问题。</p><p>惩罚的模型就是对于不同的分类错误给予不同的代价（惩罚）。比如对于错分的小类给予更高的代价。这种方式会使模型偏差，更加关注小类。</p><p>通常来说这种代价/惩罚或者比重在学习中算法是特定的。比如使用代价函数来实现：</p><blockquote><p>代价函数</p></blockquote><ul><li>基于代价函数的分类器决策控制：<code>TP*(-5)+FN*1+FP*50+TN*0</code></li></ul><p><img src="7.png" alt="代价函数"></p><p>这种方式叫做 cost sensitive learning，Weka 中相应的框架可以实现叫<a href="http://weka.sourceforge.net/doc.dev/weka/classifiers/meta/CostSensitiveClassifier.html">CostSensitiveClassifier</a></p><p>如果当你只能使用特定算法而且无法重抽样，或者模型效果不行，这时候使用惩罚（penalization）是可行的方法。这提供另外一种方式来“平衡”类别。但是设定惩罚函数/代价函数是比较复杂的。最好还是尝试不同的代价函数组合来得到最优效果。</p><h5 id="7-尝试使用不同的角度"><a href="#7-尝试使用不同的角度" class="headerlink" title="7.尝试使用不同的角度"></a>7.尝试使用不同的角度</h5><p>其实有很多研究关于非均衡数据。他们有自己的算法，度量，术语。</p><p>从它们的角度看看你的问题，思考你的问题，说不定会有新的想法。</p><p>两个领域您可以考虑： anomaly detection(异常值检测) 和 change detection（变化趋势检测）。</p><p>Anomaly dectection 就是检测稀有事件。 比如通过机器震动来识别机器谷中或者根据一系列系统的调用来检测恶意操作。与常规操作相比，这些事件是罕见的。</p><p>把小类想成异常类这种转变可能会帮助你想到新办法来分类数据样本。</p><p>change detection 变化趋势检测类似于异常值检测。但是他不是寻找异常值而是寻找变化或区别。比如通过使用模式或者银行交易记录来观察用户行为转变。</p><p>这些两种转变可能会给你新的方式去思考你的问题和新的技术去尝试。 &nbsp; &nbsp;</p><h5 id="8-尝试去创新"><a href="#8-尝试去创新" class="headerlink" title="8.尝试去创新"></a>8.尝试去创新</h5><p>仔细思考你的问题然后想想看如何将这问题细分为几个更切实际的小问题。</p><p>比如：</p><p>将你的大类分解成多个较小的类；</p><p>使用One Class分类器（看待成异常点检测）；</p><p>对数据集进行抽样成多个数据集，使用集成方式，训练多个分类器，然后联合这些分类器进行分类；</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Embedding(图嵌入)--【进阶篇】</title>
      <link href="/2020/08/10/graph-embedding-second/"/>
      <url>/2020/08/10/graph-embedding-second/</url>
      
        <content type="html"><![CDATA[<h1 id="Graph-Embedding-图嵌入-–【进阶篇】"><a href="#Graph-Embedding-图嵌入-–【进阶篇】" class="headerlink" title="Graph Embedding(图嵌入)–【进阶篇】"></a>Graph Embedding(图嵌入)–【进阶篇】</h1><p><img src="Embedding11.jpg" alt="Graph Embedding1"></p><p><img src="Embedding12.jpg" alt="Graph Embedding2"></p><p><img src="Embedding13.jpg" alt="Graph Embedding3"></p><p><img src="Embedding14.jpg" alt="Graph Embedding4"></p><p><img src="Embedding15.jpg" alt="Graph Embedding5"></p><p><img src="Embedding16.jpg" alt="Graph Embedding6"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 图嵌入 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Embedding(图嵌入)--【基础篇】</title>
      <link href="/2020/07/22/graph-embedding-first/"/>
      <url>/2020/07/22/graph-embedding-first/</url>
      
        <content type="html"><![CDATA[<h1 id="Graph-Embedding-图嵌入-–【基础篇】"><a href="#Graph-Embedding-图嵌入-–【基础篇】" class="headerlink" title="Graph Embedding(图嵌入)–【基础篇】"></a>Graph Embedding(图嵌入)–【基础篇】</h1><p><img src="Embedding1.jpg" alt="Graph Embedding1"></p><p><img src="Embedding2.jpg" alt="Graph Embedding2"></p><p><img src="Embedding3.jpg" alt="Graph Embedding3"></p><p><img src="Embedding4.jpg" alt="Graph Embedding4"></p><p><img src="Embedding5.jpg" alt="Graph Embedding5"></p><p><img src="Embedding6.jpg" alt="Graph Embedding6"></p><p><img src="Embedding7.jpg" alt="Graph Embedding7"></p><p><img src="Embedding8.jpg" alt="Graph Embedding8"></p><p><img src="Embedding9.jpg" alt="Graph Embedding9"></p><p><img src="Embedding10.jpg" alt="Graph Embedding10"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 图模型 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 图模型 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 图嵌入 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习——反向传播</title>
      <link href="/2020/07/04/fan-xiang-chuan-bo/"/>
      <url>/2020/07/04/fan-xiang-chuan-bo/</url>
      
        <content type="html"><![CDATA[<h1 id="反向传递"><a href="#反向传递" class="headerlink" title="反向传递"></a>反向传递</h1><blockquote><p>建议：一定要看懂推导过程</p></blockquote><p>　　最近在看深度学习的东西，一开始看的吴恩达的UFLDL教程，有中文版就直接看了，后来发现有些地方总是不是很明确，又去看英文版，然后又找了些资料看，才发现，中文版的译者在翻译的时候会对省略的公式推导过程进行补充，但是补充的又是错的，难怪觉得有问题。反向传播法其实是神经网络的基础了，但是很多人在学的时候总是会遇到一些问题，或者看到大篇的公式觉得好像很难就退缩了，其实不难，就是一个链式求导法则反复用。如果不想看公式，可以直接把数值带进去，实际的计算一下，体会一下这个过程之后再来推导公式，这样就会觉得很容易了。</p><p>　　说到神经网络，大家看到这个图应该不陌生：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630140644406-409859737.png"></p><p>　　这是典型的三层神经网络的基本构成，Layer L1是输入层，Layer L2是隐含层，Layer L3是隐含层，我们现在手里有一堆数据{x1,x2,x3,…,xn},输出也是一堆数据{y1,y2,y3,…,yn},现在要他们在隐含层做某种变换，让你把数据灌进去后得到你期望的输出。如果你希望你的输出和原始输入一样，那么就是最常见的自编码模型（Auto-Encoder）。可能有人会问，为什么要输入输出都一样呢？有什么用啊？其实应用挺广的，在图像识别，文本分类等等都会用到，我会专门再写一篇Auto-Encoder的文章来说明，包括一些变种之类的。如果你的输出和原始输入不一样，那么就是很常见的人工神经网络了，相当于让原始数据通过一个映射来得到我们想要的输出数据，也就是我们今天要讲的话题。</p><p>　　本文直接举一个例子，带入数值演示反向传播法的过程，公式的推导等到下次写Auto-Encoder的时候再写，（注：本文假设你已经懂得基本的神经网络构成，如果完全不懂，可以参考Poll写的笔记：<a href="http://www.cnblogs.com/maybe2030/p/5597716.html">[Mechine Learning &amp; Algorithm] 神经网络基础</a>）</p><p>　　假设，你有这样一个网络层：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630141449671-1058672778.png"></p><p>　　第一层是输入层，包含两个神经元i1，i2，和截距项b1；第二层是隐含层，包含两个神经元h1,h2和截距项b2，第三层是输出o1,o2，每条线上标的wi是层与层之间连接的权重，激活函数我们默认为sigmoid函数。</p><p>　　现在对他们赋上初值，如下图：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630142019140-402363317.png"></p><p>　　其中，输入数据 &nbsp;i1=0.05，i2=0.10;</p><p>　　　　　输出数据 o1=0.01,o2=0.99;</p><p>　　　　　初始权重 &nbsp;w1=0.15,w2=0.20,w3=0.25,w4=0.30;</p><p>　　　　　　　　　 &nbsp;w5=0.40,w6=0.45,w7=0.50,w8=0.55</p><p>　　目标：给出输入数据i1,i2(0.05和0.10)，使输出尽可能与原始输出o1,o2(0.01和0.99)接近。</p><p>　　<strong>Step 1 前向传播</strong></p><p>　　1.输入层—-&gt;隐含层：</p><p>　　计算神经元h1的输入加权和：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630142915359-294460310.png"></p><p>神经元h1的输出o1:(此处用到激活函数为sigmoid函数)：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630150115390-1035378028.png"></p><p>　　同理，可计算出神经元h2的输出o2：</p><p>　　<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630150244265-1128303244.png"></p><p>　　2.隐含层—-&gt;输出层：</p><p>　　计算输出层神经元o1和o2的值：</p><p>　　<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630150517109-389457135.png"></p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630150638390-1210364296.png"></p><p>这样前向传播的过程就结束了，我们得到输出值为[0.75136079 , 0.772928465]，与实际值[0.01 , 0.99]相差还很远，现在我们对误差进行反向传播，更新权值，重新计算输出。</p><p><strong>Step 2 反向传播</strong></p><p>1.计算总误差</p><p>总误差：(square error)</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630151201812-1014280864.png"></p><p>但是有两个输出，所以分别计算o1和o2的误差，总误差为两者之和：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630151457593-1250510503.png"></p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630151508999-1967746600.png"></p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630151516093-1257166735.png"></p><p>2.隐含层—-&gt;输出层的权值更新：</p><p>以权重参数w5为例，如果我们想知道w5对整体误差产生了多少影响，可以用整体误差对w5求偏导求出：（链式法则）</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630151916796-1001638091.png"></p><p>下面的图可以更直观的看清楚误差是怎样反向传播的：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152018906-1524325812.png"></p><p>现在我们来分别计算每个式子的值：</p><p>计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152206781-7976168.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152258437-1960839452.png"></p><p>计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152417109-711077078.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152511937-1667481051.png"></p><p>（这一步实际上就是对sigmoid函数求导，比较简单，可以自己推导一下）</p><p>计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152625593-2083321635.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152658109-214239362.png"></p><p>最后三者相乘：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630152811640-888140287.png"></p><p>这样我们就计算出整体误差E(total)对w5的偏导值。</p><p>回过头来再看看上面的公式，我们发现：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153103187-515052589.png"></p><p>为了表达方便，用<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153202812-585186566.png">来表示输出层的误差：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153251234-1144531293.png"></p><p>因此，整体误差E(total)对w5的偏导公式可以写成：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153405296-436656179.png"></p><p>如果输出层误差计为负的话，也可以写成：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153514734-1544628024.png"></p><p>最后我们来更新w5的值：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153614374-1624035276.png"></p><p>（其中，<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153700093-743859667.png">是学习速率，这里我们取0.5）</p><p>同理，可更新w6,w7,w8:</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630153807624-1231975059.png"></p><p>3.隐含层—-&gt;隐含层的权值更新：</p><p>　方法其实与上面说的差不多，但是有个地方需要变一下，在上文计算总误差对w5的偏导时，是从out(o1)—-&gt;net(o1)—-&gt;w5,但是在隐含层之间的权值更新时，是out(h1)—-&gt;net(h1)—-&gt;w1,而out(h1)会接受E(o1)和E(o2)两个地方传来的误差，所以这个地方两个都要计算。</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630154317562-311369571.png"></p><p>计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630154712202-1906007645.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630154758531-934861299.png"></p><p>先计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630154958296-1922097086.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155015546-1106216279.png"></p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155036406-964647962.png"></p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155117656-1905928379.png"></p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155158468-157032005.png"></p><p>同理，计算出：</p><p>　　　　　　　　　　<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155310937-2103938446.png"></p><p>两者相加得到总值：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155435218-396769942.png"></p><p>再计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155555562-1422254830.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155628046-229505495.png"></p><p>再计算<img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155731421-239852713.png">：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155706437-964861747.png"></p><p>最后，三者相乘：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630155827718-189457408.png"></p><p>&nbsp;为了简化公式，用sigma(h1)表示隐含层单元h1的误差：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630160345281-679307550.png"></p><p>最后，更新w1的权值：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630160523437-1906004593.png"></p><p>同理，额可更新w2,w3,w4的权值：</p><p><img src="http://data.apachecn.org/img/AiLearning/dl/%E5%8F%8D%E5%90%91%E4%BC%A0%E9%80%92/853467-20160630160603484-1471434475.png"></p><p>　　这样误差反向传播法就完成了，最后我们再把更新的权值重新计算，不停地迭代，在这个例子中第一次迭代之后，总误差E(total)由0.298371109下降至0.291027924。迭代10000次后，总误差为0.000035085，输出为<a href="%E5%8E%9F%E8%BE%93%E5%85%A5%E4%B8%BA%5B0.01,0.99%5D">0.015912196,0.984065734</a>,证明效果还是不错的。</p><p>代码(Python):</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#coding:utf-8</span><span class="token keyword">import</span> random<span class="token keyword">import</span> math<span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true">#   参数解释：</span><span class="token comment" spellcheck="true">#   "pd_" ：偏导的前缀</span><span class="token comment" spellcheck="true">#   "d_" ：导数的前缀</span><span class="token comment" spellcheck="true">#   "w_ho" ：隐含层到输出层的权重系数索引</span><span class="token comment" spellcheck="true">#   "w_ih" ：输入层到隐含层的权重系数的索引</span><span class="token keyword">class</span> <span class="token class-name">NeuralNetwork</span><span class="token punctuation">:</span>    LEARNING_RATE <span class="token operator">=</span> <span class="token number">0.5</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_inputs<span class="token punctuation">,</span> num_hidden<span class="token punctuation">,</span> num_outputs<span class="token punctuation">,</span> hidden_layer_weights <span class="token operator">=</span> None<span class="token punctuation">,</span> hidden_layer_bias <span class="token operator">=</span> None<span class="token punctuation">,</span> output_layer_weights <span class="token operator">=</span> None<span class="token punctuation">,</span> output_layer_bias <span class="token operator">=</span> None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>num_inputs <span class="token operator">=</span> num_inputs        self<span class="token punctuation">.</span>hidden_layer <span class="token operator">=</span> NeuronLayer<span class="token punctuation">(</span>num_hidden<span class="token punctuation">,</span> hidden_layer_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>output_layer <span class="token operator">=</span> NeuronLayer<span class="token punctuation">(</span>num_outputs<span class="token punctuation">,</span> output_layer_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>init_weights_from_inputs_to_hidden_layer_neurons<span class="token punctuation">(</span>hidden_layer_weights<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>init_weights_from_hidden_layer_neurons_to_output_layer_neurons<span class="token punctuation">(</span>output_layer_weights<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">init_weights_from_inputs_to_hidden_layer_neurons</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_layer_weights<span class="token punctuation">)</span><span class="token punctuation">:</span>        weight_num <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> h <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token operator">not</span> hidden_layer_weights<span class="token punctuation">:</span>                    self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">.</span>append<span class="token punctuation">(</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">.</span>append<span class="token punctuation">(</span>hidden_layer_weights<span class="token punctuation">[</span>weight_num<span class="token punctuation">]</span><span class="token punctuation">)</span>                weight_num <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">def</span> <span class="token function">init_weights_from_hidden_layer_neurons_to_output_layer_neurons</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> output_layer_weights<span class="token punctuation">)</span><span class="token punctuation">:</span>        weight_num <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> o <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> h <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> <span class="token operator">not</span> output_layer_weights<span class="token punctuation">:</span>                    self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">.</span>append<span class="token punctuation">(</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output_layer_weights<span class="token punctuation">[</span>weight_num<span class="token punctuation">]</span><span class="token punctuation">)</span>                weight_num <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">def</span> <span class="token function">inspect</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------'</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'* Inputs: &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------'</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Hidden Layer'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>inspect<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------'</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'* Output Layer'</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>inspect<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'------'</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">feed_forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        hidden_layer_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>feed_forward<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>feed_forward<span class="token punctuation">(</span>hidden_layer_outputs<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> training_inputs<span class="token punctuation">,</span> training_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>feed_forward<span class="token punctuation">(</span>training_inputs<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 1. 输出神经元的值</span>        pd_errors_wrt_output_neuron_total_net_input <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span>        <span class="token keyword">for</span> o <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># ∂E/∂zⱼ</span>            pd_errors_wrt_output_neuron_total_net_input<span class="token punctuation">[</span>o<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>calculate_pd_error_wrt_total_net_input<span class="token punctuation">(</span>training_outputs<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 2. 隐含层神经元的值</span>        pd_errors_wrt_hidden_neuron_total_net_input <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span>        <span class="token keyword">for</span> h <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment" spellcheck="true"># dE/dyⱼ = Σ ∂E/∂zⱼ * ∂z/∂yⱼ = Σ ∂E/∂zⱼ * wᵢⱼ</span>            d_error_wrt_hidden_neuron_output <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">for</span> o <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                d_error_wrt_hidden_neuron_output <span class="token operator">+=</span> pd_errors_wrt_output_neuron_total_net_input<span class="token punctuation">[</span>o<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">[</span>h<span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># ∂E/∂zⱼ = dE/dyⱼ * ∂zⱼ/∂</span>            pd_errors_wrt_hidden_neuron_total_net_input<span class="token punctuation">[</span>h<span class="token punctuation">]</span> <span class="token operator">=</span> d_error_wrt_hidden_neuron_output <span class="token operator">*</span> self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">.</span>calculate_pd_total_net_input_wrt_input<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 3. 更新输出层权重系数</span>        <span class="token keyword">for</span> o <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> w_ho <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># ∂Eⱼ/∂wᵢⱼ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢⱼ</span>                pd_error_wrt_weight <span class="token operator">=</span> pd_errors_wrt_output_neuron_total_net_input<span class="token punctuation">[</span>o<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>calculate_pd_total_net_input_wrt_weight<span class="token punctuation">(</span>w_ho<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># Δw = α * ∂Eⱼ/∂wᵢ</span>                self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">[</span>w_ho<span class="token punctuation">]</span> <span class="token operator">-=</span> self<span class="token punctuation">.</span>LEARNING_RATE <span class="token operator">*</span> pd_error_wrt_weight        <span class="token comment" spellcheck="true"># 4. 更新隐含层的权重系数</span>        <span class="token keyword">for</span> h <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> w_ih <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment" spellcheck="true"># ∂Eⱼ/∂wᵢ = ∂E/∂zⱼ * ∂zⱼ/∂wᵢ</span>                pd_error_wrt_weight <span class="token operator">=</span> pd_errors_wrt_hidden_neuron_total_net_input<span class="token punctuation">[</span>h<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">.</span>calculate_pd_total_net_input_wrt_weight<span class="token punctuation">(</span>w_ih<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># Δw = α * ∂Eⱼ/∂wᵢ</span>                self<span class="token punctuation">.</span>hidden_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>h<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">[</span>w_ih<span class="token punctuation">]</span> <span class="token operator">-=</span> self<span class="token punctuation">.</span>LEARNING_RATE <span class="token operator">*</span> pd_error_wrt_weight    <span class="token keyword">def</span> <span class="token function">calculate_total_error</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> training_sets<span class="token punctuation">)</span><span class="token punctuation">:</span>        total_error <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>training_sets<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            training_inputs<span class="token punctuation">,</span> training_outputs <span class="token operator">=</span> training_sets<span class="token punctuation">[</span>t<span class="token punctuation">]</span>            self<span class="token punctuation">.</span>feed_forward<span class="token punctuation">(</span>training_inputs<span class="token punctuation">)</span>            <span class="token keyword">for</span> o <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>training_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                total_error <span class="token operator">+=</span> self<span class="token punctuation">.</span>output_layer<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">.</span>calculate_error<span class="token punctuation">(</span>training_outputs<span class="token punctuation">[</span>o<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> total_error<span class="token keyword">class</span> <span class="token class-name">NeuronLayer</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_neurons<span class="token punctuation">,</span> bias<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 同一层的神经元共享一个截距项b</span>        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> bias <span class="token keyword">if</span> bias <span class="token keyword">else</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>neurons <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_neurons<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>neurons<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Neuron<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">inspect</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Neurons:'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> n <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>neurons<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' Neuron'</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span>            <span class="token keyword">for</span> w <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'  Weight:'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>neurons<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">.</span>weights<span class="token punctuation">[</span>w<span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'  Bias:'</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">feed_forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> neuron <span class="token keyword">in</span> self<span class="token punctuation">.</span>neurons<span class="token punctuation">:</span>            outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>neuron<span class="token punctuation">.</span>calculate_output<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs    <span class="token keyword">def</span> <span class="token function">get_outputs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> neuron <span class="token keyword">in</span> self<span class="token punctuation">.</span>neurons<span class="token punctuation">:</span>            outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>neuron<span class="token punctuation">.</span>output<span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs<span class="token keyword">class</span> <span class="token class-name">Neuron</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bias<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> bias        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">calculate_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>inputs <span class="token operator">=</span> inputs        self<span class="token punctuation">.</span>output <span class="token operator">=</span> self<span class="token punctuation">.</span>squash<span class="token punctuation">(</span>self<span class="token punctuation">.</span>calculate_total_net_input<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>output    <span class="token keyword">def</span> <span class="token function">calculate_total_net_input</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        total <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>inputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            total <span class="token operator">+=</span> self<span class="token punctuation">.</span>inputs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>weights<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> total <span class="token operator">+</span> self<span class="token punctuation">.</span>bias    <span class="token comment" spellcheck="true"># 激活函数sigmoid</span>    <span class="token keyword">def</span> <span class="token function">squash</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> total_net_input<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> math<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>total_net_input<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">calculate_pd_error_wrt_total_net_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target_output<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>calculate_pd_error_wrt_output<span class="token punctuation">(</span>target_output<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>calculate_pd_total_net_input_wrt_input<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true"># 每一个神经元的误差是由平方差公式计算的</span>    <span class="token keyword">def</span> <span class="token function">calculate_error</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target_output<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0.5</span> <span class="token operator">*</span> <span class="token punctuation">(</span>target_output <span class="token operator">-</span> self<span class="token punctuation">.</span>output<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>    <span class="token keyword">def</span> <span class="token function">calculate_pd_error_wrt_output</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> target_output<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token punctuation">(</span>target_output <span class="token operator">-</span> self<span class="token punctuation">.</span>output<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">calculate_pd_total_net_input_wrt_input</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>output <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>output<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">calculate_pd_total_net_input_wrt_weight</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>inputs<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 文中的例子:</span>nn <span class="token operator">=</span> NeuralNetwork<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> hidden_layer_weights<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.15</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.25</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden_layer_bias<span class="token operator">=</span><span class="token number">0.35</span><span class="token punctuation">,</span> output_layer_weights<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.45</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.55</span><span class="token punctuation">]</span><span class="token punctuation">,</span> output_layer_bias<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    nn<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.09</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> round<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>calculate_total_error<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.05</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.09</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#另外一个例子，可以把上面的例子注释掉再运行一下:</span><span class="token comment" spellcheck="true"># training_sets = [</span><span class="token comment" spellcheck="true">#     [[0, 0], [0]],</span><span class="token comment" spellcheck="true">#     [[0, 1], [1]],</span><span class="token comment" spellcheck="true">#     [[1, 0], [1]],</span><span class="token comment" spellcheck="true">#     [[1, 1], [0]]</span><span class="token comment" spellcheck="true"># ]</span><span class="token comment" spellcheck="true"># nn = NeuralNetwork(len(training_sets[0][0]), 5, len(training_sets[0][1]))</span><span class="token comment" spellcheck="true"># for i in range(10000):</span><span class="token comment" spellcheck="true">#     training_inputs, training_outputs = random.choice(training_sets)</span><span class="token comment" spellcheck="true">#     nn.train(training_inputs, training_outputs)</span><span class="token comment" spellcheck="true">#     print(i, nn.calculate_total_error(training_sets))</span></code></pre><pre class=" language-python"><code class="language-python"></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征选择</title>
      <link href="/2020/06/22/te-zheng-gong-cheng-te-zheng-xuan-ze/"/>
      <url>/2020/06/22/te-zheng-gong-cheng-te-zheng-xuan-ze/</url>
      
        <content type="html"><![CDATA[<p>数据预处理 python ：1、read_csv  2、info  3、isnull()   4、 fillna(inplace=True)  5、drop\ 增加、  6、LabelEncoder  7、get_dummies  8、check info </p><h1 id="第11讲-特征工程"><a href="#第11讲-特征工程" class="headerlink" title="第11讲 特征工程"></a>第11讲 特征工程</h1><h3 id="11-1-什么是特征工程"><a href="#11-1-什么是特征工程" class="headerlink" title="11.1 什么是特征工程"></a>11.1 什么是特征工程</h3><h3 id="11-2-一般特征构造和预处理"><a href="#11-2-一般特征构造和预处理" class="headerlink" title="11.2 一般特征构造和预处理"></a>11.2 一般特征构造和预处理</h3><h3 id="11-3-特征选择"><a href="#11-3-特征选择" class="headerlink" title="11.3 特征选择"></a>11.3 特征选择</h3><h3 id="11-4-过滤-filter-式特征选择方法"><a href="#11-4-过滤-filter-式特征选择方法" class="headerlink" title="11.4 过滤(filter)式特征选择方法"></a>11.4 过滤(filter)式特征选择方法</h3><h3 id="11-5-包裹式-Wrapper-特征选择方法"><a href="#11-5-包裹式-Wrapper-特征选择方法" class="headerlink" title="11.5 包裹式(Wrapper)特征选择方法"></a>11.5 包裹式(Wrapper)特征选择方法</h3><h3 id="11-6-递归逆向特征消除法-RFE"><a href="#11-6-递归逆向特征消除法-RFE" class="headerlink" title="11.6 递归逆向特征消除法(RFE)"></a>11.6 递归逆向特征消除法(RFE)</h3><h2 id="11-1-什么是特征工程-1"><a href="#11-1-什么是特征工程-1" class="headerlink" title="11.1 什么是特征工程"></a>11.1 什么是特征工程</h2><p>(1). 特征工程是指将原始数据转换为有效特征，使得模型能更好的表示潜在问题，从而提高模型对不可<br>见数据的预测准确性</p><p>(2). 特征工程研究子问题包括：</p><ul><li>特征重要性(feature importance)：对特征有用性的评估</li><li>特征选择(feature selection)：从许多特征到一些有用的特征</li><li>特征提取(feature extracton)：从原始数据中自动构建新特征</li><li>特征构造(Feature Construction)： 从原始数据中手工构造新特征 （手工设置一些独热编码等）</li></ul><p>(3). 特征工程的迭代过程</p><ul><li>特征头脑风暴： 真正进入问题，查看大量数据，研究其他问题的特性工程，看看能学到什么</li><li>特征设计：取决于你的问题，但你可以使用自动特征提取，手工特征构建和两者的混合</li><li>选择特性：使用不同的特性重要性评分和特性选择方法来为您的模型准备一个或多个“视图”(多组特征的集合)</li><li>评估模型：使用所选的特征估计模型对不可见数据的准确性</li></ul><p>(4). 特征工程的一般例子</p><ul><li>分解类别属性，如类别特征：颜色，取值为红、蓝和未知（数据类型不能出现在程序中，需转换为如数值型）</li><li>分解日期-时间，日期-时间包含很多信息，模型很难在其原生形式中利用这些信息，比如2014-09-20T20:45:40Z （类型不合适，方法如：时间差值法、离散法、权重法（差值范围设置权重））</li><li>重新定义数据单位 您的数据很可能包含数据单位，可以重新构造以更好地显示相关结构。这可能是转换为一个新的单位，或者是将一个速率分解为时间和其它数量组件</li></ul><h2 id="11-2-一般特征构造和预处理-1"><a href="#11-2-一般特征构造和预处理-1" class="headerlink" title="11.2 一般特征构造和预处理"></a>11.2 一般特征构造和预处理</h2><p>(1). 类别型数据(categorical data) 如上述的颜色</p><ul><li>对类别型数据特征需要区分是名义型(nominal) 还是顺序型(ordinal) , nominal 是无序的, 而ordinal 是有序的（衣服尺码等）</li></ul><p>(2). 类别型数据的处理方法</p><ul><li>nominal特征采用独热编码color size price classlabel</li><li>ordinal特征映射为相应的整数</li><li>对应 nominal 的 class labels（分类标签）, 也需要将其转换为数值表征，记住此时的数值只代表一个类别，并不表征数值关系</li></ul><p>(3). 特征标准化(feature scaling)</p><ul><li>Feature Scaling 很容易被遗忘, 虽然在 Decision tree和 random forests 时不用担心这个问题. 但在很多算法和模型下都是 scaling 后拟合效果更好.</li><li>两类常用方法: normalization 和 standardization.</li><li>normalization: rescaling to [0,1], 如 min-max scaling<img src="01.png" alt="title"></li><li>standardization（更多）: more practical, 因为在一些算法中, weights 初始值都设置为 0, 或者接近 0.</li><li>standardization 之后会更利用更新 weights. 并且 standardize 对 outlier（离群值） 更不敏感，受影响更小<img src="02.png" alt="title"></li></ul><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex11_1 创建示例数据集</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">[</span>            <span class="token punctuation">[</span><span class="token string">'green'</span><span class="token punctuation">,</span> <span class="token string">'M'</span><span class="token punctuation">,</span> <span class="token number">10.1</span><span class="token punctuation">,</span> <span class="token string">'class1'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token punctuation">[</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'L'</span><span class="token punctuation">,</span> <span class="token number">13.5</span><span class="token punctuation">,</span> <span class="token string">'class2'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>             <span class="token punctuation">[</span><span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'XL'</span><span class="token punctuation">,</span> <span class="token number">15.3</span><span class="token punctuation">,</span> <span class="token string">'class1'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'color'</span><span class="token punctuation">,</span> <span class="token string">'size'</span><span class="token punctuation">,</span> <span class="token string">'price'</span><span class="token punctuation">,</span> <span class="token string">'classlabel'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>color</th>      <th>size</th>      <th>price</th>      <th>classlabel</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>green</td>      <td>M</td>      <td>10.1</td>      <td>class1</td>    </tr>    <tr>      <th>1</th>      <td>red</td>      <td>L</td>      <td>13.5</td>      <td>class2</td>    </tr>    <tr>      <th>2</th>      <td>blue</td>      <td>XL</td>      <td>15.3</td>      <td>class1</td>    </tr>  </tbody></table></div><ul><li>color: nominal feature</li><li>size: ordinal feature, XL &gt; L &gt; M</li><li>price: numerical feature</li></ul><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex11_2 映射有序特征及还原</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npsize_mapping <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>           <span class="token string">'XL'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span>           <span class="token string">'L'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>           <span class="token string">'M'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>df<span class="token punctuation">[</span><span class="token string">'size'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'size'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>size_mapping<span class="token punctuation">)</span>df<span class="token comment" spellcheck="true">###分类标签编码</span>class_mapping <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;label:idx for idx, label in enumerate(np.unique(df['classlabel']))&amp;#125;</span>class_mappingdf<span class="token punctuation">[</span><span class="token string">'classlabel'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'classlabel'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>class_mapping<span class="token punctuation">)</span>df<span class="token comment" spellcheck="true">###转回</span>inv_label_mapping <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;idx:label for label, idx in class_mapping.items()&amp;#125;</span>df<span class="token punctuation">[</span><span class="token string">'classlabel'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'classlabel'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>inv_label_mapping<span class="token punctuation">)</span>df<span class="token comment" spellcheck="true">## # sklearn 中也有相应函数</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoderclass_le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>y <span class="token operator">=</span> class_le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'classlabel'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">)</span>y <span class="token comment" spellcheck="true">#</span><span class="token comment" spellcheck="true">#同样也可以反向转换</span>class_le<span class="token punctuation">.</span>inverse_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span></code></pre><pre><code>array(['class1', 'class2', 'class1'], dtype=object)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex11_3 nominal特征独热编码</span><span class="token comment" spellcheck="true">## 注意若使用LabelEncoder把nominal特征数值化，会引入特征顺序性</span>X <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'color'</span><span class="token punctuation">,</span> <span class="token string">'size'</span><span class="token punctuation">,</span> <span class="token string">'price'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuescolor_le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> color_le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 独热编码：为名义特征每个唯一值创建一个特征</span><span class="token comment" spellcheck="true"># ## 方法1</span><span class="token comment" spellcheck="true"># from sklearn.preprocessing import OneHotEncoder</span><span class="token comment" spellcheck="true"># ohe = OneHotEncoder(categorical_features=[0], sparse=False) #换后的变量在列中的位置,sparse返回常规的Numpy矩阵</span><span class="token comment" spellcheck="true"># ohe.fit_transform(X)</span><span class="token comment" spellcheck="true"># 方法2 pandas.get_dummies方法，只转换字符串列</span>pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'price'</span><span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">,</span><span class="token string">'size'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 为减少特征相关性，可以直接删除一个特征列，不会失去重要信息</span>pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'price'</span><span class="token punctuation">,</span><span class="token string">'color'</span><span class="token punctuation">,</span><span class="token string">'size'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> drop_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></code></pre><pre><code>[[1 nan 10.1] [2 nan 13.5] [0 nan 15.3]]</code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>price</th>      <th>size</th>      <th>color_green</th>      <th>color_red</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>10.1</td>      <td>NaN</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>1</th>      <td>13.5</td>      <td>NaN</td>      <td>0</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>15.3</td>      <td>NaN</td>      <td>0</td>      <td>0</td>    </tr>  </tbody></table></div><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#ex11_4</span><span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span>df_wine <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'wine.data'</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">)</span>df_wine<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Class label'</span><span class="token punctuation">,</span> <span class="token string">'Alcohol'</span><span class="token punctuation">,</span> <span class="token string">'Malic acid'</span><span class="token punctuation">,</span> <span class="token string">'Ash'</span><span class="token punctuation">,</span> <span class="token string">'Alcalinity of ash'</span><span class="token punctuation">,</span> <span class="token string">'Magnesium'</span><span class="token punctuation">,</span> <span class="token string">'Total phenols'</span><span class="token punctuation">,</span> <span class="token string">'Flavanoids'</span><span class="token punctuation">,</span> <span class="token string">'Nonflavanoid phenols'</span><span class="token punctuation">,</span> <span class="token string">'Proanthocyanins'</span><span class="token punctuation">,</span> <span class="token string">'Color intensity'</span><span class="token punctuation">,</span> <span class="token string">'Hue'</span><span class="token punctuation">,</span> <span class="token string">'OD280/OD315 of diluted wines'</span><span class="token punctuation">,</span> <span class="token string">'Proline'</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Class labels'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>df_wine<span class="token punctuation">[</span><span class="token string">'Class label'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## 一共三种已设置的label 1,2,3</span>df_wine<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token comment" spellcheck="true">## 数据集和测试集的拆分</span>X<span class="token punctuation">,</span> y <span class="token operator">=</span> df_wine<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_wine<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesX_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> \        train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> stratify<span class="token operator">=</span>y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#stratified 切分， 使切分后的数据集更好地保留标签的相对比例</span><span class="token comment" spellcheck="true"># 两种标准化的方法</span><span class="token comment" spellcheck="true"># min-max rescaling（0-1标准化）</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScalermms <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train_norm <span class="token operator">=</span> mms<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_test_norm <span class="token operator">=</span> mms<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 注意测试集是按照训练集的参数进行转换</span><span class="token comment" spellcheck="true"># standarzation（后面实验用的标准化方法）</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalerstdsc <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train_std <span class="token operator">=</span> stdsc<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_test_std <span class="token operator">=</span> stdsc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></code></pre><pre><code>Class labels [1 2 3]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 检验标准化后的均值  (均值为0)</span>X_train_std<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre><pre><code>array([ 6.89009781e-15,  1.68324136e-16,  3.79965996e-15,  2.85613826e-16,       -3.17846108e-16,  1.66264851e-15,  1.59818395e-16, -1.19886180e-15,        1.88827448e-15, -1.61519543e-15, -5.78390382e-16,  8.63108868e-16,       -1.33405831e-16])</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 检验标准化后的方差（方差为1）</span>X_train_std<span class="token punctuation">.</span>std<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre><pre><code>array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 检验标准化后的均值 （0-1标准化的）</span>X_train_norm<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre><pre><code>array([0.47472175, 0.31893089, 0.44765971, 0.45169962, 0.35911987,       0.46373749, 0.3637369 , 0.47612903, 0.38635668, 0.29747751,       0.50446122, 0.49426917, 0.3401017 ])</code></pre><h2 id="11-3-特征选择-1"><a href="#11-3-特征选择-1" class="headerlink" title="11.3 特征选择"></a>11.3 特征选择</h2><p>（1）. 含义：从给定的特征集合中选择出相关特征子集的过程</p><p>（2）. 为什么要做特征选择：</p><ul><li>减轻维数灾难，在部分特征上构建模型</li><li>去除不相关特征（与任务无关或冗余特征），降低学习任务的难度</li></ul><p>（3）. 特征子集的选择过程<img src="03.png" alt="title"></p><ul><li>特征产生过程( Generation Procedure )</li><li>产生过程是搜索特征子集的过程，负责为评价函数提供特征子集。</li><li>评价函数( Evaluation Function )</li><li>评价函数是评价一个特征子集好坏程度的一个准则。</li><li>停止准则( Stopping Criterion )</li><li>停止准则是与评价函数相关的，一般是一个阈值，当评价函数值达到这个阈值后就可停止搜索。</li><li>验证过程( Validation Procedure )</li><li>在验证数据集上验证选出来的特征子集的有效性</li></ul><p>(4). 搜索子集常用算法<img src="04.png" alt="title"><br>（框中为现常用的算法：启发式的方法）</p><ul><li>序列前向算法（Sequential Forward Selection， SFS）：特征子集X从空集开始，每次选择一个特征x加入特征子集X，使得特征函数J(X)最优。即每次都选择一个使得评价函数的取值达到最优的特征加入</li><li>序列后向算法（Sequential Backward Selection， SBS ）：从特征全集O开始，每次从特征集O中剔除一个特征x，使得剔除特征x后评价函数值达到最优</li><li>双向搜索(Bidirectional Search， BDS )：使用序列前向选择(SFS)从空集开始，同时使用序列后向</li><li>选择(SBS)从全集开始搜索，当两者搜索到一个相同的特征子集C时停止搜索</li></ul><p>(5). 子集评价(subset evaluation)</p><ul><li>使用某种评价函数对特征子集的优劣进行评估</li><li>评价函数包括皮尔逊相关系数、信息增益、距离计算模型、模型性能指标Acc, Auc, AIC或BIC等</li><li>子集评估是一个不断迭代的过程，在对新的特征子集进行评价得到评价值后，增加或减少特征，不能再提高特征子集的评价值则停止</li></ul><p>(6). 常用特征选择方法（主要看用前两者）</p><ul><li><p>根据特征子集搜索机制与子集评价机制相结合，可到到特征选择方法。大致分为三类： 过滤式<br>(filter)、包裹式(wrapper)、嵌入式(embedding)</p><ul><li><p>过滤式(filter)</p><ul><li><p>先对数据集进行特征选择，然后再训练学习器，两个过程相互独立</p></li><li><p>通常需要确定一个特定统计量来衡量特征的重要性</p></li><li><p>过滤式特征选择的评价统计量如：</p><p>  (1) 皮尔逊相关系数 判断特征和目标特征之间线性关系的统计量 <img src="05.png" alt="title"></p><p>  (2) 信息增益 选择特征X前后，Y的信息熵变化用Y的信息增益表示 <img src="06.png" alt="title"><br>  其中，<img src="07.png" alt="title">为分类变量Y的信息熵，<br>  <img src="08.png" alt="title">为对于某特征X的条件信息熵。<br>  假定存在特征子集X1和X2，若<img src="09.png" alt="title"> ，则宜选用特征子集X1</p></li></ul></li><li><p>包裹式(Wrapper)</p><ul><li>将特征选择过程与模型训练过程结合，根据特征子集得到的模型性能来评价特征子集</li><li>每次对特征子集的评价都要重复模型的训练和测试，计算开销大</li><li>认为学习器是“黑箱”模型，用以评价特征的学习算法很多，对子集的评价标准也很多，如准确率，召回率、AUC、赤池信息准则AIC、贝叶斯信息准则BIC、模型分类错误率等</li><li>可以得到对模型有提升效果的特征子集，但选择出的特征子集对不同模型不是普遍适用的</li><li>常用的特征选择方法例如递归特征消除 RFE(Recursive Feature Elimination)[Guyon, I., Weston, J., Barnhill,S., &amp; Vapnik, V., 2002]是一种常用的包裹式特征选择方法。该方法目标是通过不断构建模型递归地删除特征，对特征权重进行排序</li><li>SFS、GA</li></ul></li><li><p>嵌入式(embedding)</p><ul><li>将特征选择和模型训练在同一过程中完成，模型训练结束，特征选择也完成</li><li>与前两种方法（特征选择和学习器训练分开）不同，嵌入式方法在学习器训练过程中进行了特征选择</li><li>常见的嵌入式特征选择方法包括： L1正则化(LASSO)和基于树的模型（决策树、随机森林等）</li></ul></li></ul></li></ul><h2 id="11-4-sklearn中过滤-filter-式特征选择方法"><a href="#11-4-sklearn中过滤-filter-式特征选择方法" class="headerlink" title="11.4 sklearn中过滤(filter)式特征选择方法"></a>11.4 sklearn中过滤(filter)式特征选择方法</h2><p>(1). 选择特性的最简单方法是使用单变量统计( Univariate statistics)，即分别查看每个特征并检验统计<br>指标，以查看它是否与预测目标相关</p><p>(2). sklearn 中可以用到的 Univariate statistics 有：</p><ul><li>回归问题: f_regression</li><li>分类问题: chi2 （卡方）or f_classif</li></ul><p>(3). 得到统计量和 p 值之后，sklearn 又配套了不同的选择方法</p><ul><li>SelectKBest 除去k个得分最高的特征之外的所有特征</li><li>SelectPercentile 删除除用户指定的最高评分百分比外的所有特征</li><li>对每个特征使用通用的单变量统计检验 SelectFpr,false discovery rate SelectFdr, or family wise error SelectFwe.</li><li>GenericUnivariateSelect 允许使用可配置的策略执行单变量特性选择。这允许选择最好的单变量选择策略与超参数搜索估计</li></ul><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##  ex11_5  过滤式</span><span class="token comment" spellcheck="true"># 以 chi2 和 SelectKbest 为例（选择k个最好特征来进行最好选择）</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> chi2<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> SelectKBestselect <span class="token operator">=</span> SelectKBest<span class="token punctuation">(</span>chi2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>X_uni_selected <span class="token operator">=</span> select<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_train_std<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>X_uni_selected<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 可视化</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token comment" spellcheck="true"># 查看选出了哪几个 feature, 黑色是选出来的 （13个中选出了6个）</span>mask <span class="token operator">=</span> select<span class="token punctuation">.</span>get_support<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># visualize the mask. black is True, white is False</span>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>mask<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray_r'</span><span class="token punctuation">)</span></code></pre><pre><code>(124, 13)(124, 6)[False  True False  True  True False  True False False  True False False  True]&lt;matplotlib.image.AxesImage at 0x2884b6558c8&gt;</code></pre><p><img src="output_14_2.png" alt="png"></p><h2 id="11-5-包裹式-Wrapper-特征选择方法-1"><a href="#11-5-包裹式-Wrapper-特征选择方法-1" class="headerlink" title="11.5 包裹式(Wrapper)特征选择方法"></a>11.5 包裹式(Wrapper)特征选择方法</h2><p>(1). 序列前向算法（Sequential Forward Selection， SFS）或序列后向算法（Sequential Backward<br>Selection， SBS ）都是属于贪婪搜索算法，目的是根据分类器的性能来降低初始特征子空间的维<br>数，从而提高计算效率。SBS是经典的特征选择算法。</p><p>(2). 算法逻辑</p><ul><li>顺序地从完整的特征子集移除特征，直到新特征子空间包含需要的特征数量</li><li>为了确定每个阶段要删除哪些特征，需要定义评价函数 ，一般为分类器在去除特定特征前后的性能差异</li><li>每个阶段要删除的特征为该标准值最大的特征</li></ul><p>(3). 算法步骤</p><ul><li>用k=d初始化算法， d为特征空间xd 的维数</li><li><img src="010.png" alt="title">  x满足评价函数最大值</li><li><img src="011.png" alt="title"></li><li>如果k等于期望的特征数则停止；否则转往步骤2</li></ul><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex11_6</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>base <span class="token keyword">import</span> clone<span class="token keyword">from</span> itertools <span class="token keyword">import</span> combinations<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">class</span> <span class="token class-name">SBS</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''    k_features: 想要返回的理想特征数，estimator为分类器，scoring为评价函数    '''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> estimator<span class="token punctuation">,</span> k_features<span class="token punctuation">,</span>scoring<span class="token operator">=</span>accuracy_score<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>scoring <span class="token operator">=</span> scoring        self<span class="token punctuation">.</span>estimator <span class="token operator">=</span> clone<span class="token punctuation">(</span>estimator<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#深复制，生成一个新的分类器，否则将继续上一个分类器进行迭代，容易出现问题</span>        self<span class="token punctuation">.</span>k_features <span class="token operator">=</span> k_features        self<span class="token punctuation">.</span>test_size <span class="token operator">=</span> test_size        self<span class="token punctuation">.</span>random_state <span class="token operator">=</span> random_state    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">##选择</span>        X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span>test_size<span class="token operator">=</span>self<span class="token punctuation">.</span>test_size<span class="token punctuation">,</span>random_state<span class="token operator">=</span>self<span class="token punctuation">.</span>random_state<span class="token punctuation">)</span>        dim <span class="token operator">=</span> X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#维度</span>        self<span class="token punctuation">.</span>indices_ <span class="token operator">=</span> tuple<span class="token punctuation">(</span>range<span class="token punctuation">(</span>dim<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#索引</span>        self<span class="token punctuation">.</span>subsets_ <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>indices_<span class="token punctuation">]</span>        score <span class="token operator">=</span> self<span class="token punctuation">.</span>_calc_score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> self<span class="token punctuation">.</span>indices_<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>scores_ <span class="token operator">=</span> <span class="token punctuation">[</span>score<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">##以上为未进行特征选择之前的表现情况</span>        <span class="token keyword">while</span> dim <span class="token operator">></span> self<span class="token punctuation">.</span>k_features<span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">#进行特征选择</span>            scores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            subsets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> p <span class="token keyword">in</span> combinations<span class="token punctuation">(</span>self<span class="token punctuation">.</span>indices_<span class="token punctuation">,</span> r<span class="token operator">=</span>dim<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">##利用combinations函数选择减少一个特征后的集合，得到新的集合的索引进行操作。</span>                score <span class="token operator">=</span> self<span class="token punctuation">.</span>_calc_score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> p<span class="token punctuation">)</span>                scores<span class="token punctuation">.</span>append<span class="token punctuation">(</span>score<span class="token punctuation">)</span>                subsets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>p<span class="token punctuation">)</span>            best <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#选择最优</span>            self<span class="token punctuation">.</span>indices_ <span class="token operator">=</span> subsets<span class="token punctuation">[</span>best<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">#取出索引</span>            self<span class="token punctuation">.</span>subsets_<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>indices_<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#添加最优的索引</span>            dim<span class="token operator">-=</span><span class="token number">1</span>            self<span class="token punctuation">.</span>scores_<span class="token punctuation">.</span>append<span class="token punctuation">(</span>scores<span class="token punctuation">[</span>best<span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>k_score_ <span class="token operator">=</span> self<span class="token punctuation">.</span>scores_<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">transform</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment" spellcheck="true">#取出最好的特征子集的索引</span>        <span class="token keyword">return</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>indices_<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">_calc_score</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">##预测打分</span>        self<span class="token punctuation">.</span>estimator<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> indices<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>        y_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>estimator<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> indices<span class="token punctuation">]</span><span class="token punctuation">)</span>        score <span class="token operator">=</span> self<span class="token punctuation">.</span>scoring<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>        <span class="token keyword">return</span> score</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 使用SVM分类器实现SBS实例</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVCsvm <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#线性的支持向量机</span>svm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#拟合标准化之后的训练集</span>sbs <span class="token operator">=</span> SBS<span class="token punctuation">(</span>svm<span class="token punctuation">,</span> k_features<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>   <span class="token comment" spellcheck="true">#使用SBS方法生成实例化对象后进一步拟合我们的训练集</span>sbs<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span></code></pre><pre><code>&lt;__main__.SBS at 0x2884b6aeec8&gt;</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 绘制验证数据集上计算的svm分类器的分类准确度</span>k_feat <span class="token operator">=</span> <span class="token punctuation">[</span>len<span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> sbs<span class="token punctuation">.</span>subsets_<span class="token punctuation">]</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>k_feat<span class="token punctuation">,</span> sbs<span class="token punctuation">.</span>scores_<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span> <span class="token number">1.02</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Accuracy'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Number of features'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_18_0.png" alt="png"></p><p>当分类器的准确度达到100%时，特征数分别为k={6,7,8,9,10,11,12}</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 看最优特征子集</span>k6 <span class="token operator">=</span> list<span class="token punctuation">(</span>sbs<span class="token punctuation">.</span>subsets_<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df_wine<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">[</span>k6<span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre><code>Index(['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Flavanoids',       'OD280/OD315 of diluted wines'],      dtype='object')</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">### 评估在原始测试集上的性能</span>svm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training accuracy:'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_std<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Training accuracy: 1.0Test accuracy: 1.0</code></pre><pre class=" language-python"><code class="language-python">svm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>k6<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training accuracy:'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k6<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> k6<span class="token punctuation">]</span><span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Training accuracy: 0.9838709677419355Test accuracy: 0.9444444444444444</code></pre><p>上述分析表明：</p><ol><li>如果采用少于1/2的原始特征，测试集的预测准确度略有下降（可接受）。由于是小数据集，容易受到随机性<br>的影响</li><li>特征选择之后的所提供的特征信息并不比原始数据集少，缩小了数据集的规模</li><li>得到了更简单的模型，提高了模型解释性</li></ol><h2 id="11-6-递归逆向特征消除法-RFE-1"><a href="#11-6-递归逆向特征消除法-RFE-1" class="headerlink" title="11.6 递归逆向特征消除法(RFE)"></a>11.6 递归逆向特征消除法(RFE)</h2><p>（1）. 给定一个给特征赋予权重的外部估计量(例如，一个线性模型的系数)，递归特征消除(RFE)是通过递<br>归地考虑越来越小的特征集来选择特征</p><ul><li>首先，对学习器进行初始特征集的训练，并为每个特征分配权重</li><li>然后，从当前集合特征中去除绝对权重最小的特征</li><li>该过程不断重复，直到最终达到所需的要选择的特征数量</li></ul><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex11_7 sklearn中的RFE</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> RFE<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVCsvc <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">"linear"</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#分类器仍选择线性的支持向量机</span>rfe <span class="token operator">=</span> RFE<span class="token punctuation">(</span>estimator<span class="token operator">=</span>svc<span class="token punctuation">,</span>n_features_to_select<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 要选出几个 feature</span>        step<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 每次剔除出几个feature</span>rfe<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>X_rfe_selected <span class="token operator">=</span> rfe<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_train_std<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 查看选出了哪几个 feature</span>mask <span class="token operator">=</span> rfe<span class="token punctuation">.</span>get_support<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>mask<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'gray_r'</span><span class="token punctuation">)</span></code></pre><pre><code>[ True False False  True False False  True False False False  True  True  True]&lt;matplotlib.image.AxesImage at 0x2884b714e08&gt;</code></pre><p><img src="output_25_2.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>mask<span class="token punctuation">)</span></code></pre><pre><code>[ True False False  True False False  True False False False  True  True  True]</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>df_wine<span class="token punctuation">.</span>columns<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">[</span>mask<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">## 此处可以对比看一下SBS 选择出的最优特征子集，不同的选择方法选择出的特征子集可能不同</span></code></pre><pre><code>Index(['Alcohol', 'Alcalinity of ash', 'Flavanoids', 'Hue',       'OD280/OD315 of diluted wines', 'Proline'],      dtype='object')</code></pre><pre class=" language-python"><code class="language-python">svm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>mask<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training accuracy:'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> mask<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Test accuracy:'</span><span class="token punctuation">,</span> svm<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> mask<span class="token punctuation">]</span><span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Training accuracy: 0.9838709677419355Test accuracy: 0.9814814814814815</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文本分类</title>
      <link href="/2020/06/02/wen-ben-fen-lei/"/>
      <url>/2020/06/02/wen-ben-fen-lei/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token operator">%</span>run contractions<span class="token punctuation">.</span>py</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_1 导入必要的包</span><span class="token keyword">from</span> contractions <span class="token keyword">import</span> CONTRACTION_MAP<span class="token keyword">import</span> re<span class="token keyword">import</span> nltk<span class="token keyword">import</span> string<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> WordNetLemmatizer<span class="token comment" spellcheck="true">## 载入停用词</span>stopword_list <span class="token operator">=</span> nltk<span class="token punctuation">.</span>corpus<span class="token punctuation">.</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">'english'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 构建词形还原实例对象</span>wnl <span class="token operator">=</span> WordNetLemmatizer<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_2 tokenize_text实现词语切分</span><span class="token keyword">def</span> <span class="token function">tokenize_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokens <span class="token operator">=</span> nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span> <span class="token comment" spellcheck="true">#去除词前后多余空格</span>    <span class="token keyword">return</span> tokens</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 练习对以下语料进行分词</span>CORPUS <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token string">'the sky is blue'</span><span class="token punctuation">,</span>        <span class="token string">'sky is blue and sky is beatiful'</span><span class="token punctuation">,</span>        <span class="token string">'the beatiful sky is so blue'</span><span class="token punctuation">,</span>        <span class="token string">'I love blue cheese'</span><span class="token punctuation">]</span>tokinze_corpus <span class="token operator">=</span> <span class="token punctuation">[</span>tokenize_text<span class="token punctuation">(</span>item<span class="token punctuation">)</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> CORPUS<span class="token punctuation">]</span>tokinze_corpus</code></pre><pre><code>[['the', 'sky', 'is', 'blue'], ['sky', 'is', 'blue', 'and', 'sky', 'is', 'beatiful'], ['the', 'beatiful', 'sky', 'is', 'so', 'blue'], ['I', 'love', 'blue', 'cheese']]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_3 扩展缩写词</span><span class="token keyword">def</span> <span class="token function">expand_contractions</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> contraction_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span>    contractions_pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'(&amp;#123;&amp;#125;)'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">'|'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>contraction_mapping<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                         flags<span class="token operator">=</span>re<span class="token punctuation">.</span>IGNORECASE<span class="token operator">|</span>re<span class="token punctuation">.</span>DOTALL<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##忽略大小写和里面的.</span>    <span class="token keyword">def</span> <span class="token function">expand_match</span><span class="token punctuation">(</span>contraction<span class="token punctuation">)</span><span class="token punctuation">:</span>        match <span class="token operator">=</span> contraction<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        first_char <span class="token operator">=</span> match<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        expanded_contraction <span class="token operator">=</span> contraction_mapping<span class="token punctuation">.</span>get<span class="token punctuation">(</span>match<span class="token punctuation">)</span>\                                <span class="token keyword">if</span> contraction_mapping<span class="token punctuation">.</span>get<span class="token punctuation">(</span>match<span class="token punctuation">)</span>\                                <span class="token keyword">else</span> contraction_mapping<span class="token punctuation">.</span>get<span class="token punctuation">(</span>match<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        expanded_contraction <span class="token operator">=</span> first_char <span class="token operator">+</span> expanded_contraction<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> expanded_contraction    expanded_text <span class="token operator">=</span> contractions_pattern<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>expand_match<span class="token punctuation">,</span> text<span class="token punctuation">)</span>    expanded_text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">"'"</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">,</span> expanded_text<span class="token punctuation">)</span>    <span class="token keyword">return</span> expanded_text</code></pre><pre class=" language-python"><code class="language-python">text <span class="token operator">=</span> <span class="token string">"It's not true.I'm not sure.I'll do it"</span>expanded_text <span class="token operator">=</span> expand_contractions<span class="token punctuation">(</span>text<span class="token punctuation">,</span>CONTRACTION_MAP<span class="token punctuation">)</span>expanded_text</code></pre><pre><code>'It is not true.I am not sure.I will do it'</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##15_4 使用词形还原函数把单词变换为词根形式</span><span class="token keyword">from</span> pattern<span class="token punctuation">.</span>en <span class="token keyword">import</span> tag<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> wordnet <span class="token keyword">as</span> wn<span class="token comment" spellcheck="true">## 将词性标签从Penn treebank语法格式转换为WordNet语法格式</span><span class="token keyword">def</span> <span class="token function">pos_tag_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">penn_to_wn_tags</span><span class="token punctuation">(</span>pos_tag<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'J'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>ADJ        <span class="token keyword">elif</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'V'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>VERB        <span class="token keyword">elif</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'N'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>NOUN        <span class="token keyword">elif</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'R'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>ADV        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> None    tagged_text <span class="token operator">=</span> tag<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    tagged_lower_text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>word<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>penn_to_wn_tags<span class="token punctuation">(</span>pos_tag<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word<span class="token punctuation">,</span> pos_tag <span class="token keyword">in</span> tagged_text<span class="token punctuation">]</span>    <span class="token keyword">return</span> tagged_lower_text<span class="token keyword">def</span> <span class="token function">lemmatize_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    pos_tagged_text <span class="token operator">=</span> pos_tag_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    lemmatized_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>wnl<span class="token punctuation">.</span>lemmatize<span class="token punctuation">(</span>word<span class="token punctuation">,</span> pos_tag<span class="token punctuation">)</span> <span class="token keyword">if</span> pos_tag  <span class="token keyword">else</span> word <span class="token keyword">for</span> word<span class="token punctuation">,</span> pos_tag <span class="token keyword">in</span> pos_tagged_text<span class="token punctuation">]</span>    lemmatized_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>lemmatized_tokens<span class="token punctuation">)</span>    <span class="token keyword">return</span> lemmatized_text</code></pre><pre class=" language-python"><code class="language-python">text <span class="token operator">=</span> <span class="token string">'He jumps every day. He is jumping. He jumped in the morning toady. He is very tall.'</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 15_5 特殊符号和字符的去除</span><span class="token keyword">def</span> <span class="token function">remove_special_characters</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokens <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'[&amp;#123;&amp;#125;]'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>re<span class="token punctuation">.</span>escape<span class="token punctuation">(</span>string<span class="token punctuation">.</span>punctuation<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    filtered_tokens <span class="token operator">=</span> list<span class="token punctuation">(</span>filter<span class="token punctuation">(</span>None<span class="token punctuation">,</span> <span class="token punctuation">[</span>pattern<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">,</span> token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    filtered_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>filtered_tokens<span class="token punctuation">)</span>    <span class="token keyword">return</span> filtered_text</code></pre><pre class=" language-python"><code class="language-python">text <span class="token operator">=</span> <span class="token string">'He jumps every day. He is jumping. %%^He jumped in the morning toady.()))+=He is very tall.'</span>text <span class="token operator">=</span> remove_special_characters<span class="token punctuation">(</span>text<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 15_6 去除停用词</span><span class="token keyword">def</span> <span class="token function">remove_stopwords</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokens <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    filtered_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> token <span class="token operator">not</span> <span class="token keyword">in</span> stopword_list<span class="token punctuation">]</span>    filtered_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>filtered_tokens<span class="token punctuation">)</span>    <span class="token keyword">return</span> filtered_text</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 15_7 将所有函数连接在一起，输入文本文档语料，进行规范化处理，返回规范化处理后的文本文档语料</span><span class="token keyword">def</span> <span class="token function">normalize_corpus</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> tokenize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    normalized_corpus <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> text <span class="token keyword">in</span> corpus<span class="token punctuation">:</span>        text <span class="token operator">=</span> expand_contractions<span class="token punctuation">(</span>text<span class="token punctuation">,</span> CONTRACTION_MAP<span class="token punctuation">)</span>        text <span class="token operator">=</span> lemmatize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>        text <span class="token operator">=</span> remove_special_characters<span class="token punctuation">(</span>text<span class="token punctuation">)</span>        text <span class="token operator">=</span> remove_stopwords<span class="token punctuation">(</span>text<span class="token punctuation">)</span>        normalized_corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>        <span class="token keyword">if</span> tokenize<span class="token punctuation">:</span>            text <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>            normalized_corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    <span class="token keyword">return</span> normalized_corpus</code></pre><pre class=" language-python"><code class="language-python">normalize_corpus<span class="token punctuation">(</span>CORPUS<span class="token punctuation">)</span></code></pre><pre><code>['sky blue', 'sky blue sky beatiful', 'beatiful sky blue', 'love blue cheese']</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_8 定义一个基于词袋的特征提取模块</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizerCORPUS <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token string">'the sky is blue'</span><span class="token punctuation">,</span>        <span class="token string">'sky is blue and sky is beatiful'</span><span class="token punctuation">,</span>        <span class="token string">'the beatiful sky is so blue'</span><span class="token punctuation">,</span>        <span class="token string">'I love blue cheese'</span><span class="token punctuation">]</span>new_doc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'loving this blue sky today'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">## ngram_range参数作为n元分词的特征,如(1,3)将建立包括unigram, bigram和trigram的向量空间</span><span class="token keyword">def</span> <span class="token function">bow_extractor</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    vectorizer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>min_df<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##min_df=1表示最小频率为1的词项都会被考虑</span>    features <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>    <span class="token keyword">return</span> vectorizer<span class="token punctuation">,</span> featuresbow_vectorizer<span class="token punctuation">,</span> bow_features <span class="token operator">=</span> bow_extractor<span class="token punctuation">(</span>CORPUS<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>bow_vectorizer<span class="token punctuation">.</span>vocabulary_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>bow_vectorizer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>bow_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>new_doc_features <span class="token operator">=</span> bow_vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>new_doc<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>new_doc_features<span class="token punctuation">)</span></code></pre><pre><code>{'the': 8, 'sky': 6, 'is': 4, 'blue': 2, 'and': 0, 'beatiful': 1, 'so': 7, 'love': 5, 'cheese': 3}['and', 'beatiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the'][[0 0 1 0 1 0 1 0 1] [1 1 1 0 2 0 2 0 0] [0 1 1 0 1 0 1 1 1] [0 0 1 1 0 1 0 0 0]][[0 0 1 0 0 0 1 0 0]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_9</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfTransformer<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npnp<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">tfidf_transformer</span><span class="token punctuation">(</span>bow_matrix<span class="token punctuation">)</span><span class="token punctuation">:</span>    transformer <span class="token operator">=</span> TfidfTransformer<span class="token punctuation">(</span>use_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                         norm<span class="token operator">=</span><span class="token string">'l2'</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true">##进行L2归一化，返回长度为1的向量 </span>                         smooth_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    tfidf_matrix <span class="token operator">=</span> transformer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>bow_matrix<span class="token punctuation">)</span>    <span class="token keyword">return</span> transformer<span class="token punctuation">,</span> tfidf_matrixtfidf_trans<span class="token punctuation">,</span> tfidf_features <span class="token operator">=</span> tfidf_transformer<span class="token punctuation">(</span>bow_features<span class="token punctuation">)</span>tfidf_features <span class="token operator">=</span> tfidf_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>bow_vectorizer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tfidf_features<span class="token punctuation">)</span>nd_tfidf <span class="token operator">=</span> tfidf_trans<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>new_doc_features<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>nd_tfidf<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 实现一个通用函数，直接从原始文档中计算文档基于tfidf的特征向量</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer<span class="token comment" spellcheck="true">## TfidfVectorizer类把原始文档作为输入，在内部计算词频和逆文档频率，直接计算tfidf向量</span><span class="token keyword">def</span> <span class="token function">tfidf_extractor</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    vectorizer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>                                min_df<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                norm<span class="token operator">=</span><span class="token string">'l2'</span><span class="token punctuation">,</span>                                smooth_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                use_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">)</span>    features <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>    <span class="token keyword">return</span> vectorizer<span class="token punctuation">,</span>featurestfidf_vectorizer<span class="token punctuation">,</span> tdidf_features <span class="token operator">=</span> tfidf_extractor<span class="token punctuation">(</span>CORPUS<span class="token punctuation">)</span>tdidf_features <span class="token operator">=</span> tdidf_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>nd_tfidf <span class="token operator">=</span> tfidf_vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>new_doc<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tdidf_features<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>nd_tfidf<span class="token punctuation">)</span></code></pre><pre><code>['and', 'beatiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the'][[0.   0.   0.4  0.   0.49 0.   0.49 0.   0.6 ] [0.44 0.35 0.23 0.   0.56 0.   0.56 0.   0.  ] [0.   0.43 0.29 0.   0.35 0.   0.35 0.55 0.43] [0.   0.   0.35 0.66 0.   0.66 0.   0.   0.  ]][[0.   0.   0.63 0.   0.   0.   0.77 0.   0.  ]][[0.   0.   0.4  0.   0.49 0.   0.49 0.   0.6 ] [0.44 0.35 0.23 0.   0.56 0.   0.56 0.   0.  ] [0.   0.43 0.29 0.   0.35 0.   0.35 0.55 0.43] [0.   0.   0.35 0.66 0.   0.66 0.   0.   0.  ]][[0.   0.   0.63 0.   0.   0.   0.77 0.   0.  ]]</code></pre><pre class=" language-python"><code class="language-python">nd_tfidf <span class="token operator">=</span> tfidf_trans<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>new_doc_features<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>nd_tfidf<span class="token punctuation">)</span></code></pre><pre><code>[[0.   0.   0.63 0.   0.   0.   0.77 0.   0.  ]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer<span class="token comment" spellcheck="true">## TfidfVectorizer类把原始文档作为输入，在内部计算词频和逆文档频率，直接计算tfidf向量</span><span class="token keyword">def</span> <span class="token function">tfidf_extractor</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    vectorizer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>                                min_df<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                norm<span class="token operator">=</span><span class="token string">'l2'</span><span class="token punctuation">,</span>                                smooth_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                use_idf<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">)</span>    features <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>    <span class="token keyword">return</span> vectorizer<span class="token punctuation">,</span>featurestfidf_vectorizer<span class="token punctuation">,</span> tdidf_features <span class="token operator">=</span> tfidf_extractor<span class="token punctuation">(</span>CORPUS<span class="token punctuation">)</span>tdidf_features <span class="token operator">=</span> tdidf_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>nd_tfidf <span class="token operator">=</span> tfidf_vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>new_doc<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tdidf_features<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>nd_tfidf<span class="token punctuation">)</span></code></pre><pre><code>[[0.   0.   0.4  0.   0.49 0.   0.49 0.   0.6 ] [0.44 0.35 0.23 0.   0.56 0.   0.56 0.   0.  ] [0.   0.43 0.29 0.   0.35 0.   0.35 0.55 0.43] [0.   0.   0.35 0.66 0.   0.66 0.   0.   0.  ]][[0.   0.   0.63 0.   0.   0.   0.77 0.   0.  ]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_10 使用训练语料建立word2vec模型，提取文本特征</span><span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span><span class="token keyword">import</span> gensim<span class="token keyword">import</span> nltk<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npCORPUS <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token string">'the sky is blue'</span><span class="token punctuation">,</span>        <span class="token string">'sky is blue and sky is beautiful'</span><span class="token punctuation">,</span>        <span class="token string">'the beatiful sky is so blue'</span><span class="token punctuation">,</span>        <span class="token string">'I love blue cheese'</span><span class="token punctuation">]</span>new_doc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'loving this blue sky today'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 对训练语料分词</span>TOKENIZED_CORPUS <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> CORPUS<span class="token punctuation">]</span>tokenized_new_doc <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span> <span class="token keyword">for</span> sentence <span class="token keyword">in</span> new_doc<span class="token punctuation">]</span><span class="token comment" spellcheck="true">##在训练集上构建词向量模型</span>model <span class="token operator">=</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>TOKENIZED_CORPUS<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> window<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>min_count<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> sample<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 模型为单词表中的每个单词创建一个向量表示，可以输入下面的代码查看</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">[</span><span class="token string">'sky'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">[</span><span class="token string">'blue'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre><code>[-0.04680252  0.00913968 -0.02815402  0.0082107  -0.02250418  0.02936089  0.04233479 -0.02649353  0.04165124  0.00874214][ 0.01168812 -0.03595724 -0.03161702  0.04333565 -0.00992669  0.00657995  0.02869998  0.02371777  0.03715583 -0.03389712]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_11 采用平均加权词向量，保证最后的特征维度一致性</span><span class="token keyword">def</span> <span class="token function">average_word_vectors</span><span class="token punctuation">(</span>words<span class="token punctuation">,</span> model<span class="token punctuation">,</span> vocabulary<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''    words: 特定文档的单词列表    model: 训练好的词向量模型    vocabulary: 词汇列表    num_features: 词向量长度    '''</span>    feature_vector <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_features<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span><span class="token string">'float64'</span><span class="token punctuation">)</span>    nwords <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>        <span class="token keyword">if</span> word <span class="token keyword">in</span> vocabulary<span class="token punctuation">:</span>            nwords <span class="token operator">+=</span> <span class="token number">1</span>            feature_vector <span class="token operator">=</span> np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>feature_vector<span class="token punctuation">,</span>model<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> nwords<span class="token punctuation">:</span>        feature_vector <span class="token operator">=</span> np<span class="token punctuation">.</span>divide<span class="token punctuation">(</span>feature_vector<span class="token punctuation">,</span> nwords<span class="token punctuation">)</span>    <span class="token keyword">return</span> feature_vector<span class="token comment" spellcheck="true">## 实现语料库多个文档平均词向量的计算</span><span class="token keyword">def</span> <span class="token function">averaged_word_vectorizer</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> model<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span><span class="token punctuation">:</span>    vocabulary <span class="token operator">=</span> set<span class="token punctuation">(</span>model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>index2word<span class="token punctuation">)</span>    features <span class="token operator">=</span> <span class="token punctuation">[</span>average_word_vectors<span class="token punctuation">(</span>tokenized_sentence<span class="token punctuation">,</span> model<span class="token punctuation">,</span> vocabulary<span class="token punctuation">,</span> num_features<span class="token punctuation">)</span>                 <span class="token keyword">for</span> tokenized_sentence <span class="token keyword">in</span> corpus<span class="token punctuation">]</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 在示例语料CORPUS上执行</span>avg_word_vec_features <span class="token operator">=</span> averaged_word_vectorizer<span class="token punctuation">(</span>corpus<span class="token operator">=</span>TOKENIZED_CORPUS<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> num_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>avg_word_vec_features<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 在测试语料new_doc上计算平均词向量</span>nd_avg_word_vec_features <span class="token operator">=</span> averaged_word_vectorizer<span class="token punctuation">(</span>corpus<span class="token operator">=</span>tokenized_new_doc<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> num_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>nd_avg_word_vec_features<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>[[ 0.004  0.007 -0.013  0.031 -0.029 -0.004  0.009  0.015  0.022  0.005] [-0.003  0.002 -0.029  0.031 -0.028 -0.006  0.027  0.007  0.043 -0.001] [ 0.004  0.007 -0.013  0.031 -0.029 -0.004  0.009  0.015  0.022  0.005] [ 0.012 -0.036 -0.032  0.043 -0.01   0.007  0.029  0.024  0.037 -0.034]][[-0.018 -0.013 -0.03   0.026 -0.016  0.018  0.036 -0.001  0.039 -0.013]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_12 模型评估指标计算</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counteractual_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'spam'</span><span class="token punctuation">,</span> <span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span>            <span class="token string">'ham'</span><span class="token punctuation">,</span> <span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span>            <span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span>            <span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">]</span>predicted_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'spam'</span><span class="token punctuation">,</span> <span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span>            <span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span>            <span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span>            <span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'spam'</span><span class="token punctuation">]</span>ac <span class="token operator">=</span> Counter<span class="token punctuation">(</span>actual_labels<span class="token punctuation">)</span>pc <span class="token operator">=</span> Counter<span class="token punctuation">(</span>predicted_labels<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Actual counts'</span><span class="token punctuation">,</span> ac<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Predicted counts'</span><span class="token punctuation">,</span> pc<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 建立混淆矩阵</span>cm <span class="token operator">=</span> metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>y_true<span class="token operator">=</span>actual_labels<span class="token punctuation">,</span>                            y_pred <span class="token operator">=</span> predicted_labels<span class="token punctuation">,</span>                            labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>cm<span class="token punctuation">,</span>                columns<span class="token operator">=</span>pd<span class="token punctuation">.</span>MultiIndex<span class="token punctuation">(</span>levels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Predicted:'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                            <span class="token punctuation">[</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                        labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                index <span class="token operator">=</span> pd<span class="token punctuation">.</span>MultiIndex<span class="token punctuation">(</span>levels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Actual:'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                            <span class="token punctuation">[</span><span class="token string">'spam'</span><span class="token punctuation">,</span><span class="token string">'ham'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                        labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 利用metrics模块计算评价指标</span>positive_class <span class="token operator">=</span> <span class="token string">'spam'</span><span class="token comment" spellcheck="true">##准确率</span>accuracy <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>actual_labels<span class="token punctuation">,</span>y_pred<span class="token operator">=</span>predicted_labels<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##精确率</span>precision <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>actual_labels<span class="token punctuation">,</span>y_pred<span class="token operator">=</span>predicted_labels<span class="token punctuation">,</span>pos_label<span class="token operator">=</span>positive_class<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##召回率</span>recall <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>actual_labels<span class="token punctuation">,</span>y_pred<span class="token operator">=</span>predicted_labels<span class="token punctuation">,</span>pos_label<span class="token operator">=</span>positive_class<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## F1 score</span>f1 <span class="token operator">=</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>actual_labels<span class="token punctuation">,</span>y_pred<span class="token operator">=</span>predicted_labels<span class="token punctuation">,</span>pos_label<span class="token operator">=</span>positive_class<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span>accuracy<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'precision'</span><span class="token punctuation">,</span>precision<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'recall'</span><span class="token punctuation">,</span> recall<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'f1'</span><span class="token punctuation">,</span>f1<span class="token punctuation">)</span></code></pre><pre><code>Actual counts [('spam', 10), ('ham', 10)]Predicted counts [('spam', 11), ('ham', 9)]             Predicted:                       spam hamActual: spam          5   5        ham           6   4accuracy 0.45precision 0.45recall 0.5f1 0.48</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_13 数据准备</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> fetch_20newsgroups<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    data <span class="token operator">=</span> fetch_20newsgroups<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">'all'</span><span class="token punctuation">,</span>                             shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                             remove<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'headers'</span><span class="token punctuation">,</span><span class="token string">'footers'</span><span class="token punctuation">,</span><span class="token string">'quotes'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#去除新闻组帖子中的文件头、文件尾、引用</span>    <span class="token keyword">return</span> data<span class="token comment" spellcheck="true">##拆分训练集和测试集</span><span class="token keyword">def</span> <span class="token function">prepare_datasets</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> test_proportion<span class="token punctuation">)</span><span class="token punctuation">:</span>    train_X<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> test_size<span class="token operator">=</span>test_proportion<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> train_X<span class="token punctuation">,</span> test_X<span class="token punctuation">,</span> train_y<span class="token punctuation">,</span> test_y<span class="token comment" spellcheck="true">## 去除空新闻</span><span class="token keyword">def</span> <span class="token function">remove_empty_docs</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>    filtered_corpus <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    filtered_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> doc<span class="token punctuation">,</span> label <span class="token keyword">in</span> zip<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> doc<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            filtered_corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>doc<span class="token punctuation">)</span>            filtered_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label<span class="token punctuation">)</span>    <span class="token keyword">return</span> filtered_corpus<span class="token punctuation">,</span> filtered_labels<span class="token comment" spellcheck="true">## 获得数据</span>dataset <span class="token operator">=</span> get_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 输出所有类别名字和标签，标签名称</span><span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>target<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 得到数据集及相应标签</span>corpus<span class="token punctuation">,</span> labels <span class="token operator">=</span> dataset<span class="token punctuation">.</span>data<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>targetcorpus<span class="token punctuation">,</span> labels <span class="token operator">=</span> remove_empty_docs<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##18331</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##标签类别</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##标签计数</span><span class="token comment" spellcheck="true"># # ## 输出一个数据样本，查看内容和标签，标签名称</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Sample document:\n'</span><span class="token punctuation">,</span> corpus<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Class label:\n'</span><span class="token punctuation">,</span> labels<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print('Actual class label:', dataset.target_names[labels[10]])</span><span class="token comment" spellcheck="true"># ##拆分数据集，测试集比例占corpus的30%</span>train_corpus<span class="token punctuation">,</span> test_corpus<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span> test_labels <span class="token operator">=</span> prepare_datasets<span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> labels<span class="token punctuation">,</span>test_proportion<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">)</span></code></pre><pre><code>['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc'][10  3 17 ...  3  1  7]18331[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19][779 955 947 964 929 982 959 937 969 958 975 962 958 960 955 975 886 919 756 606]Sample document: the blood of the lamb.This will be a hard task, because most cultures used most animalsfor blood sacrifices. It has to be something related to our currentpost-modernism state. Hmm, what about used computers?Cheers,KentClass label: 19</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_14 利用normalization.py模块（和该文件放同一目录）对上述数据集进行规范化处理</span><span class="token comment" spellcheck="true">## 注意此过程较慢，课后完成</span><span class="token keyword">from</span> normalization <span class="token keyword">import</span> normalize_corpusnorm_train_corpus <span class="token operator">=</span> normalize_corpus<span class="token punctuation">(</span>train_corpus<span class="token punctuation">)</span>norm_test_corpus <span class="token operator">=</span> normalize_corpus<span class="token punctuation">(</span>test_corpus<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##训练集norm_train_corpus存为pkl文件</span><span class="token keyword">import</span> picklef_ntc<span class="token operator">=</span>open<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\python projects\《数据挖掘》\norm_train_corpus.pkl'</span><span class="token punctuation">,</span><span class="token string">'wb'</span><span class="token punctuation">)</span>pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>norm_train_corpus<span class="token punctuation">,</span>f_ntc<span class="token punctuation">)</span>f_ntc<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ## 测试能否导入</span>f_ntc <span class="token operator">=</span> open<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\python projects\《数据挖掘》\norm_train_corpus.pkl'</span><span class="token punctuation">,</span><span class="token string">'rb'</span><span class="token punctuation">)</span>norm_train_corpus_pkl <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f_ntc<span class="token punctuation">)</span>f_ntc<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 测试集norm_test_corpus存为pkl文件</span>f_ntest <span class="token operator">=</span> open<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\python projects\《数据挖掘》\norm_test_corpus.pkl'</span><span class="token punctuation">,</span><span class="token string">'wb'</span><span class="token punctuation">)</span>pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>norm_test_corpus<span class="token punctuation">,</span> f_ntest<span class="token punctuation">)</span>f_ntest<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##测试测试集能否导入</span>f_ntest <span class="token operator">=</span> open<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\python projects\《数据挖掘》\norm_test_corpus.pkl'</span><span class="token punctuation">,</span><span class="token string">'rb'</span><span class="token punctuation">)</span>norm_test_corpus_pkl <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f_ntest<span class="token punctuation">)</span>f_ntest<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>norm_test_corpus_pkl<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre><code>['quite confident essence exist propose define thing one without definition definition know essence property property doe god property number exist reality abstract entity invent see post altmessianic possibility tritheism phiolosophical point view', 'forgive day read newsgroup physician post theraputic us vitamin b6 seem locate article recall mention safe limit look balance 100 time release formulation walgreens note 100 mg b6 thousand time rda safe also condition b6 theraputic mail would fine want clog net', 'consolation similar problem recall exit session fullscreen mode menu title change scrambled version icon title font something like start happen use icontitlefacename winini change desktop font arial stop exit session fullscreen mode mac use something similar computer weird', 'accord 1990 harvard alumnus directory mr okeefe fail graduate may decide indeed educate anywhere', '1 make new newsgroup call talkpoliticsgunsparanoid talkpoliticsgunstheyrheretotakemeaway 2 move posting waco burn guess 3 stop post newsgroup glad try save us evil goverment would mail regular mail let us say 1000 people thomas parsli everybody talk evil arise europe label reactionary late 1930s could negotiate hitler trust keep end bargain least stalin chamberlin think guess forget teach country overrun german wwii eh thomas sorry consider outrage government excess everytime israeli conduct mass operation terrorist group actively kill citizen soldier world get indignant ok u assault citizen religous minority accuse sexual deviation hoarding weapon find real ironic happen day al gore arrive poland recognize sacrifice make warsaw ghetto justification raise armed assault blackclad troop armor support', 'well temp file thing create obvious problem impossible use cview view cdrom base picture collection non window viewer work properly cirrusbased 24 bit vga', 'well always try find pc dealer sell guaranteed memory work company grow 40 year order hundred computer per year never fail machine come bad simms wonder pc mac crash tell always think incompetent write design software well think way anymore especially result get replace bad simms machine others work moral story make sure memory good would willing bet lot simms either soft hard error even know every awhile bad simms make life hell get plain sick deal people complaint thier machine crash lose thier work case wonder already guess work department service die perogative line work moral memory tested simm hardware tester mean simple little software program run machine simms complicate little beast need special hardware test effectively interested get one nifty little device cheap write back make life little bit easier besides pay short time loss productivity people would deal thier machine commit suicide', 'hi would like substitute exciting win31 open logo company logo boot time matter replace logo file logo format company logo thanks', 'everywhere see hear christianity due evangalistic nature witness spread gospel etc want know anyone else become christian twenty five word less zero one take us peace plastic 1993', 'useful article one 1989 issue transaction graphic believe maureen stone one author sorry specific reference article actually general give way decide whether give cubic bezier curve contain cusp intersection point whatever wierdness treatment also available siggraph 89 course note course call math siggraph something like']</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_15 基于不同技术提取3种特征</span><span class="token keyword">from</span> feature_extractors <span class="token keyword">import</span> bow_extractor<span class="token punctuation">,</span> tfidf_extractor<span class="token keyword">from</span> feature_extractors <span class="token keyword">import</span> averaged_word_vectorizer<span class="token comment" spellcheck="true">#from feature_extractors import tfidf_weighted_averaged_word_vectorizer</span><span class="token keyword">import</span> nltk<span class="token keyword">import</span> gensim<span class="token comment" spellcheck="true">## bag of words features</span>bow_vectorizer<span class="token punctuation">,</span> bow_train_features <span class="token operator">=</span> bow_extractor<span class="token punctuation">(</span>norm_train_corpus<span class="token punctuation">)</span>bow_test_features <span class="token operator">=</span> bow_vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>norm_test_corpus<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## tfidf features</span>tfidf_vectorizer<span class="token punctuation">,</span> tfidf_train_features <span class="token operator">=</span> tfidf_extractor<span class="token punctuation">(</span>norm_train_corpus<span class="token punctuation">)</span>tfidf_test_features <span class="token operator">=</span> tfidf_vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>norm_test_corpus<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## tokenize documents</span>tokenized_train <span class="token operator">=</span><span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>                 <span class="token keyword">for</span> text <span class="token keyword">in</span> norm_train_corpus<span class="token punctuation">]</span>tokenized_test <span class="token operator">=</span> <span class="token punctuation">[</span>nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>                 <span class="token keyword">for</span> text <span class="token keyword">in</span> norm_test_corpus<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># ## build word2vec model</span>model <span class="token operator">=</span> gensim<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Word2Vec<span class="token punctuation">(</span>tokenized_train<span class="token punctuation">,</span>                               size<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>                               window<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>                               min_count<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>                               sample<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ## averaged word vector features</span>avg_wv_train_features <span class="token operator">=</span> averaged_word_vectorizer<span class="token punctuation">(</span>corpus<span class="token operator">=</span>tokenized_train<span class="token punctuation">,</span>                                                model<span class="token operator">=</span>model<span class="token punctuation">,</span>                                                num_features<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span>avg_wv_test_features <span class="token operator">=</span> averaged_word_vectorizer<span class="token punctuation">(</span>corpus<span class="token operator">=</span>tokenized_test<span class="token punctuation">,</span>                                               model<span class="token operator">=</span>model<span class="token punctuation">,</span>                                               num_features<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_16 定义一个评估分类模型的函数</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">def</span> <span class="token function">get_metrics</span><span class="token punctuation">(</span>true_labels<span class="token punctuation">,</span> predicted_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy:'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>                        metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>true_labels<span class="token punctuation">,</span>                                                predicted_labels<span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Precision:'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>                        metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>true_labels<span class="token punctuation">,</span>                                                predicted_labels<span class="token punctuation">,</span>                                               average<span class="token operator">=</span><span class="token string">'weighted'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Recall:'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>                        metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>true_labels<span class="token punctuation">,</span>                                                predicted_labels<span class="token punctuation">,</span>                                               average<span class="token operator">=</span><span class="token string">'weighted'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'F1 Score:'</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>round<span class="token punctuation">(</span>                        metrics<span class="token punctuation">.</span>f1_score<span class="token punctuation">(</span>true_labels<span class="token punctuation">,</span>                                                predicted_labels<span class="token punctuation">,</span>                                               average<span class="token operator">=</span><span class="token string">'weighted'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex15_17 定义一个函数使用机器学习算法和训练数据来训练模型，在测试数据上执行测试，使用上面的函数评估模型预测性能</span><span class="token keyword">def</span> <span class="token function">train_predict_evaluate_model</span><span class="token punctuation">(</span>classifier<span class="token punctuation">,</span>                                  train_features<span class="token punctuation">,</span> train_labels<span class="token punctuation">,</span>                                  test_features<span class="token punctuation">,</span> test_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># build model    </span>    classifier<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span> train_labels<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># predict using model</span>    predictions <span class="token operator">=</span> classifier<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># evaluate model prediction performance   </span>    get_metrics<span class="token punctuation">(</span>true_labels<span class="token operator">=</span>test_labels<span class="token punctuation">,</span>                 predicted_labels<span class="token operator">=</span>predictions<span class="token punctuation">)</span>    <span class="token keyword">return</span> predictions</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> SGDClassifiersvm <span class="token operator">=</span> SGDClassifier<span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'hinge'</span><span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># Support Vector Machine with bag of words features</span>svm_bow_predictions <span class="token operator">=</span> train_predict_evaluate_model<span class="token punctuation">(</span>classifier<span class="token operator">=</span>svm<span class="token punctuation">,</span>                                           train_features<span class="token operator">=</span>bow_train_features<span class="token punctuation">,</span>                                           train_labels<span class="token operator">=</span>train_labels<span class="token punctuation">,</span>                                           test_features<span class="token operator">=</span>bow_test_features<span class="token punctuation">,</span>                                           test_labels<span class="token operator">=</span>test_labels<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Support Vector Machine with tfidf features</span>svm_tfidf_predictions <span class="token operator">=</span> train_predict_evaluate_model<span class="token punctuation">(</span>classifier<span class="token operator">=</span>svm<span class="token punctuation">,</span>                                           train_features<span class="token operator">=</span>tfidf_train_features<span class="token punctuation">,</span>                                           train_labels<span class="token operator">=</span>train_labels<span class="token punctuation">,</span>                                           test_features<span class="token operator">=</span>tfidf_test_features<span class="token punctuation">,</span>                                           test_labels<span class="token operator">=</span>test_labels<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Support Vector Machine with averaged word vector features</span>svm_avgwv_predictions <span class="token operator">=</span> train_predict_evaluate_model<span class="token punctuation">(</span>classifier<span class="token operator">=</span>svm<span class="token punctuation">,</span>                                           train_features<span class="token operator">=</span>avg_wv_train_features<span class="token punctuation">,</span>                                           train_labels<span class="token operator">=</span>train_labels<span class="token punctuation">,</span>                                           test_features<span class="token operator">=</span>avg_wv_test_features<span class="token punctuation">,</span>                                           test_labels<span class="token operator">=</span>test_labels<span class="token punctuation">)</span></code></pre><pre><code>Accuracy: 0.65Precision: 0.69Recall: 0.65F1 Score: 0.66Accuracy: 0.77Precision: 0.77Recall: 0.77F1 Score: 0.77Accuracy: 0.55Precision: 0.55Recall: 0.55F1 Score: 0.52</code></pre><pre class=" language-python"><code class="language-python">help<span class="token punctuation">(</span>SGDClassifier<span class="token punctuation">)</span></code></pre><pre><code>Help on class SGDClassifier in module sklearn.linear_model.stochastic_gradient:class SGDClassifier(BaseSGDClassifier) |  SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False) |   |  Linear classifiers (SVM, logistic regression, a.o.) with SGD training. |   |  This estimator implements regularized linear models with stochastic |  gradient descent (SGD) learning: the gradient of the loss is estimated |  each sample at a time and the model is updated along the way with a |  decreasing strength schedule (aka learning rate). SGD allows minibatch |  (online/out-of-core) learning, see the partial_fit method. |  For best results using the default learning rate schedule, the data should |  have zero mean and unit variance. |   |  This implementation works with data represented as dense or sparse arrays |  of floating point values for the features. The model it fits can be |  controlled with the loss parameter; by default, it fits a linear support |  vector machine (SVM). |   |  The regularizer is a penalty added to the loss function that shrinks model |  parameters towards the zero vector using either the squared euclidean norm |  L2 or the absolute norm L1 or a combination of both (Elastic Net). If the |  parameter update crosses the 0.0 value because of the regularizer, the |  update is truncated to 0.0 to allow for learning sparse models and achieve |  online feature selection. |   |  Read more in the :ref:`User Guide &lt;sgd&gt;`. |   |  Parameters |  ---------- |  loss : str, default: 'hinge' |      The loss function to be used. Defaults to 'hinge', which gives a |      linear SVM. |   |      The possible options are 'hinge', 'log', 'modified_huber', |      'squared_hinge', 'perceptron', or a regression loss: 'squared_loss', |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'. |   |      The 'log' loss gives logistic regression, a probabilistic classifier. |      'modified_huber' is another smooth loss that brings tolerance to |      outliers as well as probability estimates. |      'squared_hinge' is like hinge but is quadratically penalized. |      'perceptron' is the linear loss used by the perceptron algorithm. |      The other losses are designed for regression but can be useful in |      classification as well; see SGDRegressor for a description. |   |  penalty : str, 'none', 'l2', 'l1', or 'elasticnet' |      The penalty (aka regularization term) to be used. Defaults to 'l2' |      which is the standard regularizer for linear SVM models. 'l1' and |      'elasticnet' might bring sparsity to the model (feature selection) |      not achievable with 'l2'. |   |  alpha : float |      Constant that multiplies the regularization term. Defaults to 0.0001 |      Also used to compute learning_rate when set to 'optimal'. |   |  l1_ratio : float |      The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1. |      l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. |      Defaults to 0.15. |   |  fit_intercept : bool |      Whether the intercept should be estimated or not. If False, the |      data is assumed to be already centered. Defaults to True. |   |  max_iter : int, optional (default=1000) |      The maximum number of passes over the training data (aka epochs). |      It only impacts the behavior in the ``fit`` method, and not the |      `partial_fit`. |   |      .. versionadded:: 0.19 |   |  tol : float or None, optional (default=1e-3) |      The stopping criterion. If it is not None, the iterations will stop |      when (loss &gt; best_loss - tol) for ``n_iter_no_change`` consecutive |      epochs. |   |      .. versionadded:: 0.19 |   |  shuffle : bool, optional |      Whether or not the training data should be shuffled after each epoch. |      Defaults to True. |   |  verbose : integer, optional |      The verbosity level |   |  epsilon : float |      Epsilon in the epsilon-insensitive loss functions; only if `loss` is |      'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'. |      For 'huber', determines the threshold at which it becomes less |      important to get the prediction exactly right. |      For epsilon-insensitive, any differences between the current prediction |      and the correct label are ignored if they are less than this threshold. |   |  n_jobs : int or None, optional (default=None) |      The number of CPUs to use to do the OVA (One Versus All, for |      multi-class problems) computation. |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. |      ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;` |      for more details. |   |  random_state : int, RandomState instance or None, optional (default=None) |      The seed of the pseudo random number generator to use when shuffling |      the data.  If int, random_state is the seed used by the random number |      generator; If RandomState instance, random_state is the random number |      generator; If None, the random number generator is the RandomState |      instance used by `np.random`. |   |  learning_rate : string, optional |      The learning rate schedule: |   |      'constant': |          eta = eta0 |      'optimal': [default] |          eta = 1.0 / (alpha * (t + t0)) |          where t0 is chosen by a heuristic proposed by Leon Bottou. |      'invscaling': |          eta = eta0 / pow(t, power_t) |      'adaptive': |          eta = eta0, as long as the training keeps decreasing. |          Each time n_iter_no_change consecutive epochs fail to decrease the |          training loss by tol or fail to increase validation score by tol if |          early_stopping is True, the current learning rate is divided by 5. |   |  eta0 : double |      The initial learning rate for the 'constant', 'invscaling' or |      'adaptive' schedules. The default value is 0.0 as eta0 is not used by |      the default schedule 'optimal'. |   |  power_t : double |      The exponent for inverse scaling learning rate [default 0.5]. |   |  early_stopping : bool, default=False |      Whether to use early stopping to terminate training when validation |      score is not improving. If set to True, it will automatically set aside |      a stratified fraction of training data as validation and terminate |      training when validation score is not improving by at least tol for |      n_iter_no_change consecutive epochs. |   |      .. versionadded:: 0.20 |   |  validation_fraction : float, default=0.1 |      The proportion of training data to set aside as validation set for |      early stopping. Must be between 0 and 1. |      Only used if early_stopping is True. |   |      .. versionadded:: 0.20 |   |  n_iter_no_change : int, default=5 |      Number of iterations with no improvement to wait before early stopping. |   |      .. versionadded:: 0.20 |   |  class_weight : dict, {class_label: weight} or "balanced" or None, optional |      Preset for the class_weight fit parameter. |   |      Weights associated with classes. If not given, all classes |      are supposed to have weight one. |   |      The "balanced" mode uses the values of y to automatically adjust |      weights inversely proportional to class frequencies in the input data |      as ``n_samples / (n_classes * np.bincount(y))`` |   |  warm_start : bool, optional |      When set to True, reuse the solution of the previous call to fit as |      initialization, otherwise, just erase the previous solution. |      See :term:`the Glossary &lt;warm_start&gt;`. |   |      Repeatedly calling fit or partial_fit when warm_start is True can |      result in a different solution than when calling fit a single time |      because of the way the data is shuffled. |      If a dynamic learning rate is used, the learning rate is adapted |      depending on the number of samples already seen. Calling ``fit`` resets |      this counter, while ``partial_fit`` will result in increasing the |      existing counter. |   |  average : bool or int, optional |      When set to True, computes the averaged SGD weights and stores the |      result in the ``coef_`` attribute. If set to an int greater than 1, |      averaging will begin once the total number of samples seen reaches |      average. So ``average=10`` will begin averaging after seeing 10 |      samples. |   |  Attributes |  ---------- |  coef_ : array, shape (1, n_features) if n_classes == 2 else (n_classes,            n_features) |      Weights assigned to the features. |   |  intercept_ : array, shape (1,) if n_classes == 2 else (n_classes,) |      Constants in decision function. |   |  n_iter_ : int |      The actual number of iterations to reach the stopping criterion. |      For multiclass fits, it is the maximum over every binary fit. |   |  loss_function_ : concrete ``LossFunction`` |   |  Examples |  -------- |  &gt;&gt;&gt; import numpy as np |  &gt;&gt;&gt; from sklearn import linear_model |  &gt;&gt;&gt; X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1]]) |  &gt;&gt;&gt; Y = np.array([1, 1, 2, 2]) |  &gt;&gt;&gt; clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3) |  &gt;&gt;&gt; clf.fit(X, Y) |  ... #doctest: +NORMALIZE_WHITESPACE |  SGDClassifier(alpha=0.0001, average=False, class_weight=None, |         early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, |         l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000, |         n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5, |         random_state=None, shuffle=True, tol=0.001, validation_fraction=0.1, |         verbose=0, warm_start=False) |   |  &gt;&gt;&gt; print(clf.predict([[-0.8, -1]])) |  [1] |   |  See also |  -------- |  sklearn.svm.LinearSVC, LogisticRegression, Perceptron |   |  Method resolution order: |      SGDClassifier |      BaseSGDClassifier |      BaseSGD |      sklearn.base.BaseEstimator |      sklearn.linear_model.base.SparseCoefMixin |      sklearn.linear_model.base.LinearClassifierMixin |      sklearn.base.ClassifierMixin |      builtins.object |   |  Methods defined here: |   |  __init__(self, loss='hinge', penalty='l2', alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, epsilon=0.1, n_jobs=None, random_state=None, learning_rate='optimal', eta0=0.0, power_t=0.5, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False, average=False) |      Initialize self.  See help(type(self)) for accurate signature. |   |  ---------------------------------------------------------------------- |  Data descriptors defined here: |   |  predict_log_proba |      Log of probability estimates. |       |      This method is only available for log loss and modified Huber loss. |       |      When loss="modified_huber", probability estimates may be hard zeros |      and ones, so taking the logarithm is not possible. |       |      See ``predict_proba`` for details. |       |      Parameters |      ---------- |      X : array-like, shape (n_samples, n_features) |       |      Returns |      ------- |      T : array-like, shape (n_samples, n_classes) |          Returns the log-probability of the sample for each class in the |          model, where classes are ordered as they are in |          `self.classes_`. |   |  predict_proba |      Probability estimates. |       |      This method is only available for log loss and modified Huber loss. |       |      Multiclass probability estimates are derived from binary (one-vs.-rest) |      estimates by simple normalization, as recommended by Zadrozny and |      Elkan. |       |      Binary probability estimates for loss="modified_huber" are given by |      (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions |      it is necessary to perform proper probability calibration by wrapping |      the classifier with |      :class:`sklearn.calibration.CalibratedClassifierCV` instead. |       |      Parameters |      ---------- |      X : {array-like, sparse matrix}, shape (n_samples, n_features) |       |      Returns |      ------- |      array, shape (n_samples, n_classes) |          Returns the probability of the sample for each class in the model, |          where classes are ordered as they are in `self.classes_`. |       |      References |      ---------- |      Zadrozny and Elkan, "Transforming classifier scores into multiclass |      probability estimates", SIGKDD'02, |      http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf |       |      The justification for the formula in the loss="modified_huber" |      case is in the appendix B in: |      http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf |   |  ---------------------------------------------------------------------- |  Data and other attributes defined here: |   |  __abstractmethods__ = frozenset() |   |  ---------------------------------------------------------------------- |  Methods inherited from BaseSGDClassifier: |   |  fit(self, X, y, coef_init=None, intercept_init=None, sample_weight=None) |      Fit linear model with Stochastic Gradient Descent. |       |      Parameters |      ---------- |      X : {array-like, sparse matrix}, shape (n_samples, n_features) |          Training data |       |      y : numpy array, shape (n_samples,) |          Target values |       |      coef_init : array, shape (n_classes, n_features) |          The initial coefficients to warm-start the optimization. |       |      intercept_init : array, shape (n_classes,) |          The initial intercept to warm-start the optimization. |       |      sample_weight : array-like, shape (n_samples,), optional |          Weights applied to individual samples. |          If not provided, uniform weights are assumed. These weights will |          be multiplied with class_weight (passed through the |          constructor) if class_weight is specified |       |      Returns |      ------- |      self : returns an instance of self. |   |  partial_fit(self, X, y, classes=None, sample_weight=None) |      Perform one epoch of stochastic gradient descent on given samples. |       |      Internally, this method uses ``max_iter = 1``. Therefore, it is not |      guaranteed that a minimum of the cost function is reached after calling |      it once. Matters such as objective convergence and early stopping |      should be handled by the user. |       |      Parameters |      ---------- |      X : {array-like, sparse matrix}, shape (n_samples, n_features) |          Subset of the training data |       |      y : numpy array, shape (n_samples,) |          Subset of the target values |       |      classes : array, shape (n_classes,) |          Classes across all calls to partial_fit. |          Can be obtained by via `np.unique(y_all)`, where y_all is the |          target vector of the entire dataset. |          This argument is required for the first call to partial_fit |          and can be omitted in the subsequent calls. |          Note that y doesn't need to contain all labels in `classes`. |       |      sample_weight : array-like, shape (n_samples,), optional |          Weights applied to individual samples. |          If not provided, uniform weights are assumed. |       |      Returns |      ------- |      self : returns an instance of self. |   |  ---------------------------------------------------------------------- |  Data and other attributes inherited from BaseSGDClassifier: |   |  loss_functions = {'epsilon_insensitive': (&lt;class 'sklearn.linear_model... |   |  ---------------------------------------------------------------------- |  Methods inherited from BaseSGD: |   |  set_params(self, *args, **kwargs) |      Set the parameters of this estimator. |       |      The method works on simple estimators as well as on nested objects |      (such as pipelines). The latter have parameters of the form |      ``&lt;component&gt;__&lt;parameter&gt;`` so that it's possible to update each |      component of a nested object. |       |      Returns |      ------- |      self |   |  ---------------------------------------------------------------------- |  Methods inherited from sklearn.base.BaseEstimator: |   |  __getstate__(self) |   |  __repr__(self, N_CHAR_MAX=700) |      Return repr(self). |   |  __setstate__(self, state) |   |  get_params(self, deep=True) |      Get parameters for this estimator. |       |      Parameters |      ---------- |      deep : boolean, optional |          If True, will return the parameters for this estimator and |          contained subobjects that are estimators. |       |      Returns |      ------- |      params : mapping of string to any |          Parameter names mapped to their values. |   |  ---------------------------------------------------------------------- |  Data descriptors inherited from sklearn.base.BaseEstimator: |   |  __dict__ |      dictionary for instance variables (if defined) |   |  __weakref__ |      list of weak references to the object (if defined) |   |  ---------------------------------------------------------------------- |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin: |   |  densify(self) |      Convert coefficient matrix to dense array format. |       |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the |      default format of ``coef_`` and is required for fitting, so calling |      this method is only required on models that have previously been |      sparsified; otherwise, it is a no-op. |       |      Returns |      ------- |      self : estimator |   |  sparsify(self) |      Convert coefficient matrix to sparse format. |       |      Converts the ``coef_`` member to a scipy.sparse matrix, which for |      L1-regularized models can be much more memory- and storage-efficient |      than the usual numpy.ndarray representation. |       |      The ``intercept_`` member is not converted. |       |      Notes |      ----- |      For non-sparse models, i.e. when there are not many zeros in ``coef_``, |      this may actually *increase* memory usage, so use this method with |      care. A rule of thumb is that the number of zero elements, which can |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this |      to provide significant benefits. |       |      After calling this method, further fitting with the partial_fit |      method (if any) will not work until you call densify. |       |      Returns |      ------- |      self : estimator |   |  ---------------------------------------------------------------------- |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin: |   |  decision_function(self, X) |      Predict confidence scores for samples. |       |      The confidence score for a sample is the signed distance of that |      sample to the hyperplane. |       |      Parameters |      ---------- |      X : array_like or sparse matrix, shape (n_samples, n_features) |          Samples. |       |      Returns |      ------- |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes) |          Confidence scores per (sample, class) combination. In the binary |          case, confidence score for self.classes_[1] where &gt;0 means this |          class would be predicted. |   |  predict(self, X) |      Predict class labels for samples in X. |       |      Parameters |      ---------- |      X : array_like or sparse matrix, shape (n_samples, n_features) |          Samples. |       |      Returns |      ------- |      C : array, shape [n_samples] |          Predicted class label per sample. |   |  ---------------------------------------------------------------------- |  Methods inherited from sklearn.base.ClassifierMixin: |   |  score(self, X, y, sample_weight=None) |      Returns the mean accuracy on the given test data and labels. |       |      In multi-label classification, this is the subset accuracy |      which is a harsh metric since you require for each sample that |      each label set be correctly predicted. |       |      Parameters |      ---------- |      X : array-like, shape = (n_samples, n_features) |          Test samples. |       |      y : array-like, shape = (n_samples) or (n_samples, n_outputs) |          True labels for X. |       |      sample_weight : array-like, shape = [n_samples], optional |          Sample weights. |       |      Returns |      ------- |      score : float |          Mean accuracy of self.predict(X) wrt. y.</code></pre><p>​    </p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdcm <span class="token operator">=</span> metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>test_labels<span class="token punctuation">,</span> svm_tfidf_predictions<span class="token punctuation">)</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>cm<span class="token punctuation">,</span> index<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> columns<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><div><style scoped="">    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>0</th>      <th>1</th>      <th>2</th>      <th>3</th>      <th>4</th>      <th>5</th>      <th>6</th>      <th>7</th>      <th>8</th>      <th>9</th>      <th>10</th>      <th>11</th>      <th>12</th>      <th>13</th>      <th>14</th>      <th>15</th>      <th>16</th>      <th>17</th>      <th>18</th>      <th>19</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>140</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>5</td>      <td>0</td>      <td>5</td>      <td>4</td>      <td>2</td>      <td>6</td>      <td>4</td>      <td>33</td>      <td>2</td>      <td>6</td>      <td>8</td>      <td>15</td>    </tr>    <tr>      <th>1</th>      <td>1</td>      <td>208</td>      <td>7</td>      <td>7</td>      <td>7</td>      <td>11</td>      <td>6</td>      <td>1</td>      <td>2</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>6</td>      <td>4</td>      <td>3</td>      <td>1</td>      <td>3</td>      <td>0</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>1</td>      <td>20</td>      <td>201</td>      <td>15</td>      <td>8</td>      <td>18</td>      <td>8</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>4</td>      <td>7</td>      <td>1</td>      <td>4</td>      <td>2</td>      <td>1</td>      <td>1</td>      <td>3</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>0</td>      <td>11</td>      <td>21</td>      <td>201</td>      <td>10</td>      <td>4</td>      <td>7</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>8</td>      <td>2</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>1</td>      <td>6</td>      <td>6</td>      <td>14</td>      <td>200</td>      <td>5</td>      <td>3</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>10</td>      <td>2</td>      <td>3</td>      <td>1</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>5</th>      <td>0</td>      <td>18</td>      <td>17</td>      <td>1</td>      <td>2</td>      <td>247</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>6</th>      <td>0</td>      <td>1</td>      <td>7</td>      <td>9</td>      <td>12</td>      <td>4</td>      <td>237</td>      <td>11</td>      <td>3</td>      <td>2</td>      <td>1</td>      <td>1</td>      <td>11</td>      <td>1</td>      <td>4</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>7</th>      <td>1</td>      <td>4</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>3</td>      <td>3</td>      <td>229</td>      <td>19</td>      <td>1</td>      <td>3</td>      <td>1</td>      <td>10</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>3</td>      <td>1</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>8</th>      <td>1</td>      <td>1</td>      <td>0</td>      <td>3</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>21</td>      <td>242</td>      <td>3</td>      <td>4</td>      <td>2</td>      <td>0</td>      <td>5</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>0</td>    </tr>    <tr>      <th>9</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>3</td>      <td>4</td>      <td>1</td>      <td>7</td>      <td>257</td>      <td>11</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>4</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>10</th>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>3</td>      <td>2</td>      <td>3</td>      <td>259</td>      <td>0</td>      <td>2</td>      <td>1</td>      <td>3</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>11</th>      <td>3</td>      <td>5</td>      <td>4</td>      <td>3</td>      <td>1</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>3</td>      <td>0</td>      <td>228</td>      <td>6</td>      <td>3</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>2</td>      <td>5</td>      <td>0</td>    </tr>    <tr>      <th>12</th>      <td>1</td>      <td>6</td>      <td>7</td>      <td>13</td>      <td>3</td>      <td>2</td>      <td>11</td>      <td>10</td>      <td>8</td>      <td>2</td>      <td>3</td>      <td>1</td>      <td>195</td>      <td>3</td>      <td>4</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>1</td>      <td>0</td>    </tr>    <tr>      <th>13</th>      <td>2</td>      <td>3</td>      <td>0</td>      <td>1</td>      <td>3</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>2</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>5</td>      <td>241</td>      <td>5</td>      <td>2</td>      <td>2</td>      <td>0</td>      <td>4</td>      <td>0</td>    </tr>    <tr>      <th>14</th>      <td>0</td>      <td>3</td>      <td>2</td>      <td>0</td>      <td>2</td>      <td>5</td>      <td>1</td>      <td>4</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>0</td>      <td>10</td>      <td>4</td>      <td>243</td>      <td>2</td>      <td>4</td>      <td>2</td>      <td>3</td>      <td>0</td>    </tr>    <tr>      <th>15</th>      <td>11</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>0</td>      <td>3</td>      <td>2</td>      <td>1</td>      <td>2</td>      <td>1</td>      <td>8</td>      <td>4</td>      <td>268</td>      <td>3</td>      <td>3</td>      <td>2</td>      <td>3</td>    </tr>    <tr>      <th>16</th>      <td>2</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>3</td>      <td>2</td>      <td>3</td>      <td>4</td>      <td>3</td>      <td>2</td>      <td>4</td>      <td>2</td>      <td>4</td>      <td>5</td>      <td>1</td>      <td>204</td>      <td>3</td>      <td>13</td>      <td>3</td>    </tr>    <tr>      <th>17</th>      <td>6</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>0</td>      <td>2</td>      <td>3</td>      <td>1</td>      <td>5</td>      <td>6</td>      <td>1</td>      <td>3</td>      <td>0</td>      <td>6</td>      <td>3</td>      <td>239</td>      <td>9</td>      <td>3</td>    </tr>    <tr>      <th>18</th>      <td>11</td>      <td>1</td>      <td>1</td>      <td>2</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>1</td>      <td>5</td>      <td>2</td>      <td>3</td>      <td>5</td>      <td>0</td>      <td>6</td>      <td>4</td>      <td>2</td>      <td>26</td>      <td>5</td>      <td>148</td>      <td>3</td>    </tr>    <tr>      <th>19</th>      <td>17</td>      <td>3</td>      <td>0</td>      <td>1</td>      <td>0</td>      <td>2</td>      <td>2</td>      <td>3</td>      <td>10</td>      <td>3</td>      <td>2</td>      <td>1</td>      <td>0</td>      <td>10</td>      <td>2</td>      <td>57</td>      <td>20</td>      <td>6</td>      <td>4</td>      <td>57</td>    </tr>  </tbody></table></div><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络</title>
      <link href="/2020/05/25/shen-jing-wang-luo/"/>
      <url>/2020/05/25/shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex17_1 阶跃函数的实现</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">def</span> <span class="token function">step_function</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">##x支持数组为输入</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>x<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int<span class="token punctuation">)</span><span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltx <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>y <span class="token operator">=</span> step_function<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">1.1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##负号显示</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span><span class="token string">'text.usetex'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span><span class="token string">'font.family'</span><span class="token punctuation">:</span> <span class="token string">'stixgeneral'</span><span class="token punctuation">,</span><span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span> <span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>&lt;Figure size 640x480 with 1 Axes&gt;</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex17_2 sigmoid函数的实现</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##numpy具有广播功能，支持标量和数组之间的运算</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span><span class="token string">'text.usetex'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span><span class="token string">'font.family'</span><span class="token punctuation">:</span> <span class="token string">'stixgeneral'</span><span class="token punctuation">,</span><span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span> <span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token punctuation">)</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>y <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">1.1</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_1_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex17_3 ReLU函数</span><span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span><span class="token string">'text.usetex'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span><span class="token string">'font.family'</span><span class="token punctuation">:</span> <span class="token string">'stixgeneral'</span><span class="token punctuation">,</span><span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span> <span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token punctuation">)</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">5.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">)</span>y <span class="token operator">=</span> relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span></code></pre><pre><code>(-1, 6)</code></pre><p><img src="output_2_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex17_4</span>X <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## 1*2</span><span class="token comment" spellcheck="true">## 第一层</span>W1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## 2*3  </span>B1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>A1 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span>W1<span class="token punctuation">)</span> <span class="token operator">+</span> B1 <span class="token comment" spellcheck="true">##通过矩阵的乘积计算加权信号和 表示第1层的节点信号，矩阵维度为1*3</span>Z1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>A1<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">#激活转换为信号到0-1之间</span><span class="token keyword">print</span><span class="token punctuation">(</span>A1<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># [0.3 0.7 1.1]</span><span class="token keyword">print</span><span class="token punctuation">(</span>Z1<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># [0.57444252 0.66818777 0.75026011]  #1*3</span><span class="token comment" spellcheck="true">## 第二层</span>W2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.3</span><span class="token punctuation">,</span><span class="token number">0.6</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##3*2</span>B2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>A2 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Z1<span class="token punctuation">,</span> W2<span class="token punctuation">)</span> <span class="token operator">+</span> B2  <span class="token comment" spellcheck="true">##第1层的节点信号，矩阵维度为1*2</span>Z2 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>A2<span class="token punctuation">)</span><span class="token comment" spellcheck="true">##第三层</span><span class="token keyword">def</span> <span class="token function">identity_function</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment" spellcheck="true">## 恒等函数，作为输出层的激活函数</span>    <span class="token keyword">return</span> xW3 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##2*2</span>B3 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>A3 <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>Z2<span class="token punctuation">,</span> W3<span class="token punctuation">)</span> <span class="token operator">+</span> B3  <span class="token comment" spellcheck="true">## 第3层的节点信号，矩阵维度为1*2</span>Y <span class="token operator">=</span> identity_function<span class="token punctuation">(</span>A3<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##调用输出层的激活函数</span><span class="token keyword">print</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span></code></pre><pre><code>[0.3 0.7 1.1][0.57444252 0.66818777 0.75026011][0.31682708 0.69627909]</code></pre><pre class=" language-python"><code class="language-python"></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVD的原理探析及项目实践</title>
      <link href="/2020/05/18/svd-de-yuan-li-tan-xi-ji-xiang-mu-shi-jian/"/>
      <url>/2020/05/18/svd-de-yuan-li-tan-xi-ji-xiang-mu-shi-jian/</url>
      
        <content type="html"><![CDATA[<h1 id="SVD的原理探析及项目实践"><a href="#SVD的原理探析及项目实践" class="headerlink" title="SVD的原理探析及项目实践"></a>SVD的原理探析及项目实践</h1><blockquote><p>author：张国祥 </p></blockquote><blockquote><p>date： 2020.9.10</p></blockquote><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><h2 id="SVD-概述"><a href="#SVD-概述" class="headerlink" title="SVD 概述"></a>SVD 概述</h2><pre><code>奇异值分解（SVD, Singular Value Decomposition）:    提取信息的一种方法，可以把 SVD 看成是从噪声数据中抽取相关特征。从生物信息学到金融学，SVD 是提取信息的强大工具。</code></pre><p>奇异值是什么？</p><ul><li>设A为m<em>n阶矩阵，q=min(m,n)，$A</em>A$的q个非负特征值的算术平方根叫作A的奇异值。（可以推导一下：$ P^-1 A P=Λ $）</li></ul><h2 id="SVD-场景"><a href="#SVD-场景" class="headerlink" title="SVD 场景"></a>SVD 场景</h2><blockquote><p>信息检索-隐性语义检索（Latent Semantic Indexing, LSI）或 隐形语义分析（Latent Semantic Analysis, LSA）</p></blockquote><p>隐性语义索引：矩阵 = 文档 + 词语</p><ul><li>是最早的 SVD 应用之一，我们称利用 SVD 的方法为隐性语义索引（LSI）或隐性语义分析（LSA）。</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-LSI%E4%B8%BE%E4%BE%8B.png" alt="LSA举例"></p><p>降维体现在两个方面：</p><ul><li>矩阵分解</li><li>低秩逼近</li></ul><blockquote><p>推荐系统</p></blockquote><ol><li>利用 SVD 从数据中构建一个主题空间。</li><li>再在该空间下计算其相似度。(从高维-低维空间的转化，在低维空间来计算相似度，SVD 提升了推荐系统的效率。)</li></ol><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/SVD_%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F_%E4%B8%BB%E9%A2%98%E7%A9%BA%E9%97%B4%E6%A1%88%E4%BE%8B1.jpg" alt="主题空间案例1"></p><ul><li>上图右边标注的为一组共同特征，表示美式 BBQ 空间；另一组在上图右边未标注的为日式食品 空间。</li></ul><blockquote><p>图像压缩</p></blockquote><p>例如：<code>32*32=1024 =&gt; 32*2+2*1+32*2=130</code>(2*1表示去掉了除对角线的0), 几乎获得了10倍的压缩比。</p><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-SVD%E5%85%AC%E5%BC%8F.jpg" alt="SVD公式"></p><h2 id="SVD-原理"><a href="#SVD-原理" class="headerlink" title="SVD 原理"></a>SVD 原理</h2><h3 id="SVD-工作原理"><a href="#SVD-工作原理" class="headerlink" title="SVD 工作原理"></a>SVD 工作原理</h3><blockquote><p>矩阵分解</p></blockquote><ul><li>矩阵分解是将数据矩阵分解为多个独立部分的过程。</li><li>矩阵分解可以将原始矩阵表示成新的易于处理的形式，这种新形式是两个或多个矩阵的乘积。（类似代数中的因数分解）</li><li>举例：如何将12分解成两个数的乘积？（1，12）、（2，6）、（3，4）都是合理的答案。</li></ul><blockquote><p>SVD 是矩阵分解的一种类型，也是矩阵分解最常见的技术</p></blockquote><ul><li>SVD 将原始的数据集矩阵 Data 分解成三个矩阵 U、∑、V</li><li>举例：如果原始矩阵 \(Data_{m*n}\) 是m行n列，<ul><li>\(U_{m * k}\) 表示m行k列</li><li>\(∑_{k * k}\) 表示k行k列</li><li>\(V_{k * n}\) 表示k行n列。</li></ul></li></ul><p>\(Data_{m<em>n} = U_{m\</em>k} * ∑<em>{k*k} * V</em>{k*n}\)</p><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-SVD%E5%85%AC%E5%BC%8F.jpg" alt="SVD公式"></p><p>具体的案例：（大家可以试着推导一下：<a href="https://wenku.baidu.com/view/b7641217866fb84ae45c8d17.html">https://wenku.baidu.com/view/b7641217866fb84ae45c8d17.html</a>  P57）</p><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/SVD%E5%85%AC%E5%BC%8F%E7%9A%84%E6%B5%8B%E8%AF%95%E6%A1%88%E4%BE%8B.jpg" alt="SVD公式"></p><ul><li>上述分解中会构建出一个矩阵∑，该矩阵只有对角元素，其他元素均为0(近似于0)。另一个惯例就是，∑的对角元素是从大到小排列的。这些对角元素称为奇异值。</li><li>奇异值与特征值(PCA 数据中重要特征)是有关系的。这里的奇异值就是矩阵 \(Data * Data^T\) 特征值的平方根。</li><li>普遍的事实：在某个奇异值的数目(r 个=&gt;奇异值的平方和累加到总值的90%以上)之后，其他的奇异值都置为0(近似于0)。这意味着数据集中仅有 r 个重要特征，而其余特征则都是噪声或冗余特征。</li></ul><h3 id="SVD-算法特点"><a href="#SVD-算法特点" class="headerlink" title="SVD 算法特点"></a>SVD 算法特点</h3><pre><code>优点：简化数据，去除噪声，优化算法的结果缺点：数据的转换可能难以理解使用的数据类型：数值型数据</code></pre><h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><h3 id="推荐系统-概述"><a href="#推荐系统-概述" class="headerlink" title="推荐系统 概述"></a>推荐系统 概述</h3><p><code>推荐系统是利用电子商务网站向客户提供商品信息和建议，帮助用户决定应该购买什么产品，模拟销售人员帮助客户完成购买过程。</code></p><h3 id="推荐系统-场景"><a href="#推荐系统-场景" class="headerlink" title="推荐系统 场景"></a>推荐系统 场景</h3><ol><li>Amazon 会根据顾客的购买历史向他们推荐物品</li><li>Netflix 会向其用户推荐电影</li><li>新闻网站会对用户推荐新闻频道</li></ol><h3 id="推荐系统-要点"><a href="#推荐系统-要点" class="headerlink" title="推荐系统 要点"></a>推荐系统 要点</h3><blockquote><p>基于协同过滤(collaborative filtering) 的推荐引擎</p></blockquote><ul><li>利用Python 实现 SVD(Numpy 有一个称为 linalg 的线性代数工具箱)</li><li>协同过滤：是通过将用户和其他用户的数据进行对比来实现推荐的。（利用某兴趣相投、拥有共同经验之群体（自身历史数据 or 其他人）的喜好来推荐用户感兴趣的信息）</li><li>当知道了两个用户或两个物品之间的相似度，我们就可以利用已有的数据来预测未知用户的喜好。</li></ul><blockquote><p>基于物品的相似度和基于用户的相似度：物品比较少则选择物品相似度，用户比较少则选择用户相似度。【矩阵还是小一点好计算】</p></blockquote><ul><li>基于物品的相似度：计算物品之间的距离。【耗时会随物品数量的增加而增加】</li><li>由于物品A和物品C 相似度(相关度)很高，所以给买A的人推荐C。</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6.png" alt="SVD公式"></p><ul><li>基于用户的相似度：计算用户之间的距离。【耗时会随用户数量的增加而增加】</li><li>由于用户A和用户C 相似度(相关度)很高，所以A和C是兴趣相投的人，对于C买的物品就会推荐给A。</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E4%BD%BF%E7%94%A8SVD%E7%AE%80%E5%8C%96%E6%95%B0%E6%8D%AE-%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E7%9B%B8%E4%BC%BC%E5%BA%A6.png" alt="SVD公式"></p><blockquote><p>相似度计算</p></blockquote><ul><li>inA, inB 对应的是 列向量</li></ul><ol><li>欧氏距离：指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。二维或三维中的欧氏距离就是两点之间的实际距离。<ul><li>相似度= 1/(1+欧式距离)</li><li><code>相似度= 1.0/(1.0 + la.norm(inA - inB))</code></li><li>物品对越相似，它们的相似度值就越大。</li></ul></li><li>皮尔逊相关系数：度量的是两个向量之间的相似度。<ul><li>相似度= 0.5 + 0.5<em>corrcoef() 【皮尔逊相关系数的取值范围从 -1 到 +1，通过函数0.5 + 0.5\</em>corrcoef()这个函数计算，把值归一化到0到1之间】</li><li><code>相似度= 0.5 + 0.5 * corrcoef(inA, inB, rowvar = 0)[0][1]</code></li><li>相对欧氏距离的优势：它对用户评级的量级并不敏感。</li></ul></li><li>余弦相似度：计算的是两个向量夹角的余弦值。<ul><li>余弦值 = (A·B)/(||A||·||B||) 【余弦值的取值范围也在-1到+1之间】</li><li>相似度= 0.5 + 0.5*余弦值</li><li><code>相似度= 0.5 + 0.5*( float(inA.T*inB) / la.norm(inA)*la.norm(inB))</code></li><li>如果夹角为90度，则相似度为0；如果两个向量的方向相同，则相似度为1.0。</li></ul></li></ol><blockquote><p>推荐系统的评价</p></blockquote><ul><li>采用交叉测试的方法。【拆分数据为训练集和测试集】</li><li>推荐引擎评价的指标： 最小均方根误差(Root mean squared error, RMSE)，也称标准误差(Standard error)，就是计算均方误差的平均值然后取其平方根。<ul><li>如果RMSE=1, 表示相差1个星级；如果RMSE=2.5, 表示相差2.5个星级。</li></ul></li></ul><h3 id="推荐系统-原理"><a href="#推荐系统-原理" class="headerlink" title="推荐系统 原理"></a>推荐系统 原理</h3><ul><li>推荐系统的工作过程：给定一个用户，系统会为此用户返回N个最好的推荐菜。</li><li>实现流程大致如下：<ol><li>寻找用户没有评级的菜肴，即在用户-物品矩阵中的0值。</li><li>在用户没有评级的所有物品中，对每个物品预计一个可能的评级分数。这就是说：我们认为用户可能会对物品的打分（这就是相似度计算的初衷）。</li><li>对这些物品的评分从高到低进行排序，返回前N个物品。</li></ol></li></ul><h3 id="项目案例-餐馆菜肴推荐系统"><a href="#项目案例-餐馆菜肴推荐系统" class="headerlink" title="项目案例: 餐馆菜肴推荐系统"></a>项目案例: 餐馆菜肴推荐系统</h3><h4 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h4><p><code>假如一个人在家决定外出吃饭，但是他并不知道该到哪儿去吃饭，该点什么菜。推荐系统可以帮他做到这两点。</code></p><h4 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h4><blockquote><p>收集 并 准备数据</p></blockquote><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E9%A1%B9%E7%9B%AE%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5.jpg" alt="SVD 矩阵"></p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">loadExData3</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 利用SVD提高推荐效果，菜肴矩阵</span>    <span class="token triple-quoted-string string">"""    行：代表人    列：代表菜肴名词    值：代表人对菜肴的评分，0表示未评分    """</span>    <span class="token keyword">return</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>           <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span></code></pre><blockquote><p>分析数据: 这里不做过多的讨论(当然此处可以对比不同距离之间的差别)</p></blockquote><blockquote><p>训练算法: 通过调用 recommend() 函数进行推荐</p></blockquote><p>recommend() 会调用 基于物品相似度 或者是 基于SVD，得到推荐的物品评分。</p><ul><li>1.基于物品相似度</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E5%9F%BA%E4%BA%8E%E7%89%A9%E5%93%81%E7%9B%B8%E4%BC%BC%E5%BA%A6.jpg" alt="基于物品相似度"></p><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E6%AC%A7%E5%BC%8F%E8%B7%9D%E7%A6%BB%E7%9A%84%E8%AE%A1%E7%AE%97%E6%96%B9%E5%BC%8F.jpg" alt="欧式距离的计算方式"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 基于物品相似度的推荐引擎</span><span class="token keyword">def</span> <span class="token function">standEst</span><span class="token punctuation">(</span>dataMat<span class="token punctuation">,</span> user<span class="token punctuation">,</span> simMeas<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""standEst(计算某用户未评分物品中，以对该物品和其他物品评分的用户的物品相似度，然后进行综合评分)    Args:        dataMat         训练数据集        user            用户编号        simMeas         相似度计算方法        item            未评分的物品编号    Returns:        ratSimTotal/simTotal     评分（0～5之间的值）    """</span>    <span class="token comment" spellcheck="true"># 得到数据集中的物品数目</span>    n <span class="token operator">=</span> shape<span class="token punctuation">(</span>dataMat<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 初始化两个评分值</span>    simTotal <span class="token operator">=</span> <span class="token number">0.0</span>    ratSimTotal <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token comment" spellcheck="true"># 遍历行中的每个物品（对用户评过分的物品进行遍历，并将它与其他物品进行比较）</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        userRating <span class="token operator">=</span> dataMat<span class="token punctuation">[</span>user<span class="token punctuation">,</span> j<span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 如果某个物品的评分值为0，则跳过这个物品</span>        <span class="token keyword">if</span> userRating <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token comment" spellcheck="true"># 寻找两个用户都评级的物品</span>        <span class="token comment" spellcheck="true"># 变量 overLap 给出的是两个物品当中已经被评分的那个元素的索引ID</span>        <span class="token comment" spellcheck="true"># logical_and 计算x1和x2元素的真值。</span>        overLap <span class="token operator">=</span> nonzero<span class="token punctuation">(</span>logical_and<span class="token punctuation">(</span>dataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> item<span class="token punctuation">]</span><span class="token punctuation">.</span>A <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">,</span> dataMat<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">.</span>A <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># 如果相似度为0，则两着没有任何重合元素，终止本次循环</span>        <span class="token keyword">if</span> len<span class="token punctuation">(</span>overLap<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            similarity <span class="token operator">=</span> <span class="token number">0</span>        <span class="token comment" spellcheck="true"># 如果存在重合的物品，则基于这些重合物重新计算相似度。</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            similarity <span class="token operator">=</span> simMeas<span class="token punctuation">(</span>dataMat<span class="token punctuation">[</span>overLap<span class="token punctuation">,</span> item<span class="token punctuation">]</span><span class="token punctuation">,</span> dataMat<span class="token punctuation">[</span>overLap<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># print 'the %d and %d similarity is : %f'(iten,j,similarity)</span>        <span class="token comment" spellcheck="true"># 相似度会不断累加，每次计算时还考虑相似度和当前用户评分的乘积</span>        <span class="token comment" spellcheck="true"># similarity  用户相似度，   userRating 用户评分</span>        simTotal <span class="token operator">+=</span> similarity        ratSimTotal <span class="token operator">+=</span> similarity <span class="token operator">*</span> userRating    <span class="token keyword">if</span> simTotal <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0</span>    <span class="token comment" spellcheck="true"># 通过除以所有的评分总和，对上述相似度评分的乘积进行归一化，使得最后评分在0~5之间，这些评分用来对预测值进行排序</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> ratSimTotal<span class="token operator">/</span>simTotal</code></pre><ul><li>2.基于SVD(参考地址：<a href="http://www.codeweblog.com/svd-%E7%AC%94%E8%AE%B0/">http://www.codeweblog.com/svd-%E7%AC%94%E8%AE%B0/</a>)</li></ul><p><img src="http://data.apachecn.org/img/AiLearning/ml/14.SVD/%E5%9F%BA%E4%BA%8ESVD.png" alt="基于SVD.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 基于SVD的评分估计</span><span class="token comment" spellcheck="true"># 在recommend() 中，这个函数用于替换对standEst()的调用，该函数对给定用户给定物品构建了一个评分估计值</span><span class="token keyword">def</span> <span class="token function">svdEst</span><span class="token punctuation">(</span>dataMat<span class="token punctuation">,</span> user<span class="token punctuation">,</span> simMeas<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""svdEst(计算某用户未评分物品中，以对该物品和其他物品评分的用户的物品相似度，然后进行综合评分)    Args:        dataMat         训练数据集        user            用户编号        simMeas         相似度计算方法        item            未评分的物品编号    Returns:        ratSimTotal/simTotal     评分（0～5之间的值）    """</span>    <span class="token comment" spellcheck="true"># 物品数目</span>    n <span class="token operator">=</span> shape<span class="token punctuation">(</span>dataMat<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 对数据集进行SVD分解</span>    simTotal <span class="token operator">=</span> <span class="token number">0.0</span>    ratSimTotal <span class="token operator">=</span> <span class="token number">0.0</span>    <span class="token comment" spellcheck="true"># 奇异值分解</span>    <span class="token comment" spellcheck="true"># 在SVD分解之后，我们只利用包含了90%能量值的奇异值，这些奇异值会以NumPy数组的形式得以保存</span>    U<span class="token punctuation">,</span> Sigma<span class="token punctuation">,</span> VT <span class="token operator">=</span> la<span class="token punctuation">.</span>svd<span class="token punctuation">(</span>dataMat<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># # 分析 Sigma 的长度取值</span>    <span class="token comment" spellcheck="true"># analyse_data(Sigma, 20)</span>    <span class="token comment" spellcheck="true"># 如果要进行矩阵运算，就必须要用这些奇异值构建出一个对角矩阵</span>    Sig4 <span class="token operator">=</span> mat<span class="token punctuation">(</span>eye<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token operator">*</span> Sigma<span class="token punctuation">[</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 利用U矩阵将物品转换到低维空间中，构建转换后的物品(物品+4个主要的特征)</span>    xformedItems <span class="token operator">=</span> dataMat<span class="token punctuation">.</span>T <span class="token operator">*</span> U<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span> <span class="token operator">*</span> Sig4<span class="token punctuation">.</span>I    <span class="token comment" spellcheck="true"># 对于给定的用户，for循环在用户对应行的元素上进行遍历，</span>    <span class="token comment" spellcheck="true"># 这和standEst()函数中的for循环的目的一样，只不过这里的相似度计算时在低维空间下进行的。</span>    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        userRating <span class="token operator">=</span> dataMat<span class="token punctuation">[</span>user<span class="token punctuation">,</span> j<span class="token punctuation">]</span>        <span class="token keyword">if</span> userRating <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> j <span class="token operator">==</span> item<span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token comment" spellcheck="true"># 相似度的计算方法也会作为一个参数传递给该函数</span>        similarity <span class="token operator">=</span> simMeas<span class="token punctuation">(</span>xformedItems<span class="token punctuation">[</span>item<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">,</span> xformedItems<span class="token punctuation">[</span>j<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># for 循环中加入了一条print语句，以便了解相似度计算的进展情况。如果觉得累赘，可以去掉</span>        <span class="token keyword">print</span> <span class="token string">'the %d and %d similarity is: %f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>item<span class="token punctuation">,</span> j<span class="token punctuation">,</span> similarity<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 对相似度不断累加求和</span>        simTotal <span class="token operator">+=</span> similarity        <span class="token comment" spellcheck="true"># 对相似度及对应评分值的乘积求和</span>        ratSimTotal <span class="token operator">+=</span> similarity <span class="token operator">*</span> userRating    <span class="token keyword">if</span> simTotal <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">0</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 计算估计评分</span>        <span class="token keyword">return</span> ratSimTotal<span class="token operator">/</span>simTotal</code></pre><p>排序获取最后的推荐结果</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># recommend()函数，就是推荐引擎，它默认调用standEst()函数，产生了最高的N个推荐结果。</span><span class="token comment" spellcheck="true"># 如果不指定N的大小，则默认值为3。该函数另外的参数还包括相似度计算方法和估计方法</span><span class="token keyword">def</span> <span class="token function">recommend</span><span class="token punctuation">(</span>dataMat<span class="token punctuation">,</span> user<span class="token punctuation">,</span> N<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> simMeas<span class="token operator">=</span>cosSim<span class="token punctuation">,</span> estMethod<span class="token operator">=</span>standEst<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 寻找未评级的物品</span>    <span class="token comment" spellcheck="true"># 对给定的用户建立一个未评分的物品列表</span>    unratedItems <span class="token operator">=</span> nonzero<span class="token punctuation">(</span>dataMat<span class="token punctuation">[</span>user<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>A <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 如果不存在未评分物品，那么就退出函数</span>    <span class="token keyword">if</span> len<span class="token punctuation">(</span>unratedItems<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">'you rated everything'</span>    <span class="token comment" spellcheck="true"># 物品的编号和评分值</span>    itemScores <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 在未评分物品上进行循环</span>    <span class="token keyword">for</span> item <span class="token keyword">in</span> unratedItems<span class="token punctuation">:</span>        estimatedScore <span class="token operator">=</span> estMethod<span class="token punctuation">(</span>dataMat<span class="token punctuation">,</span> user<span class="token punctuation">,</span> simMeas<span class="token punctuation">,</span> item<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 寻找前N个未评级物品，调用standEst()来产生该物品的预测得分，该物品的编号和估计值会放在一个元素列表itemScores中</span>        itemScores<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>item<span class="token punctuation">,</span> estimatedScore<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 按照估计得分，对该列表进行排序并返回。列表逆排序，第一个值就是最大值</span>    <span class="token keyword">return</span> sorted<span class="token punctuation">(</span>itemScores<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> jj<span class="token punctuation">:</span> jj<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span> N<span class="token punctuation">]</span></code></pre><h4 id="要点补充"><a href="#要点补充" class="headerlink" title="要点补充"></a>要点补充</h4><blockquote><p>基于内容(content-based)的推荐</p></blockquote><ol><li>通过各种标签来标记菜肴</li><li>将这些属性作为相似度计算所需要的数据</li><li>这就是：基于内容的推荐。</li></ol><blockquote><p>构建推荐引擎面临的挑战</p></blockquote><p>问题</p><ul><li>1）在大规模的数据集上，SVD分解会降低程序的速度</li><li>2）存在其他很多规模扩展性的挑战性问题，比如矩阵的表示方法和计算相似度得分消耗资源。</li><li>3）如何在缺乏数据时给出好的推荐-称为冷启动【简单说：用户不会喜欢一个无效的物品，而用户不喜欢的物品又无效】</li></ul><p>建议</p><ul><li>1）在大型系统中，SVD分解(可以在程序调入时运行一次)每天运行一次或者其频率更低，并且还要离线运行。</li><li>2）在实际中，另一个普遍的做法就是离线计算并保存相似度得分。(物品相似度可能被用户重复的调用)</li><li>3）冷启动问题，解决方案就是将推荐看成是搜索问题，通过各种标签／属性特征进行<code>基于内容的推荐</code>。</li></ul><h3 id="项目案例-基于-SVD-的图像压缩"><a href="#项目案例-基于-SVD-的图像压缩" class="headerlink" title="项目案例: 基于 SVD 的图像压缩"></a>项目案例: 基于 SVD 的图像压缩</h3><blockquote><p>收集 并 准备数据</p></blockquote><p>将文本数据转化为矩阵</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加载并转换数据</span><span class="token keyword">def</span> <span class="token function">imgLoadData</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>    myl <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 打开文本文件，并从文件以数组方式读入字符</span>    <span class="token keyword">for</span> line <span class="token keyword">in</span> open<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        newRow <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            newRow<span class="token punctuation">.</span>append<span class="token punctuation">(</span>int<span class="token punctuation">(</span>line<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        myl<span class="token punctuation">.</span>append<span class="token punctuation">(</span>newRow<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 矩阵调入后，就可以在屏幕上输出该矩阵</span>    myMat <span class="token operator">=</span> mat<span class="token punctuation">(</span>myl<span class="token punctuation">)</span>    <span class="token keyword">return</span> myMat</code></pre><blockquote><p>分析数据: 分析 Sigma 的长度个数</p></blockquote><p>通常保留矩阵 80% ～ 90% 的能量，就可以得到重要的特征并去除噪声。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">analyse_data</span><span class="token punctuation">(</span>Sigma<span class="token punctuation">,</span> loopNum<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""analyse_data(分析 Sigma 的长度取值)    Args:        Sigma         Sigma的值        loopNum       循环次数    """</span>    <span class="token comment" spellcheck="true"># 总方差的集合（总能量值）</span>    Sig2 <span class="token operator">=</span> Sigma<span class="token operator">**</span><span class="token number">2</span>    SigmaSum <span class="token operator">=</span> sum<span class="token punctuation">(</span>Sig2<span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>loopNum<span class="token punctuation">)</span><span class="token punctuation">:</span>        SigmaI <span class="token operator">=</span> sum<span class="token punctuation">(</span>Sig2<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token triple-quoted-string string">'''        根据自己的业务情况，就行处理，设置对应的 Singma 次数        通常保留矩阵 80% ～ 90% 的能量，就可以得到重要的特征并取出噪声。        '''</span>        <span class="token keyword">print</span> <span class="token string">'主成分：%s, 方差占比：%s%%'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>format<span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'2.0f'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> format<span class="token punctuation">(</span>SigmaI<span class="token operator">/</span>SigmaSum<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token string">'4.2f'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><blockquote><p>使用算法: 对比使用 SVD 前后的数据差异对比，对于存储大家可以试着写写</p></blockquote><p>例如：<code>32*32=1024 =&gt; 32*2+2*1+32*2=130</code>(2*1表示去掉了除对角线的0), 几乎获得了10倍的压缩比。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 打印矩阵</span><span class="token keyword">def</span> <span class="token function">printMat</span><span class="token punctuation">(</span>inMat<span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 由于矩阵保护了浮点数，因此定义浅色和深色，遍历所有矩阵元素，当元素大于阀值时打印1，否则打印0</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> float<span class="token punctuation">(</span>inMat<span class="token punctuation">[</span>i<span class="token punctuation">,</span> k<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">></span> thresh<span class="token punctuation">:</span>                <span class="token keyword">print</span> <span class="token number">1</span><span class="token punctuation">,</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">print</span> <span class="token number">0</span><span class="token punctuation">,</span>        <span class="token keyword">print</span> <span class="token string">''</span><span class="token comment" spellcheck="true"># 实现图像压缩，允许基于任意给定的奇异值数目来重构图像</span><span class="token keyword">def</span> <span class="token function">imgCompress</span><span class="token punctuation">(</span>numSV<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> thresh<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""imgCompress( )    Args:        numSV       Sigma长度           thresh      判断的阈值    """</span>    <span class="token comment" spellcheck="true"># 构建一个列表</span>    myMat <span class="token operator">=</span> imgLoadData<span class="token punctuation">(</span><span class="token string">'data/14.SVD/0_5.txt'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span> <span class="token string">"****original matrix****"</span>    <span class="token comment" spellcheck="true"># 对原始图像进行SVD分解并重构图像e</span>    printMat<span class="token punctuation">(</span>myMat<span class="token punctuation">,</span> thresh<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 通过Sigma 重新构成SigRecom来实现</span>    <span class="token comment" spellcheck="true"># Sigma是一个对角矩阵，因此需要建立一个全0矩阵，然后将前面的那些奇异值填充到对角线上。</span>    U<span class="token punctuation">,</span> Sigma<span class="token punctuation">,</span> VT <span class="token operator">=</span> la<span class="token punctuation">.</span>svd<span class="token punctuation">(</span>myMat<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># SigRecon = mat(zeros((numSV, numSV)))</span>    <span class="token comment" spellcheck="true"># for k in range(numSV):</span>    <span class="token comment" spellcheck="true">#     SigRecon[k, k] = Sigma[k]</span>    <span class="token comment" spellcheck="true"># 分析插入的 Sigma 长度</span>    analyse_data<span class="token punctuation">(</span>Sigma<span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>    SigRecon <span class="token operator">=</span> mat<span class="token punctuation">(</span>eye<span class="token punctuation">(</span>numSV<span class="token punctuation">)</span> <span class="token operator">*</span> Sigma<span class="token punctuation">[</span><span class="token punctuation">:</span> numSV<span class="token punctuation">]</span><span class="token punctuation">)</span>    reconMat <span class="token operator">=</span> U<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>numSV<span class="token punctuation">]</span> <span class="token operator">*</span> SigRecon <span class="token operator">*</span> VT<span class="token punctuation">[</span><span class="token punctuation">:</span>numSV<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token keyword">print</span> <span class="token string">"****reconstructed matrix using %d singular values *****"</span> <span class="token operator">%</span> numSV    printMat<span class="token punctuation">(</span>reconMat<span class="token punctuation">,</span> thresh<span class="token punctuation">)</span></code></pre><hr><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征降维</title>
      <link href="/2020/05/12/te-zheng-gong-cheng-te-zheng-jiang-wei/"/>
      <url>/2020/05/12/te-zheng-gong-cheng-te-zheng-jiang-wei/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex13_1 PCA算法实现步骤</span><span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_splitdf_wine <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'wine.data'</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">)</span>df_wine<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Class label'</span><span class="token punctuation">,</span> <span class="token string">'Alcohol'</span><span class="token punctuation">,</span> <span class="token string">'Malic acid'</span><span class="token punctuation">,</span> <span class="token string">'Ash'</span><span class="token punctuation">,</span> <span class="token string">'Alcalinity of ash'</span><span class="token punctuation">,</span> <span class="token string">'Magnesium'</span><span class="token punctuation">,</span> <span class="token string">'Total phenols'</span><span class="token punctuation">,</span> <span class="token string">'Flavanoids'</span><span class="token punctuation">,</span> <span class="token string">'Nonflavanoid phenols'</span><span class="token punctuation">,</span> <span class="token string">'Proanthocyanins'</span><span class="token punctuation">,</span> <span class="token string">'Color intensity'</span><span class="token punctuation">,</span> <span class="token string">'Hue'</span><span class="token punctuation">,</span> <span class="token string">'OD280/OD315 of diluted wines'</span><span class="token punctuation">,</span> <span class="token string">'Proline'</span><span class="token punctuation">]</span>df_wine<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>X<span class="token punctuation">,</span> y <span class="token operator">=</span> df_wine<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> df_wine<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesX_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> \        train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 标准化</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScalersc <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_test_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 利用Numpy的linalg.eig()获得协方差矩阵的特征向量和特征值</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npcov_mat <span class="token operator">=</span> np<span class="token punctuation">.</span>cov<span class="token punctuation">(</span>X_train_std<span class="token punctuation">.</span>T<span class="token punctuation">)</span>eigen_vals<span class="token punctuation">,</span> eigen_vecs <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>eig<span class="token punctuation">(</span>cov_mat<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## eigen_vecs 13*13</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Eigenvalues \n %s'</span> <span class="token operator">%</span> eigen_vals<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'eigen_vecss \n %s'</span> <span class="token operator">%</span> eigen_vecs<span class="token punctuation">)</span></code></pre><pre><code>Eigenvalues  [4.8923083  2.46635032 1.42809973 1.01233462 0.84906459 0.60181514 0.52251546 0.08414846 0.33051429 0.29595018 0.16831254 0.21432212 0.2399553 ]eigen_vecss  [[ 1.46698114e-01  5.04170789e-01 -1.17235150e-01  2.06254611e-01  -1.87815947e-01 -1.48851318e-01 -1.79263662e-01 -5.54687162e-02  -4.03054922e-01 -4.17197583e-01  2.75660860e-01  4.03567189e-01   4.13320786e-04] [-2.42245536e-01  2.42168894e-01  1.49946576e-01  1.30489298e-01   5.68639776e-01 -2.69052764e-01 -5.92636731e-01  3.32731614e-02  -1.01833706e-01  2.17101488e-01 -8.13845005e-02 -1.52474999e-01  -8.78560762e-02] [-2.99344215e-02  2.86984836e-01  6.56394387e-01  1.51536318e-02  -2.99209426e-01 -9.33386061e-02  6.07334578e-02 -1.00618575e-01   3.51841423e-01  1.28549846e-01 -1.29751275e-02  1.68376064e-01  -4.52518598e-01] [-2.55190023e-01 -6.46871827e-02  5.84282337e-01 -9.04220851e-02  -4.12499478e-02 -1.01342392e-01  2.50323869e-01  5.61658566e-02  -5.00457282e-01  4.73344124e-02  9.89088030e-02 -6.70902926e-02   4.86169765e-01] [ 1.20797723e-01  2.29953850e-01  8.22627466e-02 -8.39128346e-01  -2.71971315e-02  1.12567350e-01 -2.85240559e-01  9.58423947e-02   8.37391743e-02 -2.78918776e-01 -9.59297663e-02 -1.02396856e-01   1.14764951e-01] [ 3.89344551e-01  9.36399132e-02  1.80804417e-01  1.93179478e-01   1.40645426e-01  1.22248798e-02  5.31455344e-02 -4.21265116e-01   1.35111456e-01 -2.80985650e-01  2.83897644e-01 -6.18600153e-01   9.45645138e-02] [ 4.23264856e-01  1.08862204e-02  1.42959330e-01  1.40459548e-01   9.26866486e-02 -5.50345182e-02  7.98994076e-02  8.47224703e-01   3.36016514e-03 -3.91442963e-02  1.16729207e-01 -1.39680277e-01  -1.00444099e-01] [-3.06349555e-01  1.87021637e-02  1.72234753e-01  3.37332618e-01  -8.58416771e-02  6.95340883e-01 -2.97371718e-01  1.66256803e-01   1.90120758e-01 -2.78622194e-01 -3.96566280e-02  1.63323514e-03   2.00128778e-01] [ 3.05722194e-01  3.04035180e-02  1.58362102e-01 -1.14752900e-01   5.65105241e-01  4.98354410e-01  2.02519133e-01 -1.66197468e-01  -1.76029939e-01  1.48539457e-01  8.60602743e-02  3.88568490e-01  -1.39942067e-01] [-9.86919131e-02  5.45270809e-01 -1.42421708e-01  7.87857057e-02   1.32346052e-02  1.59452160e-01  3.97364107e-01  3.96173606e-02  -2.14930670e-01 -4.10240865e-03 -5.71651893e-01 -3.08345904e-01  -1.15349466e-01] [ 3.00325353e-01 -2.79243218e-01  9.32387182e-02  2.41740256e-02  -3.72610811e-01  2.16515349e-01 -3.84654748e-01 -1.05383688e-01  -5.17259438e-01  1.97814118e-01 -1.98844532e-01 -2.00456386e-01  -3.02254353e-01] [ 3.68211538e-01 -1.74365000e-01  1.96077407e-01  1.84028641e-01   8.93796748e-02 -2.35172361e-01 -8.62903341e-02 -9.95055559e-02   1.36456039e-01 -2.38138151e-01 -6.50869713e-01  2.84100327e-01   3.18414303e-01] [ 2.92597130e-01  3.63154608e-01 -9.73171134e-02  5.67677845e-02  -2.17529485e-01  1.05621383e-01 -1.30298291e-01 -1.60661776e-02   1.67758429e-01  6.37350206e-01  7.12377082e-02  3.75546771e-02   5.03247839e-01]]</code></pre><pre class=" language-python"><code class="language-python">tot <span class="token operator">=</span> sum<span class="token punctuation">(</span>eigen_vals<span class="token punctuation">)</span>var_exp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">/</span> tot<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> sorted<span class="token punctuation">(</span>eigen_vals<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">]</span>cum_var_exp <span class="token operator">=</span> np<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>var_exp<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># cumulative sum of explained variance</span><span class="token comment" spellcheck="true"># plot variance</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inlineplt<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">,</span> var_exp<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> align<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">,</span>        label<span class="token operator">=</span><span class="token string">'individual explained variance'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>step<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cum_var_exp<span class="token punctuation">,</span> where<span class="token operator">=</span><span class="token string">'mid'</span><span class="token punctuation">,</span>         label<span class="token operator">=</span><span class="token string">'cumulative explained variance'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Explained variance ratio'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Principal components'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_2_0.png" alt="png"></p><pre class=" language-python"><code class="language-python">eigen_pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>eigen_vals<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eigen_vecs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>eigen_vals<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># Sort the (eigenvalue, eigenvector) tuples from high to low</span>eigen_pairs<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 选择两个最大特征值的特征向量。实践中，要通过在计算效率和分类器性能之间的平衡来确定</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>column_stack<span class="token punctuation">(</span><span class="token punctuation">[</span>eigen_pairs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> eigen_pairs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">## 创建了一个13*2维的投影矩阵W</span><span class="token keyword">print</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span></code></pre><pre><code>[[ 0.14669811  0.50417079] [-0.24224554  0.24216889] [-0.02993442  0.28698484] [-0.25519002 -0.06468718] [ 0.12079772  0.22995385] [ 0.38934455  0.09363991] [ 0.42326486  0.01088622] [-0.30634956  0.01870216] [ 0.30572219  0.03040352] [-0.09869191  0.54527081] [ 0.30032535 -0.27924322] [ 0.36821154 -0.174365  ] [ 0.29259713  0.36315461]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 通过计算矩阵点积，将 整个 124×13-dimensional 维训练集转换为两个主成分</span>X_train_pca <span class="token operator">=</span> X_train_std<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">)</span>colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">]</span>markers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">]</span><span class="token keyword">for</span> l<span class="token punctuation">,</span> c<span class="token punctuation">,</span> m <span class="token keyword">in</span> zip<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> colors<span class="token punctuation">,</span> markers<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_train_pca<span class="token punctuation">[</span>y_train<span class="token operator">==</span>l<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 X_train_pca<span class="token punctuation">[</span>y_train<span class="token operator">==</span>l<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 c<span class="token operator">=</span>c<span class="token punctuation">,</span> label<span class="token operator">=</span>l<span class="token punctuation">,</span> marker<span class="token operator">=</span>m<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'PC 1'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'PC 2'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_4_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex13_2</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCApca <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token punctuation">)</span>X_train_pca <span class="token operator">=</span> pca<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train_std<span class="token punctuation">)</span>pca<span class="token punctuation">.</span>explained_variance_ratio_</code></pre><pre><code>array([0.37329648, 0.18818926, 0.10896791, 0.07724389, 0.06478595,       0.04592014, 0.03986936, 0.02521914, 0.02258181, 0.01830924,       0.01635336, 0.01284271, 0.00642076])</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pca<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> align<span class="token operator">=</span><span class="token string">'center'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>step<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>pca<span class="token punctuation">.</span>explained_variance_ratio_<span class="token punctuation">)</span><span class="token punctuation">,</span> where<span class="token operator">=</span><span class="token string">'mid'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Explained variance ratio'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Principal components'</span><span class="token punctuation">)</span></code></pre><pre><code>Text(0.5, 0, 'Principal components')</code></pre><p><img src="output_6_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> warningswarnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span><span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>colors <span class="token keyword">import</span> ListedColormap<span class="token keyword">def</span> <span class="token function">plot_decision_regions</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> classifier<span class="token punctuation">,</span> resolution<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># setup marker generator and color map</span>    markers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'^'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span>    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'lightgreen'</span><span class="token punctuation">,</span> <span class="token string">'gray'</span><span class="token punctuation">,</span> <span class="token string">'cyan'</span><span class="token punctuation">)</span>    cmap <span class="token operator">=</span> ListedColormap<span class="token punctuation">(</span>colors<span class="token punctuation">[</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot the decision surface</span>    x1_min<span class="token punctuation">,</span> x1_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    x2_min<span class="token punctuation">,</span> x2_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    xx1<span class="token punctuation">,</span> xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x1_min<span class="token punctuation">,</span> x1_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">,</span>                         np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x2_min<span class="token punctuation">,</span> x2_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">)</span>    Z <span class="token operator">=</span> classifier<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>xx1<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx1<span class="token punctuation">,</span> xx2<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx1<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>xx2<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot class samples</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> cl <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> cl<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> cl<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> c<span class="token operator">=</span>cmap<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">,</span>                    marker<span class="token operator">=</span>markers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>cl<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 训练集上的决策边界        </span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegressionlr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>lr <span class="token operator">=</span> lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_pca<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>plot_decision_regions<span class="token punctuation">(</span>X_train_pca<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> classifier<span class="token operator">=</span>lr<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'PC 1'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'PC 2'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>---------------------------------------------------------------------------ValueError                                Traceback (most recent call last)&lt;ipython-input-19-fe3a9f8a8303&gt; in &lt;module&gt;     34 lr = lr.fit(X_train_pca, y_train)     35 ---&gt; 36 plot_decision_regions(X_train_pca, y_train, classifier=lr)     37 plt.xlabel('PC 1')     38 plt.ylabel('PC 2')&lt;ipython-input-19-fe3a9f8a8303&gt; in plot_decision_regions(X, y, classifier, resolution)     16     xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),     17                          np.arange(x2_min, x2_max, resolution))---&gt; 18     Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)     19     Z = Z.reshape(xx1.shape)     20     plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)~\Anaconda3\lib\site-packages\sklearn\linear_model\base.py in predict(self, X)    287             Predicted class label per sample.    288         """--&gt; 289         scores = self.decision_function(X)    290         if len(scores.shape) == 1:    291             indices = (scores &gt; 0).astype(np.int)~\Anaconda3\lib\site-packages\sklearn\linear_model\base.py in decision_function(self, X)    268         if X.shape[1] != n_features:    269             raise ValueError("X has %d features per sample; expecting %d"--&gt; 270                              % (X.shape[1], n_features))    271     272         scores = safe_sparse_dot(X, self.coef_.T,ValueError: X has 2 features per sample; expecting 13</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true">## 3.2 产生均值向量</span>np<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>mean_vecs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> label <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    mean_vecs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>                X_train_std<span class="token punctuation">[</span>y_train<span class="token operator">==</span>label<span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'MV %s: %s\n'</span> <span class="token operator">%</span><span class="token punctuation">(</span>label<span class="token punctuation">,</span> mean_vecs<span class="token punctuation">[</span>label<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>MV 1: [ 0.9259 -0.3091  0.2592 -0.7989  0.3039  0.9608  1.0515 -0.6306  0.5354  0.2209  0.4855  0.798   1.2017]MV 2: [-0.8727 -0.3854 -0.4437  0.2481 -0.2409 -0.1059  0.0187 -0.0164  0.1095 -0.8796  0.4392  0.2776 -0.7016]MV 3: [ 0.1637  0.8929  0.3249  0.5658 -0.01   -0.9499 -1.228   0.7436 -0.7652  0.979  -1.1698 -1.3007 -0.3912]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 计算类内散布矩阵(协方差矩阵) S_w</span>d <span class="token operator">=</span> <span class="token number">13</span>S_W <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> label<span class="token punctuation">,</span> mv <span class="token keyword">in</span> zip<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> mean_vecs<span class="token punctuation">)</span><span class="token punctuation">:</span>    class_scatter <span class="token operator">=</span> np<span class="token punctuation">.</span>cov<span class="token punctuation">(</span>X_train_std<span class="token punctuation">[</span>y_train<span class="token operator">==</span>label<span class="token punctuation">]</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>    S_W <span class="token operator">+=</span> class_scatter<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Scaled within-class scatter matrix: %s*%s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>S_W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> S_W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 计算类间散布矩阵S_B</span>mean_overall <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>d <span class="token operator">=</span> <span class="token number">13</span>S_B <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> mean_vec <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>mean_vecs<span class="token punctuation">)</span><span class="token punctuation">:</span>    n <span class="token operator">=</span> X_train<span class="token punctuation">[</span>y_train <span class="token operator">==</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    mean_vec <span class="token operator">=</span> mean_vec<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>d<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>    mean_overall <span class="token operator">=</span> mean_overall<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>d<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>    S_B <span class="token operator">+=</span> n <span class="token operator">*</span> <span class="token punctuation">(</span>mean_vec <span class="token operator">-</span> mean_overall<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>                <span class="token punctuation">(</span>mean_vec <span class="token operator">-</span> mean_overall<span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Between-class scatter matrix: %s*%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>            S_B<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> S_B<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Scaled within-class scatter matrix: 13*13Between-class scatter matrix: 13*13</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 3.4 求解矩阵Sw-1Sb的广义特征值</span>eigen_vals<span class="token punctuation">,</span> eigen_vecs <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>eig<span class="token punctuation">(</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>S_W<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>S_B<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 3.5 按降序对特征值排序</span>eigen_pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>abs<span class="token punctuation">(</span>eigen_vals<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> eigen_vecs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>              <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>eigen_vals<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>eigen_pairs <span class="token operator">=</span> sorted<span class="token punctuation">(</span>eigen_pairs<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> k<span class="token punctuation">:</span>k<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Eigenvalues in descending order:\n'</span><span class="token punctuation">)</span><span class="token keyword">for</span> item <span class="token keyword">in</span> eigen_pairs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre><code>Eigenvalues in descending order:452.72158124497435156.436361219523231.0564670343472254e-133.996418537019543e-143.409235652909593e-142.842170943040401e-141.4793035293048285e-141.4793035293048285e-141.3494134504023504e-141.3494134504023504e-146.491059855852737e-156.491059855852737e-152.655812157040677e-15</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##创建投影矩阵</span>w <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>eigen_pairs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>real<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">,</span>              eigen_pairs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>real<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Matrix W:\n'</span><span class="token punctuation">,</span>w<span class="token punctuation">)</span></code></pre><pre><code>Matrix W: [[-0.0662 -0.3797] [ 0.0386 -0.2206] [-0.0217 -0.3816] [ 0.184   0.3018] [-0.0034  0.0141] [ 0.2326  0.0234] [-0.7747  0.1869] [-0.0811  0.0696] [ 0.0875  0.1796] [ 0.185  -0.284 ] [-0.066   0.2349] [-0.3805  0.073 ] [-0.3285 -0.5971]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 3.7 通过矩阵相乘来转换训练集</span>X_train_lda <span class="token operator">=</span> X_train_std<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">)</span>colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">]</span>markers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">]</span><span class="token keyword">for</span> l<span class="token punctuation">,</span> c<span class="token punctuation">,</span> m <span class="token keyword">in</span> zip<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> colors<span class="token punctuation">,</span> markers<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_train_lda<span class="token punctuation">[</span>y_train<span class="token operator">==</span>l<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>               X_train_lda<span class="token punctuation">[</span>y_train<span class="token operator">==</span>l<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>               c <span class="token operator">=</span> c<span class="token punctuation">,</span> label<span class="token operator">=</span>l<span class="token punctuation">,</span> marker<span class="token operator">=</span>m<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'LD 1'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'LD 2'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_12_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于复杂网络和SEIR传染病模型的COVID-19疫情发展仿真</title>
      <link href="/2020/04/20/network-seir/"/>
      <url>/2020/04/20/network-seir/</url>
      
        <content type="html"><![CDATA[<h1 id="基于复杂网络和SEIR传染病模型的COVID-19疫情发展仿真"><a href="#基于复杂网络和SEIR传染病模型的COVID-19疫情发展仿真" class="headerlink" title="基于复杂网络和SEIR传染病模型的COVID-19疫情发展仿真"></a>基于复杂网络和SEIR传染病模型的COVID-19疫情发展仿真</h1><h1 id="参数说明"><a href="#参数说明" class="headerlink" title="参数说明"></a>参数说明</h1><ul><li>p ：结点 i,j 结点代号</li><li>θ：不注意活动接触到病毒人群流动意向y_i，该结点开放；0则封闭</li><li>β：接触后感染率\mu治愈率</li><li>η：转变为易感人群概率Adj_i结点 i 的邻接点集合</li></ul><h1 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h1><p>Albert-László Barabási 和Réka Albert为了解释幂律的产生机制，提出了无标度网络模型（BA模型）。</p><p>可假设人与人间构成了 BA 网络，因为：</p><ul><li>人类社会组织存在小世界性、无标度性；</li><li>个体间存在差异，结点的度服从幂律分布。</li></ul><p>符号表如下。</p><table><thead><tr><th>Notation</th><th>Description</th><th>Notation</th><th>Description</th></tr></thead><tbody><tr><td>$p$</td><td>结点</td><td>$i,j$</td><td>结点代号</td></tr><tr><td>$\theta$</td><td>不注意活动接触到病毒人群流动意向</td><td>$y_i$</td><td>1，该结点开放；0则封闭</td></tr><tr><td>$\beta$</td><td>接触后感染率</td><td>$\mu$</td><td>治愈率</td></tr><tr><td>$\eta$</td><td>转变为易感人群概率</td><td>$Adj_i$</td><td>结点 $i$ 的邻接点集合</td></tr></tbody></table><p>对于每个结点，状态转移概率服从修正的 SEIR 模型：</p><p><img src="SEIR_model.png" alt="SEIR"></p><p>其中，对于结点 i，<br>$$<br>f_i(Adj_i)<br>$$<br> 为</p><p>$$<br>f_i(Adj_i) = (1 - \prod_{j \in Adj_i \cap Latent}(1-\theta) y_j)y_i<br>$$</p><p>$$<br>Latent<br>$$<br> 为潜伏期人群集合。</p><hr><p>举例解释一下上述模型中的传染公式：</p><p><img src="SEIR_model_ex.png">   </p><p>假设对于结点  i，其临界结点集合<br>$$<br> Adj_i = {1,2,3,4}<br>$$<br>，其中2、4结点是封闭的。</p><p>在每天中，如果  i  未封闭，则会与1、2、3、4中未封闭的点以概率 θ进行互动，如果互动，并且  j 处于潜伏期，则有 β 的概率使  i 染病。</p><p>从对立事件考虑  i  患病概率，则为：</p><p>$$<br>\beta (1 - \prod_{j \in Adj_i \cap not-seal \cap Latent}(1-\theta))<br>$$</p><p>在数学上表达是否封闭，则加入 y_j 变量，因此可定义每次迭代中，i 被感染的概率为：</p><p>$$<br>\beta f_i(Adj_i) = \beta (1 - \prod_{j \in Adj_i \cap Latent}(1-\theta) y_j)y_i<br>$$</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token comment" spellcheck="true">#进度条可视</span><span class="token keyword">from</span> tqdm <span class="token keyword">import</span> trange<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> os<span class="token keyword">import</span> systhis_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># this_dir = osp.dirname(__file__)</span><span class="token keyword">print</span><span class="token punctuation">(</span>this_dir<span class="token punctuation">)</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>this_dir<span class="token punctuation">)</span>sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span>path<span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\python projects\《算法导论》\THE MODEL OF SEIR BASED NETWORK</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> family <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment" spellcheck="true"># using ba network</span><span class="token keyword">def</span> <span class="token function">return_family_list</span><span class="token punctuation">(</span>n<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> m<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">#BA network</span>    G <span class="token operator">=</span> nx<span class="token punctuation">.</span>random_graphs<span class="token punctuation">.</span>barabasi_albert_graph<span class="token punctuation">(</span>n<span class="token punctuation">,</span> m<span class="token punctuation">,</span> seed<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#regular network</span>    <span class="token comment" spellcheck="true">#G = nx.random_graphs.random_regular_graph(节点的度,节点数)</span>    <span class="token comment" spellcheck="true">#随机图</span>    <span class="token comment" spellcheck="true">#G = nx.random_graphs.erdos_renyi_graph(节点数, 链接概率)</span>    <span class="token comment" spellcheck="true">#WS小世界网络</span>    <span class="token comment" spellcheck="true">#WS = nx.random_graphs.watts_strogatz_graph(节点数, 节点的度, 链接概率)</span>    <span class="token comment" spellcheck="true"># generate fam_list</span>    fam_list <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>    adj <span class="token operator">=</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> g <span class="token keyword">in</span> G<span class="token punctuation">:</span>        fam <span class="token operator">=</span> family<span class="token punctuation">(</span>label<span class="token operator">=</span>g<span class="token punctuation">)</span>        fam_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fam<span class="token punctuation">)</span>    <span class="token keyword">for</span> g_1<span class="token punctuation">,</span> g_2 <span class="token keyword">in</span> adj<span class="token punctuation">:</span>        f_1 <span class="token operator">=</span> fam_list<span class="token punctuation">[</span>g_1<span class="token punctuation">]</span>        f_2 <span class="token operator">=</span> fam_list<span class="token punctuation">[</span>g_2<span class="token punctuation">]</span>        f_1<span class="token punctuation">.</span>relate<span class="token punctuation">(</span>f_2<span class="token punctuation">)</span>    <span class="token keyword">return</span> fam_list<span class="token punctuation">,</span> G</code></pre><h1 id="Part1：节点流动概率对疫情传播程度的影响"><a href="#Part1：节点流动概率对疫情传播程度的影响" class="headerlink" title="Part1：节点流动概率对疫情传播程度的影响"></a>Part1：节点流动概率对疫情传播程度的影响</h1><h4 id="关键参数-θ：节点流动概率"><a href="#关键参数-θ：节点流动概率" class="headerlink" title="关键参数 θ：节点流动概率"></a>关键参数 θ：节点流动概率</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> calculator <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">def</span> <span class="token function">experiment_1_THETA</span><span class="token punctuation">(</span>fam_list<span class="token punctuation">,</span> THETAs<span class="token punctuation">,</span> INFECT_INIT<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> days<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> runs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    cal <span class="token operator">=</span> Calculator<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span>    states_each_experiment <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>    states_each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>runs<span class="token punctuation">,</span> THETAs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> days<span class="token punctuation">,</span> len<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> r <span class="token keyword">in</span> range<span class="token punctuation">(</span>runs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> t <span class="token keyword">in</span> trange<span class="token punctuation">(</span>len<span class="token punctuation">(</span>THETAs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            theta <span class="token operator">=</span> THETAs<span class="token punctuation">[</span>t<span class="token punctuation">]</span>            <span class="token comment" spellcheck="true"># print("theta: " + str(theta))</span>            paras<span class="token punctuation">.</span>THETA <span class="token operator">=</span> theta            cal<span class="token punctuation">.</span>cls<span class="token punctuation">(</span><span class="token punctuation">)</span>            infects <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">while</span> len<span class="token punctuation">(</span>infects<span class="token punctuation">)</span> <span class="token operator">&lt;</span> INFECT_INIT<span class="token punctuation">:</span>                i <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span><span class="token punctuation">)</span>                infects<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> infects<span class="token punctuation">:</span>                fam_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>state <span class="token operator">=</span> <span class="token number">5</span>            <span class="token comment" spellcheck="true"># cal.next_iter(days) returns [day:[state, state, state]]</span>            each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>cal<span class="token punctuation">.</span>next_iter<span class="token punctuation">(</span>days<span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># each_experiment = [sum(data!=0) for data in each_experiment]</span>            states_each_experiment<span class="token punctuation">[</span>r<span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">=</span> states_each_experiment<span class="token punctuation">[</span>r<span class="token punctuation">,</span> t<span class="token punctuation">]</span> <span class="token operator">+</span> each_experiment    <span class="token keyword">return</span> states_each_experiment</code></pre><pre class=" language-python"><code class="language-python">fam_list<span class="token punctuation">,</span> G<span class="token operator">=</span> return_family_list<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment 1.0</span>days <span class="token operator">=</span> <span class="token number">120</span>THETAs <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.001</span><span class="token punctuation">,</span> <span class="token number">0.004</span><span class="token punctuation">,</span> <span class="token number">0.008</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">,</span><span class="token number">0.04</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">,</span><span class="token number">0.08</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">]</span><span class="token punctuation">)</span>ex_0_data <span class="token operator">=</span> experiment_1_THETA<span class="token punctuation">(</span>fam_list<span class="token punctuation">,</span> days<span class="token operator">=</span>days<span class="token punctuation">,</span> THETAs<span class="token operator">=</span>THETAs<span class="token punctuation">)</span></code></pre><pre><code>100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.97it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.94it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.99it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.95it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.97it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.94it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.97it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.97it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.94it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05&lt;00:00,  2.01it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05&lt;00:00,  2.01it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.97it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:07&lt;00:00,  1.51it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.85it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.80it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.87it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.89it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.82it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.89it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.86it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.75it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.81it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.81it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:05&lt;00:00,  2.00it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.90it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.91it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.91it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:07&lt;00:00,  1.69it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.80it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:06&lt;00:00,  1.88it/s]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment 1.0</span><span class="token comment" spellcheck="true"># data</span>run_theta_day_state <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_0_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># show results</span>theta_day <span class="token operator">=</span> run_theta_day_state<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#在matplotlib一般使用plt.figure来设置窗口尺寸 （宽，高）</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>labelsize<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">)</span><span class="token keyword">for</span> t<span class="token punctuation">,</span> theta <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>THETAs<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> days<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">30</span><span class="token operator">/</span><span class="token number">1000</span><span class="token punctuation">]</span> <span class="token operator">+</span> list<span class="token punctuation">(</span>theta_day<span class="token punctuation">[</span>t<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'days'</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'percentage of infected people'</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token string">'$\theta=$'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>theta<span class="token punctuation">)</span> <span class="token keyword">for</span> theta <span class="token keyword">in</span> THETAs<span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_10_0.png" alt="png"></p><p>描述：$\theta$ 越大，爆发的速度越快，对疫情传播的影响越大</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># show nx draw</span><span class="token comment" spellcheck="true"># plot nodes on plt based on networkx</span>DAY <span class="token operator">=</span> <span class="token number">10</span><span class="token comment" spellcheck="true">#subplots(行，列)  figsize=(宽，高)</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> t <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>THETAs<span class="token punctuation">)</span><span class="token punctuation">:</span>    states <span class="token operator">=</span> run_theta_day_state<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> DAY<span class="token number">-1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">#spring_layout： 用Fruchterman-Reingold算法排列节点（这个算法我不了解，样子类似多中心放射状）</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span>node_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span>states<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span>iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>OrRd<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">'$\theta=$'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\Anaconda3\lib\site-packages\networkx\drawing\nx_pylab.py:579: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.  if not cb.iterable(width):</code></pre><p><img src="output_12_1.png" alt="png"></p><p>上图结点越深，说明该结点患病概率越高。</p><p>可以看出，当 $\theta$ 值不大于 0.03 时，疫情传播并不严重，当 $\theta$ 值大于0.03时，疫情传播速度将以指数级迅速在网络中蔓延</p><h1 id="Part2：探究网络结构（节点密度、链接概率）对传播速度的影响效果"><a href="#Part2：探究网络结构（节点密度、链接概率）对传播速度的影响效果" class="headerlink" title="Part2：探究网络结构（节点密度、链接概率）对传播速度的影响效果"></a>Part2：探究网络结构（节点密度、链接概率）对传播速度的影响效果</h1><h4 id="关键参数-M-0-网络结构参数（值越大，结构越紧密）"><a href="#关键参数-M-0-网络结构参数（值越大，结构越紧密）" class="headerlink" title="关键参数 $M_0$  网络结构参数（值越大，结构越紧密）"></a>关键参数 $M_0$  网络结构参数（值越大，结构越紧密）</h4><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># observe</span>Ms <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">]</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> M <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>Ms<span class="token punctuation">)</span><span class="token punctuation">:</span>    fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span>m<span class="token operator">=</span>M<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'#5C3317'</span><span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'#00FF00'</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">'$M_0=$'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>M<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span> <span class="token operator">+</span> <span class="token string">'average_path_length: '</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>round<span class="token punctuation">(</span>nx<span class="token punctuation">.</span>average_shortest_path_length<span class="token punctuation">(</span>G<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">7</span><span class="token punctuation">)</span>    d <span class="token operator">=</span> nx<span class="token punctuation">.</span>degree_histogram<span class="token punctuation">(</span>G<span class="token punctuation">)</span>    x <span class="token operator">=</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span>               y <span class="token operator">=</span> <span class="token punctuation">[</span>z <span class="token operator">/</span> float<span class="token punctuation">(</span>sum<span class="token punctuation">(</span>d<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> z <span class="token keyword">in</span> d<span class="token punctuation">]</span>    plt<span class="token punctuation">.</span>loglog<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> <span class="token string">'b*'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_16_0.png" alt="png"></p><p>如图所示：</p><ul><li>当参数 $M_0$ (Number of edges to attach from a new node to existing nodes) 增大时（社会组织结构更紧密），两点间平均距离average_path_length也变小。</li><li>度都是呈幂律分布(符合人类社会的真实规律)</li></ul><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment</span><span class="token keyword">from</span> calculator <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment" spellcheck="true"># @return:  illed people [runs:[M_0:[day:[state]]]]</span><span class="token comment" spellcheck="true"># /= runs for average</span><span class="token keyword">def</span> <span class="token function">experiment_2_M0</span><span class="token punctuation">(</span>Ms<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> INFECT_INIT<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> days<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> runs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> theta<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    states_each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>runs<span class="token punctuation">,</span> len<span class="token punctuation">(</span>Ms<span class="token punctuation">)</span><span class="token punctuation">,</span> days<span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    paras<span class="token punctuation">.</span>THETA <span class="token operator">=</span> theta    <span class="token keyword">for</span> m<span class="token punctuation">,</span> M <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>Ms<span class="token punctuation">)</span><span class="token punctuation">:</span>        fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span>n<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> m<span class="token operator">=</span>M<span class="token punctuation">)</span>        cal <span class="token operator">=</span> Calculator<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span>        <span class="token keyword">for</span> r <span class="token keyword">in</span> trange<span class="token punctuation">(</span>runs<span class="token punctuation">)</span><span class="token punctuation">:</span>            cal<span class="token punctuation">.</span>cls<span class="token punctuation">(</span><span class="token punctuation">)</span>            infects <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">while</span> len<span class="token punctuation">(</span>infects<span class="token punctuation">)</span> <span class="token operator">&lt;</span> INFECT_INIT<span class="token punctuation">:</span>                i <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span><span class="token punctuation">)</span>                infects<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> infects<span class="token punctuation">:</span>                fam_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>state <span class="token operator">=</span> <span class="token number">5</span>            <span class="token comment" spellcheck="true"># cal.next_iter(days) returns [day:[state, state, state]]</span>            each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>cal<span class="token punctuation">.</span>next_iter<span class="token punctuation">(</span>days<span class="token punctuation">)</span><span class="token punctuation">)</span>            states_each_experiment<span class="token punctuation">[</span>r<span class="token punctuation">,</span> m<span class="token punctuation">]</span> <span class="token operator">=</span> each_experiment    <span class="token keyword">return</span> states_each_experiment</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment 2</span>ex_2_data <span class="token operator">=</span> experiment_2_M0<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01&lt;00:00, 26.78it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02&lt;00:00, 13.67it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03&lt;00:00,  8.64it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03&lt;00:00,  8.20it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:04&lt;00:00,  7.00it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:04&lt;00:00,  7.07it/s]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># data</span>run_M0_day_state <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_2_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># show results</span>Ms<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span>M0_day <span class="token operator">=</span> run_M0_day_state<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> M <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>Ms<span class="token punctuation">)</span><span class="token punctuation">:</span>    fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span>m<span class="token operator">=</span>M<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    states <span class="token operator">=</span> run_M0_day_state<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span>states<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>OrRd<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">'$M_0=$'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>M<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span> <span class="token operator">+</span> <span class="token string">'day-15 infected possibiliy'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">7</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> M0_day<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1.05</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'infected people in 15 days'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_21_0.png" alt="png"></p><p>描述：社会结构变得紧密时，传播速度也会增加，个体患病概率也会增加。</p><h1 id="Part3：探究调节网络结构参数对疫情传播的影响效果"><a href="#Part3：探究调节网络结构参数对疫情传播的影响效果" class="headerlink" title="Part3：探究调节网络结构参数对疫情传播的影响效果"></a>Part3：探究调节网络结构参数对疫情传播的影响效果</h1><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># observe</span>fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span><span class="token punctuation">)</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    node_size <span class="token operator">=</span> <span class="token number">5</span>    node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>len<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span>    nodelist <span class="token operator">=</span> G<span class="token punctuation">.</span>nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"degrees"</span><span class="token punctuation">)</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">"degrees:"</span> <span class="token operator">+</span> <span class="token string">"30‰"</span><span class="token punctuation">)</span>        nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> <span class="token number">5</span><span class="token punctuation">]</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> nodelist<span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">"degree:"</span> <span class="token operator">+</span> <span class="token string">"25‰"</span><span class="token punctuation">)</span>        nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> <span class="token number">15</span><span class="token punctuation">]</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> nodelist<span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">3</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">"degrees:"</span> <span class="token operator">+</span> <span class="token string">"20‰"</span><span class="token punctuation">)</span>        nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> <span class="token number">20</span><span class="token punctuation">]</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> nodelist<span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">4</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">"degrees:"</span> <span class="token operator">+</span> <span class="token string">"15‰"</span><span class="token punctuation">)</span>        nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> <span class="token number">25</span><span class="token punctuation">]</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> nodelist<span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">5</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">"degrees:"</span> <span class="token operator">+</span> <span class="token string">"10‰"</span><span class="token punctuation">)</span>        nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> <span class="token number">30</span><span class="token punctuation">]</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> nodelist<span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">6</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">"degrees:"</span> <span class="token operator">+</span> <span class="token string">"5‰"</span><span class="token punctuation">)</span>        nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>d<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> d<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> <span class="token number">30</span><span class="token punctuation">]</span>        node_size <span class="token operator">=</span> <span class="token punctuation">[</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> nodelist<span class="token punctuation">]</span>        node_color <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>d<span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>max<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token operator">-</span>min<span class="token punctuation">(</span>node_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> d <span class="token keyword">in</span> node_size<span class="token punctuation">]</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> node_size<span class="token operator">=</span>node_size<span class="token punctuation">,</span> node_color<span class="token operator">=</span>node_color<span class="token punctuation">,</span> nodelist<span class="token operator">=</span>nodelist<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Blues_r<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_24_0.png" alt="png"></p><p>着色节点代表网络中的密集活动者，即起传播作用的关键节点</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment</span><span class="token keyword">from</span> calculator <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment" spellcheck="true"># @return:  illed people [runs:[D:[day:[state]]]]</span><span class="token comment" spellcheck="true"># /= runs for average</span><span class="token keyword">def</span> <span class="token function">experiment_3_hubs</span><span class="token punctuation">(</span>Ds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">9999</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> INFECT_INIT<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> days<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">,</span> runs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> theta<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    states_each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>runs<span class="token punctuation">,</span> len<span class="token punctuation">(</span>Ds<span class="token punctuation">)</span><span class="token punctuation">,</span> days<span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    paras<span class="token punctuation">.</span>THETA <span class="token operator">=</span> theta    <span class="token keyword">for</span> d<span class="token punctuation">,</span> D <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>Ds<span class="token punctuation">)</span><span class="token punctuation">:</span>        fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span>n<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>        cal <span class="token operator">=</span> Calculator<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span>        <span class="token keyword">for</span> r <span class="token keyword">in</span> trange<span class="token punctuation">(</span>runs<span class="token punctuation">)</span><span class="token punctuation">:</span>            cal<span class="token punctuation">.</span>cls<span class="token punctuation">(</span><span class="token punctuation">)</span>            infects <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">while</span> len<span class="token punctuation">(</span>infects<span class="token punctuation">)</span> <span class="token operator">&lt;</span> INFECT_INIT<span class="token punctuation">:</span>                i <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span><span class="token punctuation">)</span>                infects<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> infects<span class="token punctuation">:</span>                fam_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>state <span class="token operator">=</span> <span class="token number">5</span>            <span class="token comment" spellcheck="true"># control hubs</span>            <span class="token keyword">for</span> fam <span class="token keyword">in</span> fam_list<span class="token punctuation">:</span>                fam<span class="token punctuation">.</span>seal <span class="token operator">=</span> <span class="token boolean">False</span>            nodelist <span class="token operator">=</span> <span class="token punctuation">[</span>degree<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> degree <span class="token keyword">in</span> list<span class="token punctuation">(</span>G<span class="token punctuation">.</span>degree<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> degree<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">>=</span> D<span class="token punctuation">]</span>            <span class="token keyword">for</span> fam <span class="token keyword">in</span> fam_list<span class="token punctuation">:</span>                <span class="token keyword">if</span> fam<span class="token punctuation">.</span>label <span class="token keyword">in</span> nodelist<span class="token punctuation">:</span>                    fam<span class="token punctuation">.</span>seal <span class="token operator">=</span> <span class="token boolean">True</span>            <span class="token comment" spellcheck="true"># cal.next_iter(days) returns [day:[state, state, state]]</span>            each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>cal<span class="token punctuation">.</span>next_iter<span class="token punctuation">(</span>days<span class="token punctuation">)</span><span class="token punctuation">)</span>            states_each_experiment<span class="token punctuation">[</span>r<span class="token punctuation">,</span> d<span class="token punctuation">]</span> <span class="token operator">=</span> each_experiment    <span class="token keyword">return</span> states_each_experiment</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment 3</span>ex_3_data <span class="token operator">=</span> experiment_3_hubs<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03&lt;00:00,  8.83it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03&lt;00:00,  9.80it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:03&lt;00:00,  9.16it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02&lt;00:00, 11.52it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:02&lt;00:00, 12.85it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01&lt;00:00, 20.45it/s]100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:01&lt;00:00, 24.01it/s]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># data</span>run_D_day_state <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_3_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># show results</span>Ds<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">9999</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span>n<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>D_day <span class="token operator">=</span> run_D_day_state<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> D <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>Ds<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    states <span class="token operator">=</span> run_D_day_state<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span>states<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>OrRd<span class="token punctuation">)</span>    <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'no hubs to control'</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>r<span class="token string">'control degree:'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>D<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'‰'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">8</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> D_day<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'infected people in 15 days'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_29_0.png" alt="png"></p><p>描述：如图所示，随着管控程度的不断提高，疫情在网络中的传播速度下降明显，即在现实世界中，控制人口的流动将有利于控制疫情传播</p><h1 id="Part4：判断解控时机"><a href="#Part4：判断解控时机" class="headerlink" title="Part4：判断解控时机"></a>Part4：判断解控时机</h1><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># experiment</span><span class="token keyword">from</span> calculator <span class="token keyword">import</span> <span class="token operator">*</span><span class="token comment" spellcheck="true"># @return:  illed people [day:[state]]</span><span class="token keyword">def</span> <span class="token function">experiment_4_guard</span><span class="token punctuation">(</span>INFECT_INIT<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> flag<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    fam_list<span class="token punctuation">,</span> G <span class="token operator">=</span> return_family_list<span class="token punctuation">(</span><span class="token punctuation">)</span>    cal <span class="token operator">=</span> Calculator<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span>    states_each_experiment <span class="token operator">=</span> list<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">append_experiment</span><span class="token punctuation">(</span>experiment<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> states <span class="token keyword">in</span> experiment<span class="token punctuation">:</span>            states_each_experiment<span class="token punctuation">.</span>append<span class="token punctuation">(</span>states<span class="token punctuation">)</span>    day <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> day <span class="token operator">&lt;</span> <span class="token number">50</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> day <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            infects <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">while</span> len<span class="token punctuation">(</span>infects<span class="token punctuation">)</span> <span class="token operator">&lt;</span> INFECT_INIT<span class="token punctuation">:</span>                i <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>fam_list<span class="token punctuation">)</span><span class="token punctuation">)</span>                infects<span class="token punctuation">.</span>append<span class="token punctuation">(</span>i<span class="token punctuation">)</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> infects<span class="token punctuation">:</span>                fam_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>state <span class="token operator">=</span> <span class="token number">5</span>            paras<span class="token punctuation">.</span>THETA <span class="token operator">=</span> <span class="token number">0.05</span>        <span class="token keyword">if</span> day <span class="token operator">>=</span> <span class="token number">7</span> <span class="token operator">and</span> day <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">:</span>            paras<span class="token punctuation">.</span>THETA <span class="token operator">*=</span> <span class="token number">0.5</span>            paras<span class="token punctuation">.</span>ETA <span class="token operator">=</span> min<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> paras<span class="token punctuation">.</span>ETA <span class="token operator">*</span> <span class="token number">1.5</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> day <span class="token operator">></span> <span class="token number">18</span> <span class="token operator">and</span> flag<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>            paras<span class="token punctuation">.</span>THETA <span class="token operator">=</span> <span class="token number">0.05</span>        <span class="token keyword">if</span> day <span class="token operator">></span> <span class="token number">24</span> <span class="token operator">and</span> flag<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>            paras<span class="token punctuation">.</span>THETA <span class="token operator">=</span> <span class="token number">0.05</span>        each_experiment <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>cal<span class="token punctuation">.</span>next_iter<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        append_experiment<span class="token punctuation">(</span>each_experiment<span class="token punctuation">)</span>        day <span class="token operator">+=</span> <span class="token number">1</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>states_each_experiment<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python">ex_4_data <span class="token operator">=</span> experiment_4_guard<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python">S_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>E_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>I_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>R_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span></code></pre><pre class=" language-python"><code class="language-python">Days <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">]</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> i<span class="token punctuation">,</span> D <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>Days<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>    ex_4_data_tmp <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    states <span class="token operator">=</span> ex_4_data_tmp<span class="token punctuation">[</span>D<span class="token number">-1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>    nx<span class="token punctuation">.</span>draw<span class="token punctuation">(</span>G<span class="token punctuation">,</span> node_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span>states<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> pos<span class="token operator">=</span>nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>G<span class="token punctuation">,</span> iterations<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>OrRd<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'day'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>D<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>S_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>E_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>I_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>R_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'infected data'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'S'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'R'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_35_0.png" alt="png"></p><pre class=" language-python"><code class="language-python">fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>labelsize<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>S_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>E_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>I_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>R_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'control 7 days, 19 days to relax'</span><span class="token punctuation">,</span>y <span class="token operator">=</span> <span class="token number">1.1</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'S'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'R'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_36_0.png" alt="png"></p><pre class=" language-python"><code class="language-python">ex_4_data <span class="token operator">=</span> experiment_4_guard<span class="token punctuation">(</span>flag<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>S_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>E_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>I_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>R_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>labelsize<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>S_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>E_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>I_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>R_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'control 7 days, 25 days to relax'</span><span class="token punctuation">,</span>y <span class="token operator">=</span> <span class="token number">1.1</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'S'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'R'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_37_0.png" alt="png"></p><pre class=" language-python"><code class="language-python">ex_4_data <span class="token operator">=</span> experiment_4_guard<span class="token punctuation">(</span>flag<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>S_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>E_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">></span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>I_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>R_number_list <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>ex_4_data<span class="token operator">==</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">1000</span>fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>labelsize<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>S_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>E_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>I_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>R_number_list<span class="token punctuation">,</span> <span class="token string">'*-'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'control 7 days, 50 days to relax'</span><span class="token punctuation">,</span>y <span class="token operator">=</span> <span class="token number">1.1</span><span class="token punctuation">,</span>fontsize <span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'S'</span><span class="token punctuation">,</span> <span class="token string">'E'</span><span class="token punctuation">,</span> <span class="token string">'I'</span><span class="token punctuation">,</span> <span class="token string">'R'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_38_0.png" alt="png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 复杂网络&amp;社交网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
            <tag> 复杂网络 </tag>
            
            <tag> COVID-19 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>复杂网络--理论理解</title>
      <link href="/2020/04/10/conplex-network-introduction/"/>
      <url>/2020/04/10/conplex-network-introduction/</url>
      
        <content type="html"><![CDATA[<h1 id="复杂网络"><a href="#复杂网络" class="headerlink" title="复杂网络"></a>复杂网络</h1><p> <strong>2020.04.16</strong>  <strong>晚记</strong></p><p>   经过几次项目经历及相关论文的阅读，逐渐对复杂网络的的基本原理有了一定的理解，在此笔记将会汇总一些有关复杂网络、社交网络、社会网络等的一些知识点。</p><p><strong>摘要：</strong> 随着近几年关于复杂网络（Complex network）理论及其应用研究的不断深入，已有大量关于复杂网络的文章发表在Science，Nature，RL，NAS等国际一流的刊物上，侧面反映了复杂网络已经成为物理界的一个新兴的研究热点。</p><p><img src="clip_image001.png" alt="img"></p><p><strong>1、发展历史：</strong></p><p>国内学者对国外复杂网络理论研究的介绍最早始于汪小帆(2002)发表在国外杂志上的一篇文章**[3]**，文中回顾了近年来国外复杂网络研究所取得的重要成果，其中包括平均路径长度、聚集系数、度分布等网络度量，Internet、www和科学合作网络等现实系统，规则网络、随机网络、小世界网络、无标度网络等网络模型，以及复杂网络上的同步等。</p><p>而在国内刊物上对国外复杂网络理论研究的介绍可追溯到朱涵(2003) <strong>[4]**在《物理》杂志上发表的“网络‘建筑学”，文章</strong>以小世界、集团化和无标度等概念为中心**，介绍了复杂网络的研究进展。</p><p>之后，吴金闪等**[5]**从统计物理学的角度总结了复杂网络的主要研究结果，对无向网络、有向网络和加权网络等三种不同网络统计性质研究的现状分别作了综述，对规则网络、完全随机网络、小世界网络和无标度网络等网络机制模型进行了总结，并对网络演化的统计规律、网络上的动力学性质的研究进行了概括。</p><p>周涛等(2005)<strong>围绕小世界效应和无标度特性等复杂网络的统计特征及复杂网络上的物理过程等问题</strong>，概述了复杂网络的研究进展。</p><p>刘涛等**[6]<strong>从平均路径长度、聚集系数、度分布等复杂网络的统计性质，小世界网络和无标度网络等网络模型等层面</strong>简述了复杂网络领域的相关研究**。</p><p>史定华**[7]<strong>从对网络节点度和度分布的理解入手，</strong>对网络分类、网络的演化机理和模型及结构涌现等方面取得的进展进行了总结**。</p><p>遗憾的是，目前而言，科学家们还没有给出复杂网络精确严格的定义，从这十几年的研究来看，之所以称其为复杂网络，致少包含以下几层意思：首先，它是<strong>大量真实复杂系统的拓扑抽象</strong>；其次，它至少<strong>在感觉上比规则网络和随机网络复杂</strong>，因为我们可以很容易地生成规则和随机网络，但就目前而言，还<strong>没有一种简单方法能够生成完全符合真实统计特征的网络</strong>；最后，由于复杂网络是大量复杂系统得以存在的拓扑基础，此对它的研究被认为有助于理解<strong>“复杂系统之所以复杂”</strong>这一至关重要的问题。</p><p><strong>2. 复杂网络的统计特征</strong></p><p><strong>2.1平均路径长度L</strong></p><p>在网络中，两点之间的距离为连接两点的最短路径上所包含的边的数目。网络的平均路径长度指网络中所有节点对的平均距离，它表明网络中节点间的分离程度，反映了网络的全局特性。不同的网络结构可赋予L不同的含义。如在疾病传播模型中L可定义为疾病传播时间，通网络模型中L可定义为站点之间的距离等。</p><p><strong>2.2聚集系数C</strong></p><p>在网络中，节点的聚集系数是指与该节点相邻的所有节点之间连边的数目占这些相邻节点之间最大可能连边数目的比例。而网络的聚集系数则是指网络中所有节点聚集系数的平均值，它表明网络中节点的聚集情况即网络的聚集性，也就是说同一个节点的两个相邻节点仍然是相邻节点的概率有多大，它反映了网络的局部特性。</p><p><strong>2.3度及度分布</strong></p><p>在网络中，点的度是指与该节点相邻的节点的数目，即连接该节点的边的数目。而网络的度<k>指网络中所有节点度的平均值。度分布P(k)指网络中一个任意选择的节点，它的度恰好为k的概率。</k></p><p><strong>2.4介数</strong></p><p>包括节点介数和边介数。节点介数指网络中所有最短路径中经过该节点的数量比例，边介数则指网络中所有最短路径中经过该边的数量比例。介数反映了相应的节点或边在整个网络中的作用和影响力。</p><p><strong>2.5小世界效应</strong></p><p>复杂网络的小世界效应是指尽管网络的规模很大(网络节点数目N很大)，但是两个节点之间的距离比我们想象的要小得多。也就是网络的平均路径长度L随网络的规模呈对数增长，即L～In N。大量的实证研究表明，真实网络几乎都具有小世界效应。</p><p><strong>2.6无标度特性</strong></p><p>对于随机网络和规则网络，度分布区间非常狭窄，大多数节点都集中在节点度均值<k>的附近，说明节点具有同质性，因此<k>可以被看作是节点度的一个特征标度。而在节点度服从幂律分布的网络中，大多数节点的度都很小，而少数节点的度很大，说明节点具有异质性，这时特征标度消失。这种节点度的幂律分布为网络的无标度特性。</k></k></p><p><strong>3. 各种网络模型</strong></p><p><strong>3.1 规则网络</strong></p><p>最简单的网络模型为规则网络，它是指系统中各元素之间的关系可以用一些规则的结构表示，也就是说网络中任意两个节点之间的联系遵循既定的规则，通常每个节点的近邻数目都相同。常见的具有规则拓扑结构的网络包括全局耦合网络（也称为完全图）、最近邻耦合网络和星型耦合网络。</p><p><img src="clip_image002.png" alt="2"></p><p><strong>3.2 随机网络</strong></p><p>从某种意义上讲，规则网络和随机网络是两个极端，而复杂网络处于两者之间。节点不是按照确定的规则连线，如按纯粹的随机方式连线，所得的网络称为随机网络。如果节点按照某种自组织原则方式连线，将演化成各种不同网络。</p><p><img src="clip_image003.png" alt="3"></p><p><strong>3.3 小世界网络</strong></p><p>规则的最近邻耦合网络具有高聚类特性，但并不是小世界网络。另一方面，ER随机网络虽然具有小的平均路径长度但却没有高聚类特性。因此，这两类网络模型都不能再现真实网络的一些重要特征，毕竟大部分实际网络既不是完全规则的，也不是完全随机的。作为从完全规则网络向完全随机网络的过渡，Watts和Strogtz于1998年引入了一个小世界网络模型，称为WS小世界模型。</p><p><img src="clip_image004.png" alt="4"></p><p><strong>3.4 无标度网络</strong></p><p>很多网络（包括Internet和新陈代谢网络等）都不同程度拥有如下共同特性：大部分节点只有少数几个链接，而某些节点却拥有与其他节点的大量链接，表现在度分布上就是具有幂律形式，即P(k)~k—γ。这些具有大量链接的节点称为“集散节点”，所拥有的链接数可能高达几百、几千甚至几百万。包含这种集散节点的网络，由于网络节点的度没有明显的特征长度，故称为无标度网络。</p><p><img src="clip_image005.png" alt="5"></p><p><strong>3.5 自相似网络</strong></p><p>自相似是相似中的一种特殊情况，它是指系统的部分和整体之间具有某种相似性，这种相似性不是两个无关事物间的偶然近似，而是在系统中必然出现并始终保持的。这种自相似是层次复杂网络共有的拓扑性质，而自相似又是分型的一个基本特征，所以复杂系统与各层次子系统之间的自相似性，可以利用分形加以描述。</p><p><img src="clip_image006.png" alt="6"></p><p><strong>4. 复杂网络主要研究内容及应用</strong></p><p><strong>4.1 主要研究内容</strong></p><p><strong>复杂网络模型：</strong></p><ul><li>典型的复杂网络：随机网、小世界网、无标度网等；</li><li>实际网络及其分类。</li></ul><p><strong>网络的统计量及与网络结构的相关性：</strong></p><ul><li>度分布的定义和意义，聚集性、连通性的统计量及其实际意义等。</li></ul><p><strong>复杂网络性质与结构的关系：</strong></p><ul><li>同步性、鲁棒性和稳定性与网络结构的关系。</li></ul><p><strong>复杂网络的动力学：</strong></p><ul><li>信息传播动力学、网络演化动力学、网络混沌动力学。</li></ul><p><strong>复杂网络的复杂结构：</strong></p><ul><li>社团结构、层次结构、节点分类结构等。</li></ul><p><strong>网络控制：</strong></p><ul><li>关键节点控制、主参数控制和控制的稳定性和有效性。</li></ul><p><strong>复杂网络的一些应用：</strong></p><p><strong>社会网络：</strong></p><p><img src="clip_image007.png" alt="7"></p><p>朋友关系网作为一种典型的社会网络，受到了复杂网络领域诸多学者的关注。顾名思义，朋友关系网是根据人们之间的朋友关系所建立的网络，以人为节点，两人之间若有朋友关系则连接一条边。一些学者之前对朋友关系网的研究也获得了许多成果。**[34]**</p><p><img src="clip_image008.png" alt="8"></p><p>引文网络是体现知识生产、传播过程的一个重要方面。随着知识量的迅速增长，引文网络已经形成了一个超大规模的网络系统。然而，科学计量学领域中关于大型引文网络的研究还非常少，关于引文网络中知识生产和传播过程的研究更是少有涉及。</p><p>本文立足于科学学引文网络，整合复杂网络理论和社会网络分析方法，从宏观、微观和中观三个层面对科学学的引文网络进行研究，探讨网络的结构及其对知识的流动传播产生的影响。 对从SCI中下载的数据进行了权威控制并对其进行纠错，力图使研究最接近于真实情况。在此基础上对科学学引文网络的整体结构进行了研究，发现科学学引文网络同时具有复杂网络的“无标度”、“小世界”和“高集聚”的特性。科学学引文网络的整体结构适宜于知识快速流动，但是知识传播的路径还有待于进一步的优化。**[35]**</p><p><strong>交通运输网络：</strong></p><p><img src="clip_image009.png" alt="9"></p><p>在城市道路交通网络中，于恶劣天气、交通事件等可能造成一个或少数关键路段或路口失效(如堵塞)，些失效路段或路口会通过路段、路口间的相互关联引起其它路段或路口失效，成连锁效应，终导致整个网络或局部崩溃，就是级联失效。**[36]**</p><p><img src="clip_image010.png"></p><p>基于整个航空运输网络研究航班延误及其产生的次生衍生突发事件链式效应。以航班延误为中心，讨航班延误及其波及的发生发展过程，立基于阶段细分的航班延误波及模型；</p><p>根据导致航班延误的原因以及次生衍生事件链式效应规律，理由航班延误及其波及导致的下游航班或下游机场航班延误等一系列次生衍生事件链，建航班延误次生衍生事件链式网络；</p><p>通过建立航空运输网络结构，拟航班延误及其次生衍生事件链式效应的传播扩散过程，精确预测航班延误引发的次生衍生事件，量分析航班延误波及效应的影响程度。有助于民航应急管理部门有针对性地预防和管控航班延误可能发生的次生衍生事件，而有效地缓解由航班延误波及引发的次生衍生事件的后果与影响，低航班延误的损失。**[37]**</p><p><img src="clip_image011.png"></p><p>随着城市化进程的加速，人们出行日益增加，城市的交通拥堵问题越来越严重。公共交通是解决城市拥堵问题最为有效的途径，而城市公共交通网络容量是城市公共交通的一项重要研究。大量的研究如，如何定义城市公共交通网络容量；如何确定影响因素以及计算容量的大小。**[38]**</p><p><strong>5. 复杂网络研究相关著作及论文</strong></p><p><strong>[1]</strong> 谢逢洁. 复杂网络上的博弈[M]. 清华大学出版社, 2016.</p><p><strong>[2]</strong> 蒋忠元, 梁满贵. 复杂网络传输容量分析与优化[M]. 北京交通大学出版社, 2016.</p><p><strong>[3]</strong> 孙玺菁, 司守奎. 复杂网络算法与应用[M]. 国防工业出版社, 2015.</p><p><strong>[4]</strong> 李凤华, 熊金波. 复杂网络环境下访问控制技术[M]. 人民邮电出版社, 2015.</p><p><strong>[5]</strong> 苏厚胜, 汪小帆. 复杂网络化系统的牵制控制:英文版[M]. 上海交通大学出版社, 2014.</p><p><strong>[6]</strong> 张子柯. 大数据下复杂网络的机遇与挑战[M]. 科学出版社, 2014.</p><p><strong>[7]</strong> 傅新楚, MichaelSmall, 陈关荣,等. 复杂网络传播动力学:模型、方法与稳定性分析[M]. 高等教育出版社, 2014.</p><p><strong>[8]</strong> 陆再珍. 基于复杂网络理论的城市轨道交通系统[M]. 2013.</p><p><strong>[9]</strong> 郭进利. 复杂网络和人类行为动力学演化模型[M]. 科学出版社, 2013.</p><p><strong>[10]</strong> 何铮. 复杂网络在管理领域的应用研究[M]. 电子科技大学出版社, 2013.</p><p><strong>[11]</strong> 陈关荣, 汪小帆, 李翔. 复杂网络引论[M]. 高等教育出版社, 2012.</p><p><strong>[12]</strong> 郭世泽. 复杂网络基础理论[M]. 科学出版社, 2012.</p><p><strong>[13]</strong> 王维红. 金融危机沿国际贸易网络跨国传播研究:基于复杂网络理论[M]. 企业管理出版社, 2012.</p><p><strong>[14]</strong> 刘颖. 复杂网络视角下的知识传播[M]. 中国人民大学出版社, 2012.</p><p><strong>[15]</strong> 温磊. 基于复杂网络的供应链建模与仿真研究[M]. 河北大学出版社, 2012.</p><p><strong>[16]</strong> 刘健. 复杂网络社团结构的动力学方法研究[M]. 北京大学, 2011.</p><p><strong>[17]</strong> 李岸巍. 细胞自动机及其在复杂网络中的应用[M]. 人民邮电出版社, 2011.</p><p><strong>[18]</strong> 谭利. 复杂网络模型及应用研究[M]. 中南大学出版社, 2010.</p><p><strong>[19]</strong> 吴建军. 城市交通系统复杂性:复杂网络方法及其应用[M]. 科学出版社, 2010.</p><p><strong>[20]</strong> 谭玲玲. 中国煤炭需求复杂网络结构建模研究[M]. 经济管理出版社, 2009.</p><p><strong>[21]</strong> 汪小帆. 复杂网络理论及其应用[M]. 清华大学出版社, 2006.</p><p><strong>[22]</strong> 郭雷, 许晓鸣. 复杂网络[M]. 上海科技教育出版社, 2006.</p><p><strong>[23]</strong> Hofman J M, Sharma A, Watts D J. Prediction and explanation in social systems.[J]. Science, 2017, 355.</p><p><strong>[24]</strong> Newman, Barabasi, Watts. The Structure and Dynamics of Networks. Princeton University Press, 2006.</p><p><strong>[25]</strong> S.Boccaletti, et al. Complex Networks: Structure and dynamics, Phys. Rep. 424 (2006) 175-308.</p><p><strong>[26]</strong> E. Ben-Naim, et al. Complex Networks, Springer, 2004.</p><p><strong>[27]</strong> S. N. Dorogovtesev, J.Mendes. Evolving of Networks, Oxford Un. Press, 2003.</p><p><strong>[28]</strong> Ebel H, Mielsch L I, Bornholdt S. Scale-free topology of e-mail networks[J]. Phys Rev E Stat Nonlin Soft Matter Phys, 2002, 66(3 Pt 2A):035103.</p><p><strong>[29]</strong> Albert R, Barabási A. Statistical mechanics of complex networks[J]. Review of Modern Physics, 2002, 74(1):47-97.</p><p><strong>[30]</strong> Barabási A, Albert R. Emergence of Scaling in Random Networks[J]. Science, 1999, 286(5439):509-512.</p><p><strong>[31]</strong> Watts D J, Strogatz S H. Collective dynamics of ‘small-world’ networks.[J]. Nature, 1998, 393(6684):440.</p><p><strong>[32]</strong> 刘锋, 任勇, 山秀明. 互联网络数据包传输的一种简单元胞自动机模型[J]. 物理学报, 2002, 51(6):1175-1180.</p><p><strong>[33]</strong> 王光增, 曹一家, 包哲静,等. 一种新型电力网络局域世界演化模型[J]. 物理学报, 2009, 58(6):3597-3602.</p><p><strong>[34]</strong> 张恺, 马忠军, 李科赞. 朋友关系网络的实证统计研究[J]. 电子科技大学学报, 2014(3):336-341.</p><p><strong>[35]</strong> 张美平. 科学引文网络分析及其应用研究[D]. 电子科技大学, 2015.</p><p><strong>[36]</strong> 王正武, 王杰, 黄中祥. 控制城市道路交通网络级联失效的关闭策略[J]. 系统工程, 2016(2):103-108.</p><p><strong>[37]</strong> 贾萌. 基于航空网络的航班延误次生衍生事件链式效应研究[D]. 南京航空航天大学, 2015.</p><p><strong>[38]</strong> 刘岩, 邵岩, 王利杰,等. 城市公共交通网络容量研究[J]. 大连交通大学学报, 2015, 36(s1).</p><p><strong>[39]</strong> 韩博平. 生态网络分析的研究进展[J]. 生态学杂志, 1993(6):41-45.</p><p><strong>[40]</strong> 韩跃, 冀俊忠, 杨翠翠. 基于多标签传播机制的蛋白质相互作用网络功能模块检测[J]. 模式识别与人工智能, 2016, 29(6):548-557.</p><p><strong>[41]</strong> 赵国振. 基于自组织神经网的复杂网络社区发现研究[D]. 吉林大学, 2015.</p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 复杂网络&amp;社交网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 复杂网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树</title>
      <link href="/2020/04/10/jue-ce-shu/"/>
      <url>/2020/04/10/jue-ce-shu/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>colors <span class="token keyword">import</span> ListedColormap<span class="token keyword">def</span> <span class="token function">plot_decision_regions</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> classifiers<span class="token punctuation">,</span> test_idx<span class="token operator">=</span>None<span class="token punctuation">,</span> resolution<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># setup marker generator and color map</span>    markers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'^'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span>    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'lightgreen'</span><span class="token punctuation">,</span> <span class="token string">'gray'</span><span class="token punctuation">,</span> <span class="token string">'cyan'</span><span class="token punctuation">)</span>    cmap <span class="token operator">=</span> ListedColormap<span class="token punctuation">(</span>colors<span class="token punctuation">[</span><span class="token punctuation">:</span> len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    x1_min<span class="token punctuation">,</span> x1_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>    x2_min<span class="token punctuation">,</span> x2_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>    xx1<span class="token punctuation">,</span> xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x1_min<span class="token punctuation">,</span> x1_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">,</span>                           np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x2_min<span class="token punctuation">,</span> x2_max<span class="token punctuation">,</span>resolution<span class="token punctuation">)</span><span class="token punctuation">)</span>    Z <span class="token operator">=</span> classifiers<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>xx1<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx1<span class="token punctuation">,</span> xx2<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx1<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>xx2<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true">## plot all samples</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> c <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x <span class="token operator">=</span> X<span class="token punctuation">[</span>y <span class="token operator">==</span> c<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">[</span>y<span class="token operator">==</span>c<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    alpha <span class="token operator">=</span> <span class="token number">0.8</span><span class="token punctuation">,</span> c <span class="token operator">=</span> cmap<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">,</span>                    marker <span class="token operator">=</span> markers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span>label <span class="token operator">=</span> c<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># highlight test samples</span>    <span class="token keyword">if</span> test_idx<span class="token punctuation">:</span>        X_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> X<span class="token punctuation">[</span>test_idx<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>test_idx<span class="token punctuation">]</span>           plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'cyan'</span><span class="token punctuation">,</span>                 alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span>                 s<span class="token operator">=</span><span class="token number">55</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'test set'</span><span class="token punctuation">)</span>       <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaleriris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>y <span class="token operator">=</span> iris<span class="token punctuation">.</span>target  <span class="token comment" spellcheck="true">##0,1,2</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>         X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>sc <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>sc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_train_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># standardize by mean &amp; std 是否需要标准化？</span>X_test_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 利用sklearn拟合决策树分类模型</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plttree <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span> max_depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>X_combined <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">)</span><span class="token punctuation">)</span>y_combined <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span>plot_decision_regions<span class="token punctuation">(</span>X_combined<span class="token punctuation">,</span> y_combined<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> test_idx<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">105</span><span class="token punctuation">,</span><span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'petal length [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'petal width [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> export_graphviz<span class="token keyword">import</span> pydotplus<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>externals<span class="token punctuation">.</span>six <span class="token keyword">import</span> StringIO<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>display <span class="token keyword">import</span> Image dot_data <span class="token operator">=</span> StringIO<span class="token punctuation">(</span><span class="token punctuation">)</span>  export_graphviz<span class="token punctuation">(</span>tree<span class="token punctuation">,</span> out_file<span class="token operator">=</span>dot_data<span class="token punctuation">,</span>                  feature_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'petal length'</span><span class="token punctuation">,</span> <span class="token string">'petal width'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  class_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Setosa'</span><span class="token punctuation">,</span><span class="token string">'Versicolor'</span><span class="token punctuation">,</span><span class="token string">'Virginica'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  filled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> rounded<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                  special_characters<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  graph <span class="token operator">=</span> pydotplus<span class="token punctuation">.</span>graph_from_dot_data<span class="token punctuation">(</span>dot_data<span class="token punctuation">.</span>getvalue<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  Image<span class="token punctuation">(</span>graph<span class="token punctuation">.</span>create_png<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\Anaconda3\lib\site-packages\sklearn\externals\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).  "(https://pypi.org/project/six/).", DeprecationWarning)</code></pre><p><img src="output_1_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex9_4 利用sklearn构建随机森林分类器</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier<span class="token comment" spellcheck="true"># from 10 decision trees, n_jobs 值使用 cpu 个数</span>forest <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span>                                n_estimators<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>                                 random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                                n_jobs<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>forest<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>plot_decision_regions<span class="token punctuation">(</span>X_combined<span class="token punctuation">,</span> y_combined<span class="token punctuation">,</span>                       classifiers<span class="token operator">=</span>forest<span class="token punctuation">,</span> test_idx<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">105</span><span class="token punctuation">,</span><span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'petal length [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'petal width [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.</code></pre><p><img src="output_2_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file"</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestRegressor<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error<span class="token punctuation">,</span>r2_score<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_modeldiabetes_X <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"diabetes_X.csv"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values  <span class="token comment" spellcheck="true">##442*10</span>diabetes_y <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"diabetes_y.csv"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 输入特征上拆分训练集和测试集</span>diabetes_X_train<span class="token punctuation">,</span> diabetes_X_test<span class="token punctuation">,</span> diabetes_y_train<span class="token punctuation">,</span> diabetes_y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python">forest <span class="token operator">=</span> RandomForestRegressor<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> criterion<span class="token operator">=</span><span class="token string">'mse'</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span>None<span class="token punctuation">,</span> n_jobs<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>forest<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>diabetes_X_train<span class="token punctuation">,</span> diabetes_y_train<span class="token punctuation">)</span>diabetes_y_pred <span class="token operator">=</span> forest<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>diabetes_X_test<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RF Mean squared error: %.2f'</span>      <span class="token operator">%</span> mean_squared_error<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'RF Coefficient of determination: %.2f'</span>      <span class="token operator">%</span> r2_score<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>RF Mean squared error: 0.04RF Coefficient of determination: 0.94</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#生成线性回归模型对象</span>regr <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 训练模型</span>regr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>diabetes_X_train<span class="token punctuation">,</span>diabetes_y_train<span class="token punctuation">)</span><span class="token comment" spellcheck="true">##测试集上预测</span>diabetes_y_pred <span class="token operator">=</span> regr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>diabetes_X_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># The mean squared error</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'LR Mean squared error: %.2f'</span>      <span class="token operator">%</span> mean_squared_error<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># The coefficient of determination: 1 is perfect prediction</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'LR Coefficient of determination: %.2f'</span>      <span class="token operator">%</span> r2_score<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>LR Mean squared error: 0.05LR Coefficient of determination: 0.92</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># #生成弹性网络</span>eNet <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>ElasticNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 训练模型</span>eNet<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>diabetes_X_train<span class="token punctuation">,</span>diabetes_y_train<span class="token punctuation">)</span><span class="token comment" spellcheck="true">##测试集上预测</span>diabetes_y_pred <span class="token operator">=</span> eNet<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>diabetes_X_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># The mean squared error</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'eNet Mean squared error: %.2f'</span>      <span class="token operator">%</span> mean_squared_error<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># The coefficient of determination: 1 is perfect prediction</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'eNet Coefficient of determination: %.2f'</span>      <span class="token operator">%</span> r2_score<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>eNet Mean squared error: 0.16eNet Coefficient of determination: 0.73</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> scipy<span class="token punctuation">.</span>special <span class="token keyword">import</span> comb<span class="token keyword">import</span> math<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true"># emsemble error rate</span><span class="token keyword">def</span> <span class="token function">ensemble_error</span><span class="token punctuation">(</span>n_classifier<span class="token punctuation">,</span> error<span class="token punctuation">)</span><span class="token punctuation">:</span>    k_start <span class="token operator">=</span> int<span class="token punctuation">(</span>math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>n_classifier <span class="token operator">/</span> <span class="token number">2.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    probs <span class="token operator">=</span> <span class="token punctuation">[</span>comb<span class="token punctuation">(</span>n_classifier<span class="token punctuation">,</span> k<span class="token punctuation">)</span> <span class="token operator">*</span> error<span class="token operator">**</span>k <span class="token operator">*</span>                <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>error<span class="token punctuation">)</span><span class="token operator">**</span><span class="token punctuation">(</span>n_classifier <span class="token operator">-</span> k<span class="token punctuation">)</span>              <span class="token keyword">for</span> k <span class="token keyword">in</span> range<span class="token punctuation">(</span>k_start<span class="token punctuation">,</span> n_classifier <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> sum<span class="token punctuation">(</span>probs<span class="token punctuation">)</span>error_range <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.01</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>ens_errors <span class="token operator">=</span> <span class="token punctuation">[</span>ensemble_error<span class="token punctuation">(</span>n_classifier<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span> error<span class="token operator">=</span>error<span class="token punctuation">)</span>               <span class="token keyword">for</span> error <span class="token keyword">in</span> error_range<span class="token punctuation">]</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>error_range<span class="token punctuation">,</span> ens_errors<span class="token punctuation">,</span>          label<span class="token operator">=</span><span class="token string">'Ensemble error'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>error_range<span class="token punctuation">,</span> error_range<span class="token punctuation">,</span>          linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Base error'</span><span class="token punctuation">,</span>linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Base error'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Base/Ensemble error'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_7_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#在训练集上测试</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder<span class="token comment" spellcheck="true"># load iris data</span>iris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>X<span class="token punctuation">,</span> y <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">:</span><span class="token punctuation">]</span>st <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> st<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>y <span class="token operator">=</span> le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 50% train, 50% test</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> \    train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stratify<span class="token operator">=</span>y<span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_scoreclf1 <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>penalty<span class="token operator">=</span><span class="token string">'l2'</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>clf2 <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'minkowski'</span><span class="token punctuation">)</span>clf3 <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>clf_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Logistic Regression'</span><span class="token punctuation">,</span> <span class="token string">'KNN'</span><span class="token punctuation">,</span> <span class="token string">'Decision Tree'</span><span class="token punctuation">]</span>all_clf <span class="token operator">=</span> <span class="token punctuation">[</span>clf1<span class="token punctuation">,</span> clf2<span class="token punctuation">,</span> clf3<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># print('10-fold cross validation:\n')</span><span class="token keyword">for</span> clf_label<span class="token punctuation">,</span> clf <span class="token keyword">in</span> zip<span class="token punctuation">(</span>clf_labels<span class="token punctuation">,</span> all_clf<span class="token punctuation">)</span><span class="token punctuation">:</span>    scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>estimator<span class="token operator">=</span>clf<span class="token punctuation">,</span> X<span class="token operator">=</span>X_train<span class="token punctuation">,</span> y<span class="token operator">=</span>y_train<span class="token punctuation">,</span>                    cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'roc_auc'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ROC AUC: %0.2f (+/- %0.2f) [%s]"</span>         <span class="token operator">%</span> <span class="token punctuation">(</span>scores<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> scores<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> clf_label<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 加入投票机制</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> VotingClassifiermv_clf <span class="token operator">=</span> VotingClassifier<span class="token punctuation">(</span>    estimators<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'c1'</span><span class="token punctuation">,</span> clf1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'c2'</span><span class="token punctuation">,</span> clf2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'c3'</span><span class="token punctuation">,</span> clf3<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> voting<span class="token operator">=</span><span class="token string">'soft'</span><span class="token punctuation">)</span>clf_labels <span class="token operator">+=</span> <span class="token punctuation">[</span><span class="token string">'Majority Voting'</span><span class="token punctuation">]</span>all_clf <span class="token operator">+=</span> <span class="token punctuation">[</span>mv_clf<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># print('10-fold cross validation:\n')</span><span class="token keyword">for</span> clf_label<span class="token punctuation">,</span> clf <span class="token keyword">in</span> zip<span class="token punctuation">(</span>clf_labels<span class="token punctuation">,</span> all_clf<span class="token punctuation">)</span><span class="token punctuation">:</span>    scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>estimator<span class="token operator">=</span>clf<span class="token punctuation">,</span> X<span class="token operator">=</span>X_train<span class="token punctuation">,</span> y<span class="token operator">=</span>y_train<span class="token punctuation">,</span>                    cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> scoring<span class="token operator">=</span><span class="token string">'roc_auc'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"ROC AUC: %0.2f (+/- %0.2f) [%s]"</span>         <span class="token operator">%</span> <span class="token punctuation">(</span>scores<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> scores<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> clf_label<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)ROC AUC: 0.89 (+/- 0.17) [Logistic Regression]ROC AUC: 0.88 (+/- 0.15) [KNN]ROC AUC: 0.89 (+/- 0.16) [Decision Tree]ROC AUC: 0.89 (+/- 0.17) [Logistic Regression]ROC AUC: 0.88 (+/- 0.15) [KNN]ROC AUC: 0.89 (+/- 0.16) [Decision Tree]ROC AUC: 0.96 (+/- 0.13) [Majority Voting]C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#在测试集上测试</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_curve<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> auccolors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'black'</span><span class="token punctuation">,</span> <span class="token string">'orange'</span><span class="token punctuation">,</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'green'</span><span class="token punctuation">]</span>linestyles <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">':'</span><span class="token punctuation">,</span> <span class="token string">'--'</span><span class="token punctuation">,</span> <span class="token string">'-.'</span><span class="token punctuation">,</span> <span class="token string">'-'</span><span class="token punctuation">]</span><span class="token keyword">for</span> clf<span class="token punctuation">,</span> label<span class="token punctuation">,</span> clr<span class="token punctuation">,</span> ls \        <span class="token keyword">in</span> zip<span class="token punctuation">(</span>all_clf<span class="token punctuation">,</span> clf_labels<span class="token punctuation">,</span> colors<span class="token punctuation">,</span> linestyles<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># assuming the label of the positive class is 1</span>    y_pred <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>    fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span> thresholds <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y_test<span class="token punctuation">,</span>                                      y_score<span class="token operator">=</span>y_pred<span class="token punctuation">)</span>    roc_auc <span class="token operator">=</span> auc<span class="token punctuation">(</span>x<span class="token operator">=</span>fpr<span class="token punctuation">,</span> y<span class="token operator">=</span>tpr<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr<span class="token punctuation">,</span> tpr<span class="token punctuation">,</span>              color<span class="token operator">=</span>clr<span class="token punctuation">,</span>              linestyle<span class="token operator">=</span>ls<span class="token punctuation">,</span>              label<span class="token operator">=</span><span class="token string">'%s (auc = %0.2f)'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>label<span class="token punctuation">,</span> roc_auc<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span>          color<span class="token operator">=</span><span class="token string">'gray'</span><span class="token punctuation">,</span>          linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">1.1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'False Positive Rate'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'True Positive Rate'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)</code></pre><p><img src="output_9_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex10_5 在wine.data数据集上构建套袋模型</span><span class="token keyword">import</span> os<span class="token keyword">import</span> math<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file"</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"wine.data"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">)</span>df<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Class label'</span><span class="token punctuation">,</span> <span class="token string">'Alcohol'</span><span class="token punctuation">,</span> <span class="token string">'Malic acid'</span><span class="token punctuation">,</span> <span class="token string">'Ash'</span><span class="token punctuation">,</span> <span class="token string">'Alcalinity of ash'</span><span class="token punctuation">,</span> <span class="token string">'Magnesium'</span><span class="token punctuation">,</span> <span class="token string">'Total phenols'</span><span class="token punctuation">,</span> <span class="token string">'Flavanoids'</span><span class="token punctuation">,</span> <span class="token string">'Nonflavanoid phenols'</span><span class="token punctuation">,</span> <span class="token string">'Proanthocyanins'</span><span class="token punctuation">,</span> <span class="token string">'Color intensity'</span><span class="token punctuation">,</span> <span class="token string">'Hue'</span><span class="token punctuation">,</span> <span class="token string">'OD280/OD315 of diluted wines'</span><span class="token punctuation">,</span> <span class="token string">'Proline'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># df.head()</span><span class="token comment" spellcheck="true"># only consider Wine classes 2 and 3</span>df <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Class label'</span><span class="token punctuation">]</span> <span class="token operator">!=</span> <span class="token number">1</span><span class="token punctuation">]</span>y <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'Class label'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesX <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Alcohol'</span><span class="token punctuation">,</span> <span class="token string">'Hue'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token comment" spellcheck="true">## 拆分训练集和测试集</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token comment" spellcheck="true"># 转换 label</span>le <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>y <span class="token operator">=</span> le<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 60% train, 40% test</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> \    train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.40</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stratify<span class="token operator">=</span>y<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># sklearn 提供的 BaggingClassifier， 其实功能已经超过 Bagging 了</span><span class="token comment" spellcheck="true"># 它既能对 samples 采样，也能对 features 采样</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> BaggingClassifier<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifiertree <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span>                              random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                              max_depth<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 用 Decision Tree 作 base </span>bag <span class="token operator">=</span> BaggingClassifier<span class="token punctuation">(</span>base_estimator<span class="token operator">=</span>tree<span class="token punctuation">,</span>                        n_estimators<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>                         max_samples<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 子采样 samples 的比例</span>                        max_features<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 子采样 features 的比例</span>                        bootstrap<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>   <span class="token comment" spellcheck="true"># 采样 samples 时是否使用 bootstrap</span>                        bootstrap_features<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment" spellcheck="true"># 采样 features 时是否使用 bootstrap</span>                        random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 计算决策树好套袋分类器在训练集和测试集上的预测准确率，比较性能</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_scoretree <span class="token operator">=</span> tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>y_train_pred <span class="token operator">=</span> tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>y_test_pred <span class="token operator">=</span> tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>tree_train <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>tree_test <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_test_pred<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Decision tree train/test accuracies %.3f/%.3f'</span>      <span class="token operator">%</span> <span class="token punctuation">(</span>tree_train<span class="token punctuation">,</span> tree_test<span class="token punctuation">)</span><span class="token punctuation">)</span>bag <span class="token operator">=</span> bag<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>y_train_pred <span class="token operator">=</span> bag<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>y_test_pred <span class="token operator">=</span> bag<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>bag_train <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span> bag_test <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_test_pred<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Bagging train/test accuracies %.3f/%.3f'</span>      <span class="token operator">%</span> <span class="token punctuation">(</span>bag_train<span class="token punctuation">,</span> bag_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Decision tree train/test accuracies 1.000/0.875Bagging train/test accuracies 1.000/0.896</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#使用sklearn实现Adaboost</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> AdaBoostClassifiertree <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'entropy'</span><span class="token punctuation">,</span>                               random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>                              max_depth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>ada <span class="token operator">=</span> AdaBoostClassifier<span class="token punctuation">(</span>base_estimator<span class="token operator">=</span>tree<span class="token punctuation">,</span>                         n_estimators<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>                          learning_rate<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>                         random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>tree <span class="token operator">=</span> tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>y_train_pred <span class="token operator">=</span> tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>y_test_pred <span class="token operator">=</span> tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>tree_train <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span>tree_test <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_test_pred<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Decision tree train/test accuracies %.3f/%.3f'</span>      <span class="token operator">%</span> <span class="token punctuation">(</span>tree_train<span class="token punctuation">,</span> tree_test<span class="token punctuation">)</span><span class="token punctuation">)</span>ada <span class="token operator">=</span> ada<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>y_train_pred <span class="token operator">=</span> ada<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>y_test_pred <span class="token operator">=</span> ada<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>ada_train <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_train_pred<span class="token punctuation">)</span> ada_test <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_test_pred<span class="token punctuation">)</span> <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'AdaBoost train/test accuracies %.3f/%.3f'</span>      <span class="token operator">%</span> <span class="token punctuation">(</span>ada_train<span class="token punctuation">,</span> ada_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Decision tree train/test accuracies 0.887/0.896AdaBoost train/test accuracies 1.000/0.938</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聚类模型及文本聚类分析</title>
      <link href="/2020/04/01/ju-lei-mo-xing-ji-wen-ben-ju-lei-fen-xi/"/>
      <url>/2020/04/01/ju-lei-mo-xing-ji-wen-ben-ju-lei-fen-xi/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##ex16_1 导入依赖包,更新停用词表</span><span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\python projects\《数据挖掘》'</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##contractions.py放至此目录</span><span class="token keyword">from</span> contractions <span class="token keyword">import</span> CONTRACTION_MAP   <span class="token keyword">import</span> re<span class="token keyword">import</span> nltk<span class="token keyword">import</span> string<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>stem <span class="token keyword">import</span> WordNetLemmatizer<span class="token keyword">import</span> unicodedatastopword_list <span class="token operator">=</span> nltk<span class="token punctuation">.</span>corpus<span class="token punctuation">.</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">'english'</span><span class="token punctuation">)</span>stopword_list <span class="token operator">=</span> stopword_list <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token string">'mr'</span><span class="token punctuation">,</span> <span class="token string">'mrs'</span><span class="token punctuation">,</span> <span class="token string">'come'</span><span class="token punctuation">,</span> <span class="token string">'go'</span><span class="token punctuation">,</span> <span class="token string">'get'</span><span class="token punctuation">,</span>                                 <span class="token string">'tell'</span><span class="token punctuation">,</span> <span class="token string">'listen'</span><span class="token punctuation">,</span> <span class="token string">'one'</span><span class="token punctuation">,</span> <span class="token string">'two'</span><span class="token punctuation">,</span> <span class="token string">'three'</span><span class="token punctuation">,</span>                                 <span class="token string">'four'</span><span class="token punctuation">,</span> <span class="token string">'five'</span><span class="token punctuation">,</span> <span class="token string">'six'</span><span class="token punctuation">,</span> <span class="token string">'seven'</span><span class="token punctuation">,</span> <span class="token string">'eight'</span><span class="token punctuation">,</span>                                 <span class="token string">'nine'</span><span class="token punctuation">,</span> <span class="token string">'zero'</span><span class="token punctuation">,</span> <span class="token string">'join'</span><span class="token punctuation">,</span> <span class="token string">'find'</span><span class="token punctuation">,</span> <span class="token string">'make'</span><span class="token punctuation">,</span>                                 <span class="token string">'say'</span><span class="token punctuation">,</span> <span class="token string">'ask'</span><span class="token punctuation">,</span> <span class="token string">'tell'</span><span class="token punctuation">,</span> <span class="token string">'see'</span><span class="token punctuation">,</span> <span class="token string">'try'</span><span class="token punctuation">,</span> <span class="token string">'back'</span><span class="token punctuation">,</span>                                 <span class="token string">'also'</span><span class="token punctuation">]</span>wnl <span class="token operator">=</span> WordNetLemmatizer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 定义分词函数</span><span class="token keyword">def</span> <span class="token function">tokenize_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokens <span class="token operator">=</span> nltk<span class="token punctuation">.</span>word_tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>     tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span>    <span class="token keyword">return</span> tokens</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_2 扩展缩写词</span><span class="token keyword">def</span> <span class="token function">expand_contractions</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> contraction_mapping<span class="token punctuation">)</span><span class="token punctuation">:</span>    contractions_pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'(&amp;#123;&amp;#125;)'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">'|'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>contraction_mapping<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                       flags<span class="token operator">=</span>re<span class="token punctuation">.</span>IGNORECASE<span class="token operator">|</span>re<span class="token punctuation">.</span>DOTALL<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">expand_match</span><span class="token punctuation">(</span>contraction<span class="token punctuation">)</span><span class="token punctuation">:</span>        match <span class="token operator">=</span> contraction<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        first_char <span class="token operator">=</span> match<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        expanded_contraction <span class="token operator">=</span> contraction_mapping<span class="token punctuation">.</span>get<span class="token punctuation">(</span>match<span class="token punctuation">)</span>\                                <span class="token keyword">if</span> contraction_mapping<span class="token punctuation">.</span>get<span class="token punctuation">(</span>match<span class="token punctuation">)</span>\                                <span class="token keyword">else</span> contraction_mapping<span class="token punctuation">.</span>get<span class="token punctuation">(</span>match<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                               expanded_contraction <span class="token operator">=</span> first_char<span class="token operator">+</span>expanded_contraction<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> expanded_contraction    expanded_text <span class="token operator">=</span> contractions_pattern<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>expand_match<span class="token punctuation">,</span> text<span class="token punctuation">)</span>    expanded_text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">"'"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> expanded_text<span class="token punctuation">)</span>    <span class="token keyword">return</span> expanded_text</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_3 词形还原</span><span class="token keyword">from</span> pattern<span class="token punctuation">.</span>en <span class="token keyword">import</span> tag<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> wordnet <span class="token keyword">as</span> wn<span class="token comment" spellcheck="true"># Annotate text tokens with POS tags</span><span class="token keyword">def</span> <span class="token function">pos_tag_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">penn_to_wn_tags</span><span class="token punctuation">(</span>pos_tag<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'J'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>ADJ        <span class="token keyword">elif</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'V'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>VERB        <span class="token keyword">elif</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'N'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>NOUN        <span class="token keyword">elif</span> pos_tag<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'R'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> wn<span class="token punctuation">.</span>ADV        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> None    tagged_text <span class="token operator">=</span> tag<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    tagged_lower_text <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>word<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> penn_to_wn_tags<span class="token punctuation">(</span>pos_tag<span class="token punctuation">)</span><span class="token punctuation">)</span>                         <span class="token keyword">for</span> word<span class="token punctuation">,</span> pos_tag <span class="token keyword">in</span>                         tagged_text<span class="token punctuation">]</span>    <span class="token keyword">return</span> tagged_lower_text<span class="token comment" spellcheck="true"># lemmatize text based on POS tags    </span><span class="token keyword">def</span> <span class="token function">lemmatize_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    pos_tagged_text <span class="token operator">=</span> pos_tag_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    lemmatized_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>wnl<span class="token punctuation">.</span>lemmatize<span class="token punctuation">(</span>word<span class="token punctuation">,</span> pos_tag<span class="token punctuation">)</span> <span class="token keyword">if</span> pos_tag                         <span class="token keyword">else</span> word                                              <span class="token keyword">for</span> word<span class="token punctuation">,</span> pos_tag <span class="token keyword">in</span> pos_tagged_text<span class="token punctuation">]</span>    lemmatized_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>lemmatized_tokens<span class="token punctuation">)</span>    <span class="token keyword">return</span> lemmatized_text</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_4去除特殊字符、停用词、提取文本标识</span><span class="token keyword">def</span> <span class="token function">remove_special_characters</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokens <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    pattern <span class="token operator">=</span> re<span class="token punctuation">.</span>compile<span class="token punctuation">(</span><span class="token string">'[&amp;#123;&amp;#125;]'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>re<span class="token punctuation">.</span>escape<span class="token punctuation">(</span>string<span class="token punctuation">.</span>punctuation<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    filtered_tokens <span class="token operator">=</span> filter<span class="token punctuation">(</span>None<span class="token punctuation">,</span> <span class="token punctuation">[</span>pattern<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">,</span> token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span><span class="token punctuation">)</span>    filtered_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>filtered_tokens<span class="token punctuation">)</span>    <span class="token keyword">return</span> filtered_text<span class="token keyword">def</span> <span class="token function">remove_stopwords</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    tokens <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    filtered_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> token <span class="token operator">not</span> <span class="token keyword">in</span> stopword_list<span class="token punctuation">]</span>    filtered_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>filtered_tokens<span class="token punctuation">)</span>        <span class="token keyword">return</span> filtered_text<span class="token keyword">def</span> <span class="token function">keep_text_characters</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>    filtered_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    tokens <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>        <span class="token keyword">if</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token string">'[a-zA-Z]'</span><span class="token punctuation">,</span> token<span class="token punctuation">)</span><span class="token punctuation">:</span>            filtered_tokens<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token<span class="token punctuation">)</span>    filtered_text <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>filtered_tokens<span class="token punctuation">)</span>    <span class="token keyword">return</span> filtered_text</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_5 将所有预处理步骤集成</span><span class="token keyword">def</span> <span class="token function">normalize_corpus</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> lemmatize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                    only_text_chars<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                    tokenize<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    normalized_corpus <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> text <span class="token keyword">in</span> corpus<span class="token punctuation">:</span>        text <span class="token operator">=</span> expand_contractions<span class="token punctuation">(</span>text<span class="token punctuation">,</span> CONTRACTION_MAP<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##扩展缩写词</span>        <span class="token keyword">if</span> lemmatize<span class="token punctuation">:</span>            text <span class="token operator">=</span> lemmatize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##词性还原</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            text <span class="token operator">=</span> text<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>            text <span class="token operator">=</span> remove_special_characters<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##去除标点</span>            text <span class="token operator">=</span> remove_stopwords<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##去除停用词</span>        <span class="token keyword">if</span> only_text_chars<span class="token punctuation">:</span>            text <span class="token operator">=</span> keep_text_characters<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##仅保留英文字符</span>        <span class="token keyword">if</span> tokenize<span class="token punctuation">:</span>            text <span class="token operator">=</span> tokenize_text<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##分词</span>            normalized_corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            normalized_corpus<span class="token punctuation">.</span>append<span class="token punctuation">(</span>text<span class="token punctuation">)</span>    <span class="token keyword">return</span> normalized_corpus</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment" spellcheck="true">## 包含9个文档的原始语料库</span>toy_corpus <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'The sky is blue'</span><span class="token punctuation">,</span><span class="token string">'The sky is blue and beautiful'</span><span class="token punctuation">,</span><span class="token string">'Look at the bright blue sky!'</span><span class="token punctuation">,</span><span class="token string">'Python is a great Programming language'</span><span class="token punctuation">,</span><span class="token string">'Python and Java are popular Programming languages'</span><span class="token punctuation">,</span><span class="token string">'Among Programming languages, both Python and Java are the most used in Analytics'</span><span class="token punctuation">,</span><span class="token string">'The fox is quicker than the lazy dog'</span><span class="token punctuation">,</span><span class="token string">'The dog is smarter than the fox'</span><span class="token punctuation">,</span><span class="token string">'The dog, fox and cat are good friends'</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">## 包含3个文档的查询语料，对每个文档，从toy_corpus中找到最相似的一个</span>query_docs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'The fox is definitely smarter than the dog'</span><span class="token punctuation">,</span>            <span class="token string">'Java is a static typed programming language unlike Python'</span><span class="token punctuation">,</span>            <span class="token string">'I love to relax under the beautiful blue sky!'</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">## 规范化原始语料库</span>norm_corpus <span class="token operator">=</span> normalize_corpus<span class="token punctuation">(</span>toy_corpus<span class="token punctuation">,</span> lemmatize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##需运行ex16_1~ ex16_5</span><span class="token keyword">print</span><span class="token punctuation">(</span>norm_corpus<span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 规范化查询语料</span>norm_query_docs <span class="token operator">=</span> normalize_corpus<span class="token punctuation">(</span>query_docs<span class="token punctuation">,</span>lemmatize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>norm_query_docs<span class="token punctuation">)</span></code></pre><pre><code>['the sky be blue', 'the sky be blue and beautiful', 'look at the bright blue sky !', 'python be a great programming language', 'python and java be popular programming language', 'among programming language , both python and java be the most use in analytics', 'the fox be quick than the lazy dog', 'the dog be smarter than the fox', 'the dog , fox and cat be good friend']['the fox be definitely smarter than the dog', 'java be a static type programming language unlike python', 'i love to relax under the beautiful blue sky !']</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_7 定义文档向量提取函数</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer<span class="token punctuation">,</span> TfidfVectorizer<span class="token comment" spellcheck="true">## 定义如下函数，从文档中提取特征，可提取布尔特征、频率特征、tfidf特征</span><span class="token keyword">def</span> <span class="token function">build_feature_matrix</span><span class="token punctuation">(</span>documents<span class="token punctuation">,</span> feature_type<span class="token operator">=</span><span class="token string">'frequency'</span><span class="token punctuation">,</span>                         ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> min_df<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> max_df<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    feature_type <span class="token operator">=</span> feature_type<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token keyword">if</span> feature_type <span class="token operator">==</span> <span class="token string">'binary'</span><span class="token punctuation">:</span>        vectorizer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> min_df<span class="token operator">=</span>min_df<span class="token punctuation">,</span>                                     max_df<span class="token operator">=</span>max_df<span class="token punctuation">,</span> ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">)</span>    <span class="token keyword">elif</span> feature_type <span class="token operator">==</span> <span class="token string">'frequency'</span><span class="token punctuation">:</span>        vectorizer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>binary<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> min_df<span class="token operator">=</span>min_df<span class="token punctuation">,</span>                                     max_df<span class="token operator">=</span>max_df<span class="token punctuation">,</span> ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">)</span>    <span class="token keyword">elif</span> feature_type <span class="token operator">==</span> <span class="token string">'tfidf'</span><span class="token punctuation">:</span>        vectorizer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>min_df<span class="token operator">=</span>min_df<span class="token punctuation">,</span> max_df<span class="token operator">=</span>max_df<span class="token punctuation">,</span>                                      ngram_range<span class="token operator">=</span>ngram_range<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">raise</span> Exception<span class="token punctuation">(</span><span class="token string">"Wrong feature type entered. Possible values: 'binary', 'frequency', 'tfidf'"</span><span class="token punctuation">)</span>    feature_matrix <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>float<span class="token punctuation">)</span>    <span class="token keyword">return</span> vectorizer<span class="token punctuation">,</span> feature_matrix</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_8 将原始语料转换为特征向量，即提取原始语料的tfidf特征</span>tfidf_vectorizer<span class="token punctuation">,</span> tfidf_features <span class="token operator">=</span> build_feature_matrix<span class="token punctuation">(</span>norm_corpus<span class="token punctuation">,</span> feature_type<span class="token operator">=</span><span class="token string">'tfidf'</span><span class="token punctuation">,</span>\                                                       ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>min_df<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> max_df<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'norm_corpus tfidf feaures:'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>tfidf_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">## 压缩矩阵转化为稀疏矩阵</span><span class="token comment" spellcheck="true">## 将查询语料转换为特征向量，即提取查询语料的tfidf特征</span>query_docs_tfidf <span class="token operator">=</span> tfidf_vectorizer<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>norm_query_docs<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'norm_query_docs tfidf features:'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>query_docs_tfidf<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>norm_corpus tfidf feaures:[[0.         0.         0.         0.         0.34846291 0.  0.6041072  0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.6041072  0.         0.         0.3855938  0.        ] [0.         0.         0.38110217 0.         0.24880016 0.58734555  0.43132846 0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.43132846 0.         0.         0.27531137 0.        ] [0.         0.         0.         0.48233752 0.         0.  0.3542138  0.         0.48233752 0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.48233752 0.         0.         0.         0.  0.         0.3542138  0.         0.         0.22609008 0.        ] [0.         0.         0.         0.         0.25327071 0.  0.         0.         0.         0.         0.         0.  0.         0.         0.59789923 0.         0.         0.43907875  0.         0.         0.         0.         0.43907875 0.43907875  0.         0.         0.         0.         0.         0.        ] [0.         0.         0.32723247 0.         0.21363167 0.  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.42595911 0.37035915  0.         0.         0.         0.50432286 0.37035915 0.37035915  0.         0.         0.         0.         0.         0.        ] [0.33056385 0.33056385 0.21448805 0.         0.14002718 0.  0.         0.33056385 0.         0.         0.         0.  0.         0.         0.         0.33056385 0.27919949 0.2427559  0.         0.         0.33056385 0.         0.2427559  0.2427559  0.         0.         0.         0.         0.15494795 0.33056385] [0.         0.         0.         0.         0.1923419  0.  0.         0.         0.         0.         0.33345049 0.33345049  0.         0.         0.         0.         0.         0.  0.45406386 0.         0.         0.         0.         0.  0.45406386 0.         0.         0.38350956 0.42567426 0.        ] [0.         0.         0.         0.         0.21587942 0.  0.         0.         0.         0.         0.37425594 0.37425594  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.         0.50962916 0.4304409  0.47776543 0.        ] [0.         0.         0.29315989 0.         0.1913876  0.  0.         0.         0.         0.45181101 0.33179607 0.33179607  0.45181101 0.45181101 0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.21178113 0.        ]]norm_query_docs tfidf features:[[0.         0.         0.         0.         0.21587942 0.  0.         0.         0.         0.         0.37425594 0.37425594  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.         0.50962916 0.4304409  0.47776543 0.        ] [0.         0.         0.         0.         0.26733688 0.  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.53304166 0.46346434  0.         0.         0.         0.         0.46346434 0.46346434  0.         0.         0.         0.         0.         0.        ] [0.         0.         0.         0.         0.         0.65962261  0.4844065  0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.         0.         0.         0.         0.  0.         0.4844065  0.         0.         0.30919039 0.        ]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_9 利用余弦相似度，返回与查询文档相似度最高的n个文档</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>pairwise <span class="token keyword">import</span> cosine_similarity<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Document Similarity Analysis using Cosine Similarity'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token keyword">for</span> index<span class="token punctuation">,</span> doc <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>query_docs<span class="token punctuation">)</span><span class="token punctuation">:</span>    doc_tfidf <span class="token operator">=</span> query_docs_tfidf<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    similarity <span class="token operator">=</span>  cosine_similarity<span class="token punctuation">(</span>doc_tfidf<span class="token punctuation">,</span> tfidf_features<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>similarity<span class="token punctuation">)</span>    top_docs <span class="token operator">=</span> similarity<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#     print(top_docs)</span>    top_docs_with_score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> round<span class="token punctuation">(</span>similarity<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> top_docs<span class="token punctuation">]</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Document'</span><span class="token punctuation">,</span>index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">':'</span><span class="token punctuation">,</span> doc<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Top'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>top_docs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'similar docs:'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">40</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> doc_index<span class="token punctuation">,</span> sim_score <span class="token keyword">in</span> top_docs_with_score<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Doc num:&amp;#123;&amp;#125; Similarity Score:&amp;#123;&amp;#125;\nDoc:&amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>doc_index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> sim_score<span class="token punctuation">,</span> toy_corpus<span class="token punctuation">[</span>doc_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">40</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>Document Similarity Analysis using Cosine Similarity============================================================---------------------------------------------------------------------------NameError                                 Traceback (most recent call last)&lt;ipython-input-1-9b1754fc3fc1&gt; in &lt;module&gt;      5 print('='*60)      6 ----&gt; 7 for index, doc in enumerate(query_docs):      8     doc_tfidf = query_docs_tfidf[index]      9     similarity =  cosine_similarity(doc_tfidf, tfidf_features)[0]NameError: name 'query_docs' is not defined</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_10 基于HB距离，从语料库中获取n个与查询文档最相似的文档</span><span class="token keyword">def</span> <span class="token function">compute_HB_distance</span><span class="token punctuation">(</span>doc_features<span class="token punctuation">,</span> corpus_features<span class="token punctuation">,</span> top_n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># get document vectors</span>    doc_features <span class="token operator">=</span> doc_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    corpus_features <span class="token operator">=</span> corpus_features<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># compute hb distances</span>    distance <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">0.5</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>np<span class="token punctuation">.</span>square<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>doc_features<span class="token punctuation">)</span> <span class="token operator">-</span>    np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>corpus_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># get docs with lowest distance scores</span>    top_docs <span class="token operator">=</span> distance<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span>top_n<span class="token punctuation">]</span> <span class="token comment" spellcheck="true">##分布之间的距离度量，距离从小到大排序，得分为0表示完全相似</span>    top_docs_with_score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>index<span class="token punctuation">,</span> round<span class="token punctuation">(</span>distance<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                            <span class="token keyword">for</span> index <span class="token keyword">in</span> top_docs<span class="token punctuation">]</span>    <span class="token keyword">return</span> top_docs_with_score<span class="token comment" spellcheck="true">## 距离计算</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Document Similarity Analysis using Hellinger-Bhattacharya distance'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token keyword">for</span> index<span class="token punctuation">,</span> doc <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>query_docs<span class="token punctuation">)</span><span class="token punctuation">:</span>    doc_tfidf <span class="token operator">=</span> query_docs_tfidf<span class="token punctuation">[</span>index<span class="token punctuation">]</span>    top_similar_docs <span class="token operator">=</span> compute_HB_distance<span class="token punctuation">(</span>doc_tfidf<span class="token punctuation">,</span> tfidf_features<span class="token punctuation">,</span>top_n<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Document'</span><span class="token punctuation">,</span>index<span class="token operator">+</span><span class="token number">1</span> <span class="token punctuation">,</span><span class="token string">':'</span><span class="token punctuation">,</span> doc<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Top'</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>top_similar_docs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'similar docs:'</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">40</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> doc_index<span class="token punctuation">,</span> sim_score <span class="token keyword">in</span> top_similar_docs<span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Doc num: &amp;#123;&amp;#125; Distance Score: &amp;#123;&amp;#125;\nDoc: &amp;#123;&amp;#125;'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>doc_index<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>                                                        sim_score<span class="token punctuation">,</span>                                                        toy_corpus<span class="token punctuation">[</span>doc_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">40</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>Document Similarity Analysis using Hellinger-Bhattacharya distance============================================================Document 1 : The fox is definitely smarter than the dogTop 2 similar docs:----------------------------------------Doc num: 8 Distance Score: 0.0Doc: The dog is smarter than the fox----------------------------------------Doc num: 7 Distance Score: 0.844Doc: The fox is quicker than the lazy dog----------------------------------------Document 2 : Java is a static typed programming language unlike PythonTop 2 similar docs:----------------------------------------Doc num: 5 Distance Score: 0.654Doc: Python and Java are popular Programming languages----------------------------------------Doc num: 4 Distance Score: 0.752Doc: Python is a great Programming language----------------------------------------Document 3 : I love to relax under the beautiful blue sky!Top 2 similar docs:----------------------------------------Doc num: 2 Distance Score: 0.564Doc: The sky is blue and beautiful----------------------------------------Doc num: 1 Distance Score: 0.716Doc: The sky is blue----------------------------------------</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:/Users/43790/data file'</span><span class="token punctuation">)</span>movie_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'movie_data.csv'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># print(movie_data.head())</span>movie_titles <span class="token operator">=</span> movie_data<span class="token punctuation">[</span><span class="token string">'Title'</span><span class="token punctuation">]</span>movie_synopses <span class="token operator">=</span> movie_data<span class="token punctuation">[</span><span class="token string">'Synopsis'</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Movie'</span><span class="token punctuation">,</span>movie_titles<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Movie Synopsis'</span><span class="token punctuation">,</span> movie_synopses<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre><code>Movie The GodfatherMovie Synopsis In late summer 1945, guests are gathered for the wedding reception of Don Vito Corleone's daughter Connie (Talia Shire) and Carlo Rizzi (Gianni Russo). Vito (Marlon Brando), the head of the Corleone Mafia family, is known to friends and associates as "Godfather." He and Tom Hagen (Robert Duvall), the Corleone family lawyer, are hearing requests for favors because, according to Italian tradition, "no Sicilian can refuse a request on his daughter's wedding day." One of the men who asks the Don for a favor is Amerigo Bonasera, a successful mortician and acquaintance of the Don, whose daughter was brutally beaten by two young men because she refused their advances; the men received minimal punishment. The Don is disappointed in Bonasera, who'd avoided most contact with the Don due to Corleone's nefarious business dealings. The Don's wife is godmother to Bonasera's shamed daughter, a relationship the Don uses to extract new loyalty from the undertaker. The Don agrees to have his men punish </code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##文本规范化</span>norm_movie_synopses <span class="token operator">=</span> normalize_corpus<span class="token punctuation">(</span>movie_synopses<span class="token punctuation">,</span> lemmatize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> only_text_chars<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># ## 提取tf-idf的一元分词和二元分词特征</span><span class="token comment" spellcheck="true">## 每个特征至少在25%的文档中出现，至多在85%的文档中出现</span>vectorizer<span class="token punctuation">,</span> feature_matrix <span class="token operator">=</span> build_feature_matrix<span class="token punctuation">(</span>norm_movie_synopses<span class="token punctuation">,</span> feature_type<span class="token operator">=</span><span class="token string">'tfidf'</span><span class="token punctuation">,</span> min_df<span class="token operator">=</span><span class="token number">0.24</span><span class="token punctuation">,</span>max_df<span class="token operator">=</span><span class="token number">0.85</span><span class="token punctuation">,</span> ngram_range<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>feature_matrix<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## csr_matrix</span><span class="token keyword">print</span><span class="token punctuation">(</span>feature_matrix<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">## 原始矩阵，100*307 提取了307个特征</span><span class="token comment" spellcheck="true"># get feature name</span>feature_names <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>feature_names<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>feature_names<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>  (0, 245)    0.019212339105980844  (0, 244)    0.014058482888994648  (0, 255)    0.016463737903316754  (0, 225)    0.01490542083529085  (0, 573)    0.01951226744996299  (0, 240)    0.018642322542943058  (0, 484)    0.018922579806325012  (0, 237)    0.0176050414984765  (0, 352)    0.017852800316818917  (0, 551)    0.015649114100419182  (0, 254)    0.01490542083529085  (0, 421)    0.020145674272034193  (0, 78)    0.020145674272034193  (0, 514)    0.016046724430450594  (0, 20)    0.06043702281610258  (0, 61)    0.01690214583228003  (0, 72)    0.01951226744996299  (0, 589)    0.01545703678681262  (0, 26)    0.018642322542943058  (0, 503)    0.012717937620422403  (0, 481)    0.0166801312525218  (0, 77)    0.037845159612650024  (0, 499)    0.01951226744996299  (0, 230)    0.020145674272034193  (0, 469)    0.01810795600342744  :    :  (99, 63)    0.051305686365200345  (99, 160)    0.21182600776815871  (99, 319)    0.0567693710391131  (99, 580)    0.055621265504843094  (99, 124)    0.05977730538786259  (99, 22)    0.06648706707638062  (99, 351)    0.06436507985396142  (99, 516)    0.05505820594286933  (99, 182)    0.2458274974654437  (99, 423)    0.0799330814115007  (99, 498)    0.052345724418053845  (99, 283)    0.4036156953269401  (99, 302)    0.05977730538786259  (99, 178)    0.0819424991551479  (99, 564)    0.08513904186902038  (99, 600)    0.09500189264390897  (99, 412)    0.05505820594286933  (99, 406)    0.09232230995044544  (99, 606)    0.0761691422296135  (99, 57)    0.062340317698467464  (99, 137)    0.11955461077572518  (99, 111)    0.05450222907907284  (99, 345)    0.058549460380619964  (99, 290)    0.12208047277703582  (99, 176)    0.0799330814115007(100, 607)['able', 'able to', 'about', 'about his', 'about the', 'about to', 'accept', 'across', 'act', 'after the', 'again', 'against', 'agree', 'agree to', 'alive', 'all', 'all the', 'allow', 'alone', 'along']607</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_13 使用k-means算法聚类电影评论</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans<span class="token keyword">def</span> <span class="token function">k_means</span><span class="token punctuation">(</span>feature_matrix<span class="token punctuation">,</span> num_clusters<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    km <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span>num_clusters<span class="token punctuation">,</span> max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>    km<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>feature_matrix<span class="token punctuation">)</span>    clusters <span class="token operator">=</span> km<span class="token punctuation">.</span>labels_    <span class="token keyword">return</span> km<span class="token punctuation">,</span> clusters <span class="token comment" spellcheck="true">##clusters中得到为每个样本点分配的聚类标签</span><span class="token comment" spellcheck="true">##将100部电影简介聚类成5类</span>num_clusters <span class="token operator">=</span> <span class="token number">5</span>km_obj<span class="token punctuation">,</span> clusters <span class="token operator">=</span> k_means<span class="token punctuation">(</span>feature_matrix<span class="token operator">=</span>feature_matrix<span class="token punctuation">,</span> num_clusters<span class="token operator">=</span>num_clusters<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## 得到聚类对象和聚类标签</span>movie_data<span class="token punctuation">[</span><span class="token string">'Cluster'</span><span class="token punctuation">]</span><span class="token operator">=</span>clusters<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counterc <span class="token operator">=</span> Counter<span class="token punctuation">(</span>clusters<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>c<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##聚类类别统计</span></code></pre><pre><code>dict_items([(1, 24), (3, 33), (4, 12), (0, 27), (2, 4)])</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_14 从聚类模型中提取详细的聚类分析信息</span><span class="token keyword">def</span> <span class="token function">get_cluster_data</span><span class="token punctuation">(</span>clustering_obj<span class="token punctuation">,</span> movie_data<span class="token punctuation">,</span> feature_names<span class="token punctuation">,</span> num_clusters<span class="token punctuation">,</span> topn_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    cluster_details <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    <span class="token comment" spellcheck="true">##获取质心，得到按降序排序的分量索引</span>    ordered_centroids <span class="token operator">=</span> clustering_obj<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment" spellcheck="true">##5行307列</span>    <span class="token comment" spellcheck="true">## 获取每一个类的关键特征</span>    <span class="token keyword">for</span> cluster_num <span class="token keyword">in</span> range<span class="token punctuation">(</span>num_clusters<span class="token punctuation">)</span><span class="token punctuation">:</span>        cluster_details<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>        cluster_details<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'cluster_num'</span><span class="token punctuation">]</span> <span class="token operator">=</span> cluster_num        key_features <span class="token operator">=</span> <span class="token punctuation">[</span>feature_names<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> ordered_centroids<span class="token punctuation">[</span>cluster_num<span class="token punctuation">,</span><span class="token punctuation">:</span>topn_features<span class="token punctuation">]</span><span class="token punctuation">]</span>        cluster_details<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'key_features'</span><span class="token punctuation">]</span> <span class="token operator">=</span> key_features        <span class="token comment" spellcheck="true">## 获取每个聚类的电影标题</span>        movies <span class="token operator">=</span> movie_data<span class="token punctuation">[</span>movie_data<span class="token punctuation">[</span><span class="token string">'Cluster'</span><span class="token punctuation">]</span><span class="token operator">==</span>cluster_num<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'Title'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>        cluster_details<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'movies'</span><span class="token punctuation">]</span> <span class="token operator">=</span> movies    <span class="token keyword">return</span> cluster_details<span class="token comment" spellcheck="true">## 定义一个能清晰展示结果的函数</span><span class="token keyword">def</span> <span class="token function">print_cluster_data</span><span class="token punctuation">(</span>cluster_data<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true">##打印cluster_datails中的结果</span>    <span class="token keyword">for</span> cluster_num<span class="token punctuation">,</span> cluster_details <span class="token keyword">in</span> cluster_data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Cluster &amp;#123;&amp;#125; details'</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span>cluster_num<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">20</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'key features:'</span><span class="token punctuation">,</span> cluster_details<span class="token punctuation">[</span><span class="token string">'key_features'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Movie in this cluster:'</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>cluster_details<span class="token punctuation">[</span><span class="token string">'movies'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token operator">*</span><span class="token number">40</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_15 聚类可视化</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>manifold <span class="token keyword">import</span> MDS<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>pairwise <span class="token keyword">import</span> cosine_similarity<span class="token keyword">import</span> random<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>font_manager <span class="token keyword">import</span> FontProperties<span class="token keyword">def</span> <span class="token function">plot_clusters</span><span class="token punctuation">(</span>num_clusters<span class="token punctuation">,</span> feature_matrix<span class="token punctuation">,</span>                  cluster_data<span class="token punctuation">,</span> movie_data<span class="token punctuation">,</span>                  plot_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 为每个类产生随机颜色                  </span>    <span class="token keyword">def</span> <span class="token function">generate_random_color</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        color <span class="token operator">=</span> <span class="token string">'#%06x'</span> <span class="token operator">%</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0xFFFFFF</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> color    <span class="token comment" spellcheck="true"># 为每个类别样本设定显示形状    </span>    markers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">,</span> <span class="token string">'^'</span><span class="token punctuation">,</span> <span class="token string">'&lt;'</span><span class="token punctuation">,</span> <span class="token string">'>'</span><span class="token punctuation">,</span> <span class="token string">'8'</span><span class="token punctuation">,</span> <span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'p'</span><span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">,</span> <span class="token string">'H'</span><span class="token punctuation">,</span> <span class="token string">'D'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># 构建余弦相似度矩阵</span>    cosine_distance <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> cosine_similarity<span class="token punctuation">(</span>feature_matrix<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true"># 使用MDS进行特征降维</span>    mds <span class="token operator">=</span> MDS<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> dissimilarity<span class="token operator">=</span><span class="token string">"precomputed"</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 获取低维空间的坐标轴</span>    plot_positions <span class="token operator">=</span> mds<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>cosine_distance<span class="token punctuation">)</span>      x_pos<span class="token punctuation">,</span> y_pos <span class="token operator">=</span> plot_positions<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> plot_positions<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># build cluster plotting data</span>    cluster_color_map <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    cluster_name_map <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;&amp;#125;</span>    <span class="token keyword">for</span> cluster_num<span class="token punctuation">,</span> cluster_details <span class="token keyword">in</span> cluster_data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># assign cluster features to unique label</span>        cluster_color_map<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span> <span class="token operator">=</span> generate_random_color<span class="token punctuation">(</span><span class="token punctuation">)</span>        cluster_name_map<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">', '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>cluster_details<span class="token punctuation">[</span><span class="token string">'key_features'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># map each unique cluster label with its coordinates and movies</span>    cluster_plot_frame <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'x': x_pos,</span>                                       <span class="token string">'y'</span><span class="token punctuation">:</span> y_pos<span class="token punctuation">,</span>                                       <span class="token string">'label'</span><span class="token punctuation">:</span> movie_data<span class="token punctuation">[</span><span class="token string">'Cluster'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                       <span class="token string">'title'</span><span class="token punctuation">:</span> movie_data<span class="token punctuation">[</span><span class="token string">'Title'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>                                        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>    grouped_plot_frame <span class="token operator">=</span> cluster_plot_frame<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">'label'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># set plot figure size and axes</span>    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span>plot_size<span class="token punctuation">)</span>     ax<span class="token punctuation">.</span>margins<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot each cluster using co-ordinates and movie titles</span>    <span class="token keyword">for</span> cluster_num<span class="token punctuation">,</span> cluster_frame <span class="token keyword">in</span> grouped_plot_frame<span class="token punctuation">:</span>         marker <span class="token operator">=</span> markers<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span> <span class="token keyword">if</span> cluster_num <span class="token operator">&lt;</span> len<span class="token punctuation">(</span>markers<span class="token punctuation">)</span> \                  <span class="token keyword">else</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>markers<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>         ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>cluster_frame<span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cluster_frame<span class="token punctuation">[</span><span class="token string">'y'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                  marker<span class="token operator">=</span>marker<span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> ms<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span>                 label<span class="token operator">=</span>cluster_name_map<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span><span class="token punctuation">,</span>                  color<span class="token operator">=</span>cluster_color_map<span class="token punctuation">[</span>cluster_num<span class="token punctuation">]</span><span class="token punctuation">,</span> mec<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>         ax<span class="token punctuation">.</span>set_aspect<span class="token punctuation">(</span><span class="token string">'auto'</span><span class="token punctuation">)</span>         ax<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>axis<span class="token operator">=</span> <span class="token string">'x'</span><span class="token punctuation">,</span> which<span class="token operator">=</span><span class="token string">'both'</span><span class="token punctuation">,</span> bottom<span class="token operator">=</span><span class="token string">'off'</span><span class="token punctuation">,</span> top<span class="token operator">=</span><span class="token string">'off'</span><span class="token punctuation">,</span>                                labelbottom<span class="token operator">=</span><span class="token string">'off'</span><span class="token punctuation">)</span>         ax<span class="token punctuation">.</span>tick_params<span class="token punctuation">(</span>axis<span class="token operator">=</span> <span class="token string">'y'</span><span class="token punctuation">,</span> which<span class="token operator">=</span><span class="token string">'both'</span><span class="token punctuation">,</span> left<span class="token operator">=</span><span class="token string">'off'</span><span class="token punctuation">,</span> top<span class="token operator">=</span><span class="token string">'off'</span><span class="token punctuation">,</span>                                 labelleft<span class="token operator">=</span><span class="token string">'off'</span><span class="token punctuation">)</span>    fontP <span class="token operator">=</span> FontProperties<span class="token punctuation">(</span><span class="token punctuation">)</span>    fontP<span class="token punctuation">.</span>set_size<span class="token punctuation">(</span><span class="token string">'small'</span><span class="token punctuation">)</span>        ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper center'</span><span class="token punctuation">,</span> bbox_to_anchor<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span> fancybox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>               shadow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> ncol<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> numpoints<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> prop<span class="token operator">=</span>fontP<span class="token punctuation">)</span>     <span class="token comment" spellcheck="true">#add labels as the film titles</span>    <span class="token keyword">for</span> index <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>cluster_plot_frame<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        ax<span class="token punctuation">.</span>text<span class="token punctuation">(</span>cluster_plot_frame<span class="token punctuation">.</span>ix<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'x'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 cluster_plot_frame<span class="token punctuation">.</span>ix<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'y'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                 cluster_plot_frame<span class="token punctuation">.</span>ix<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>      <span class="token comment" spellcheck="true"># show the plot           </span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 在电影简介上显示</span>cluster_data <span class="token operator">=</span>  get_cluster_data<span class="token punctuation">(</span>clustering_obj<span class="token operator">=</span>km_obj<span class="token punctuation">,</span>                                 movie_data<span class="token operator">=</span>movie_data<span class="token punctuation">,</span>                                 feature_names<span class="token operator">=</span>feature_names<span class="token punctuation">,</span>                                 num_clusters<span class="token operator">=</span>num_clusters<span class="token punctuation">,</span>                                 topn_features<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>         print_cluster_data<span class="token punctuation">(</span>cluster_data<span class="token punctuation">)</span> plot_clusters<span class="token punctuation">(</span>num_clusters<span class="token operator">=</span>num_clusters<span class="token punctuation">,</span>               feature_matrix<span class="token operator">=</span>feature_matrix<span class="token punctuation">,</span>              cluster_data<span class="token operator">=</span>cluster_data<span class="token punctuation">,</span>               movie_data<span class="token operator">=</span>movie_data<span class="token punctuation">,</span>              plot_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Cluster 0 details--------------------key features: ['her', 'she', 'love', 'about', 'she be']Movie in this cluster:Casablanca,Gone with the Wind,The Wizard of Oz,Titanic,Psycho,Sunset Blvd.,Vertigo,The Sound of Music,West Side Story,The Silence of the Lambs,Singin' in the Rain,A Streetcar Named Desire,The Philadelphia Story,An American in Paris,My Fair Lady,The Apartment,The Exorcist,City Lights,It Happened One Night,Annie Hall,Out of Africa,Terms of Endearment,Tootsie,Nashville,The Graduate,Taxi Driver,Double Indemnity========================================Cluster 1 details--------------------key features: ['family', 'brother', 'father', 'train', 'find']Movie in this cluster:The Godfather,Raging Bull,The Godfather: Part II,Forrest Gump,E.T. the Extra-Terrestrial,Gandhi,Ben-Hur,Doctor Zhivago,The Good, the Bad and the Ugly,Butch Cassidy and the Sundance Kid,High Noon,The Pianist,Goodfellas,The French Connection,The King's Speech,Mr. Smith Goes to Washington,Rain Man,Giant,The Grapes of Wrath,The Green Mile,Mutiny on the Bounty,A Clockwork Orange,Rebel Without a Cause,Yankee Doodle Dandy========================================Cluster 2 details--------------------key features: ['of his', 'death', 'son', 'murder', 'about']Movie in this cluster:Amadeus,Gladiator,A Place in the Sun,Midnight Cowboy========================================Cluster 3 details--------------------key features: ['her', 'she', 'tell', 'will', 'go']Movie in this cluster:The Shawshank Redemption,One Flew Over the Cuckoo's Nest,Citizen Kane,On the Waterfront,Star Wars,2001: A Space Odyssey,Chinatown,It's a Wonderful Life,Some Like It Hot,The Lord of the Rings: The Return of the King,From Here to Eternity,Unforgiven,Raiders of the Lost Ark,Rocky,To Kill a Mockingbird,The Best Years of Our Lives,Jaws,Braveheart,The Deer Hunter,Good Will Hunting,Fargo,Shane,Close Encounters of the Third Kind,Network,American Graffiti,Pulp Fiction,The African Queen,Stagecoach,The Maltese Falcon,Wuthering Heights,Rear Window,The Third Man,North by Northwest========================================Cluster 4 details--------------------key features: ['soldier', 'kill', 'war', 'officer', 'men']Movie in this cluster:Schindler's List,Lawrence of Arabia,The Bridge on the River Kwai,12 Angry Men,Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb,Apocalypse Now,Saving Private Ryan,Patton,The Treasure of the Sierra Madre,Platoon,Dances with Wolves,All Quiet on the Western Front========================================C:\Users\43790\Anaconda3\lib\site-packages\ipykernel_launcher.py:60: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecatedC:\Users\43790\Anaconda3\lib\site-packages\ipykernel_launcher.py:61: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecatedC:\Users\43790\Anaconda3\lib\site-packages\ipykernel_launcher.py:62: FutureWarning: .ix is deprecated. Please use.loc for label based indexing or.iloc for positional indexingSee the documentation here:http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated</code></pre><p><img src="output_15_2.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex16_16</span>distortions <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    km <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span>i<span class="token punctuation">,</span> init<span class="token operator">=</span><span class="token string">'k-means++'</span><span class="token punctuation">,</span>max_iter<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>    km<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>feature_matrix<span class="token punctuation">)</span>    distortions<span class="token punctuation">.</span>append<span class="token punctuation">(</span>km<span class="token punctuation">.</span>inertia_<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">,</span> distortions<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Number of clusters'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Distortion'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_16_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分类模型</title>
      <link href="/2020/03/27/fen-lei-mo-xing/"/>
      <url>/2020/03/27/fen-lei-mo-xing/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">class</span> <span class="token class-name">Perceptron</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Perceptron classifier.    Parameter    ---------    eta: float        Learning rate(between 0.0 and 1.0)    n_iter: int        passes over the dataset    Attribute    ---------    w_: 1d array        Weights after fitting    errors_: list        Number of misclassifications in each epoch. 1个epoch相当于过了1遍训练集中的所有样本    """</span>            <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>eta<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>eta <span class="token operator">=</span> eta        self<span class="token punctuation">.</span>n_iter <span class="token operator">=</span> n_iter  <span class="token comment" spellcheck="true">## the number of epoch</span>    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Fitting training data.        Parameters        ----------        X: &amp;#123;array-like&amp;#125;, shape = [n_samples, n_features]        y: &amp;#123;array-like&amp;#125;, shape = [n_samples,], Target values        Return        self: object        """</span>        self<span class="token punctuation">.</span>w_ <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 权重初始值设为0</span>        self<span class="token punctuation">.</span>errors_ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>            errors <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">for</span> xi<span class="token punctuation">,</span>target <span class="token keyword">in</span> zip<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>                update <span class="token operator">=</span> self<span class="token punctuation">.</span>eta <span class="token operator">*</span> <span class="token punctuation">(</span>target <span class="token operator">-</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>xi<span class="token punctuation">)</span><span class="token punctuation">)</span>                self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> update <span class="token operator">*</span> xi                 self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> update                errors <span class="token operator">+=</span> int<span class="token punctuation">(</span>update <span class="token operator">!=</span> <span class="token number">0.0</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>errors_<span class="token punctuation">.</span>append<span class="token punctuation">(</span>errors<span class="token punctuation">)</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">net_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Calculate net input w*x"""</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""return class label"""</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>self<span class="token punctuation">.</span>net_input<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token operator">>=</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex1_2 载入鸢尾花数据集</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> os<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##数据读取</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"iris.csv"</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">## 花萼和花瓣</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##将数据可视化 ，选择setosa和versicolor两种</span><span class="token comment" spellcheck="true"># select setosa and versicolor</span>X <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesy <span class="token operator">=</span> df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>valuesy <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>y<span class="token operator">==</span><span class="token string">'setosa'</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## 标签转换为-1,1</span><span class="token comment" spellcheck="true">##plot data</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">50</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'setosa'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>marker<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'versicolor'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'petal length [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'sepal length [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_1_0.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">##ex1_3 拟合训练集X</span>ppn <span class="token operator">=</span> Perceptron<span class="token punctuation">(</span>eta<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>ppn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>ppn<span class="token punctuation">.</span>errors_<span class="token comment" spellcheck="true">##可视化观察是否收敛</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>ppn<span class="token punctuation">.</span>errors_<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ppn<span class="token punctuation">.</span>errors_<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epochs'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Number of misclassifications'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_2_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>colors <span class="token keyword">import</span> ListedColormap<span class="token comment" spellcheck="true"># Colormap object generated from a list of colors. 画决策边界</span><span class="token keyword">def</span> <span class="token function">plot_decision_regions</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> classifier<span class="token punctuation">,</span> resolution<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># setup marker generator and color map</span>    markers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'^'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span>    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'lightgreen'</span><span class="token punctuation">,</span> <span class="token string">'gray'</span><span class="token punctuation">,</span> <span class="token string">'cyan'</span><span class="token punctuation">)</span>    cmap <span class="token operator">=</span> ListedColormap<span class="token punctuation">(</span>colors<span class="token punctuation">[</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot the decision surface 确定横纵轴边界</span>    x1_min<span class="token punctuation">,</span> x1_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>  <span class="token comment" spellcheck="true"># 最小-1, 最大+1</span>    x2_min<span class="token punctuation">,</span> x2_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    <span class="token comment" spellcheck="true"># create a pair of grid arrays </span>    <span class="token comment" spellcheck="true"># flatten the grid arrays then predict</span>    xx1<span class="token punctuation">,</span> xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x1_min<span class="token punctuation">,</span> x1_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">,</span>                         np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x2_min<span class="token punctuation">,</span> x2_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">)</span>     Z <span class="token operator">=</span> classifier<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>xx1<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># maps the different decision regions to different colors </span>    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx1<span class="token punctuation">,</span> xx2<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx1<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>xx2<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot class samples</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> cl <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> cl<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> cl<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> c<span class="token operator">=</span>cmap<span class="token punctuation">(</span>idx<span class="token punctuation">)</span><span class="token punctuation">,</span>                    marker<span class="token operator">=</span>markers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>cl<span class="token punctuation">)</span>plot_decision_regions<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> classifier<span class="token operator">=</span>ppn<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'sepal length [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'petal length [cm]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' &amp; 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.</code></pre><p><img src="output_3_1.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#7_5</span><span class="token keyword">class</span> <span class="token class-name">AdalineGD</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Adaptive Linear Neuron Classifier    Parameters    ----------    eta: float        Learning rate(between 0.0 and 1.0)    n_iter: int        Passing over the training dataset    Attributes    ----------    w_: 1d-array        Weights after fitting    errors_: list        Number of misclssification in every epoch    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> eta<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>eta <span class="token operator">=</span> eta        self<span class="token punctuation">.</span>n_iter <span class="token operator">=</span> n_iter    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">""" Fit training data.        Parameters        ----------        X : &amp;#123;array-like&amp;#125;, shape = [n_samples, n_features]            Training vectors, where n_samples is the number of samples and            n_features is the number of features.        y : array-like, shape = [n_samples]            Target values.        Returns        -------        self : object        """</span>        self<span class="token punctuation">.</span>w_ <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>cost_ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true">## gradient descent</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>            output <span class="token operator">=</span> self<span class="token punctuation">.</span>net_input<span class="token punctuation">(</span>X<span class="token punctuation">)</span>            errors <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> output<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>eta <span class="token operator">*</span> X<span class="token punctuation">.</span>T<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>errors<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>eta <span class="token operator">*</span> errors<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>            cost <span class="token operator">=</span> <span class="token punctuation">(</span>errors<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2.0</span>            self<span class="token punctuation">.</span>cost_ <span class="token punctuation">.</span>append<span class="token punctuation">(</span>cost<span class="token punctuation">)</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">net_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""Calculate net input"""</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">activation</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>net_input<span class="token punctuation">(</span>X<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""return class label"""</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">>=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 测试两种 learning rate, 0.01 和 0.0001</span>fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>nrows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ncols<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>ada1 <span class="token operator">=</span> AdalineGD<span class="token punctuation">(</span>n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> eta<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>ada1<span class="token punctuation">.</span>cost_<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>log10<span class="token punctuation">(</span>ada1<span class="token punctuation">.</span>cost_<span class="token punctuation">)</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Epochs'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'log(Sum-squared-error)'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Adaline - Learning rate 0.01'</span><span class="token punctuation">)</span>ada2 <span class="token operator">=</span> AdalineGD<span class="token punctuation">(</span>n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> eta<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>ada2<span class="token punctuation">.</span>cost_<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> ada2<span class="token punctuation">.</span>cost_<span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Epochs'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Sum-squared-error'</span><span class="token punctuation">)</span>ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Adaline - Learning rate 0.0001'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># plt.savefig('./adaline_1.png', dpi=300)</span></code></pre><p><img src="output_4_0.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#7_10</span><span class="token comment" spellcheck="true">## ex7_11 LogisticRegression实现</span><span class="token keyword">class</span> <span class="token class-name">LogisticRegression</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""LogisticRegression classifier.    Parameters    ----------    eta: float        Learning rate(between 0.0 and 1.0)    n_iter: int        Passing over the training dataset.    Attributes    ----------    w_: 1d-array        Weight after fitting.    cost_: list        Cost in every epoch.    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> eta<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>eta <span class="token operator">=</span> eta        self<span class="token punctuation">.</span>n_iter <span class="token operator">=</span> n_iter    <span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>w_ <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>cost_ <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>n_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>            y_val <span class="token operator">=</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>X<span class="token punctuation">)</span>            errors <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> y_val<span class="token punctuation">)</span>            neg_grad <span class="token operator">=</span> X<span class="token punctuation">.</span>T<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>errors<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>eta <span class="token operator">*</span> neg_grad            self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>eta <span class="token operator">*</span> errors<span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span>            self<span class="token punctuation">.</span>cost_<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_logit_cost<span class="token punctuation">(</span>y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">_logit_cost</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> y<span class="token punctuation">,</span> y_val<span class="token punctuation">)</span><span class="token punctuation">:</span>        logit <span class="token operator">=</span> <span class="token operator">-</span>y<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_val<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_val<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> logit    <span class="token keyword">def</span> <span class="token function">_sigmoid</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">net_input</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w_<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">activation</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        z <span class="token operator">=</span> self<span class="token punctuation">.</span>net_input<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_sigmoid<span class="token punctuation">(</span>z<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">predict_proba</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>X<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token operator">></span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#7_11</span>y<span class="token punctuation">[</span>y<span class="token operator">==</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>X_std <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> X<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> X<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span>lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>n_iter<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> eta<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_std<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>len<span class="token punctuation">(</span>lr<span class="token punctuation">.</span>cost_<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>log10<span class="token punctuation">(</span>lr<span class="token punctuation">.</span>cost_<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epochs'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Cost'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Logistic Regression - Learning rate 0.02'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_6_0.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 1）导入</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npiris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment" spellcheck="true">##分别代表花瓣的长和宽</span>y <span class="token operator">=</span> iris<span class="token punctuation">.</span>target   <span class="token comment" spellcheck="true">## 已转换为整数标签</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>iris<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span> <span class="token comment" spellcheck="true">#0=Iris-Setosa, 1=Iris-Versicolor, 2=Iris-Virginica</span><span class="token comment" spellcheck="true">#拆分数据集</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token comment" spellcheck="true"># stratify=y, 使训练集和测试集的分类标签比例相同</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stratify<span class="token operator">=</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token comment" spellcheck="true">#标准化</span>sc <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>sc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_train_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_test_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span></code></pre><pre><code>[0 1 2]['setosa' 'versicolor' 'virginica'][50 50 50][35 35 35]</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> Perceptron<span class="token comment" spellcheck="true"># sklearn 中有封装好的 Perceptron 函数</span>ppn <span class="token operator">=</span> Perceptron<span class="token punctuation">(</span>n_iter_no_change<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">,</span> eta0<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>ppn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>y_pred <span class="token operator">=</span> ppn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_std<span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># predict</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Misclassified samples: %d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>y_test <span class="token operator">!=</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 错误个数</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Accuracy: %.2f'</span> <span class="token operator">%</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true"># 91% 的准确率</span></code></pre><pre><code>Misclassified samples: 8Accuracy: 0.82</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex8_3 重新定义画决策边界函数, 使得能区分训练数据和测试数据</span><span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>colors <span class="token keyword">import</span> ListedColormap<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token operator">%</span>matplotlib inline<span class="token comment" spellcheck="true"># 重新定义画决策边界函数, 使得能区分训练数据和测试数据</span><span class="token keyword">def</span> <span class="token function">plot_decision_regions</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> classifier<span class="token punctuation">,</span> test_idx<span class="token operator">=</span>None<span class="token punctuation">,</span> resolution<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># setup marker generator and color map</span>    markers <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'s'</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'o'</span><span class="token punctuation">,</span> <span class="token string">'^'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span>    colors <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'blue'</span><span class="token punctuation">,</span> <span class="token string">'lightgreen'</span><span class="token punctuation">,</span> <span class="token string">'gray'</span><span class="token punctuation">,</span> <span class="token string">'cyan'</span><span class="token punctuation">)</span>    cmap <span class="token operator">=</span> ListedColormap<span class="token punctuation">(</span>colors<span class="token punctuation">[</span><span class="token punctuation">:</span>len<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot the decision surface</span>    x1_min<span class="token punctuation">,</span> x1_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    x2_min<span class="token punctuation">,</span> x2_max <span class="token operator">=</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>    xx1<span class="token punctuation">,</span> xx2 <span class="token operator">=</span> np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x1_min<span class="token punctuation">,</span> x1_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">,</span>                         np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x2_min<span class="token punctuation">,</span> x2_max<span class="token punctuation">,</span> resolution<span class="token punctuation">)</span><span class="token punctuation">)</span>    Z <span class="token operator">=</span> classifier<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>xx1<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>T<span class="token punctuation">)</span>    Z <span class="token operator">=</span> Z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>contourf<span class="token punctuation">(</span>xx1<span class="token punctuation">,</span> xx2<span class="token punctuation">,</span> Z<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span>cmap<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx1<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx1<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>xx2<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xx2<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># plot all samples</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> cl <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token operator">=</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> cl<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token operator">=</span>X<span class="token punctuation">[</span>y <span class="token operator">==</span> cl<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">,</span> c<span class="token operator">=</span>colors<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span>                    marker<span class="token operator">=</span>markers<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span>cl<span class="token punctuation">,</span>                    edgecolor<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># highlight test samples</span>    <span class="token keyword">if</span> test_idx<span class="token punctuation">:</span>        X_test<span class="token punctuation">,</span> y_test <span class="token operator">=</span> X<span class="token punctuation">[</span>test_idx<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y<span class="token punctuation">[</span>test_idx<span class="token punctuation">]</span>           plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'cyan'</span><span class="token punctuation">,</span>                 alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'o'</span><span class="token punctuation">,</span>                 s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'test set'</span><span class="token punctuation">)</span>X_combined_std <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span><span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> X_test_std<span class="token punctuation">)</span><span class="token punctuation">)</span>y_combined <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex8_4 LogisticRegression建模</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression<span class="token comment" spellcheck="true"># C parameter 是什么呢?</span>lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">100.0</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>lr<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_test_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">## 每行对应三种花类的概率</span>lr<span class="token punctuation">.</span>predict_proba<span class="token punctuation">(</span>X_test_std<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)array([2, 0, 0, 1, 1], dtype=int64)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex8_5 正则路径分析</span><span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltweights<span class="token punctuation">,</span> params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token keyword">for</span> c <span class="token keyword">in</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token operator">**</span>c<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    lr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>    weights<span class="token punctuation">.</span>append<span class="token punctuation">(</span>lr<span class="token punctuation">.</span>coef_<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    params<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">.</span><span class="token operator">**</span>c<span class="token punctuation">)</span>weights <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>weights<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>params<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'petal length'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>params<span class="token punctuation">,</span> weights<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'petal width'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'weight coefficient'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'C'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span><span class="token string">'text.usetex'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span><span class="token string">'font.family'</span><span class="token punctuation">:</span> <span class="token string">'stixgeneral'</span><span class="token punctuation">,</span><span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span> <span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.  FutureWarning)C:\Users\43790\Anaconda3\lib\site-packages\sklearn\linear_model\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.  "this warning.", FutureWarning)</code></pre><p><img src="output_4_1.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># ex8_6 在iris数据集上训练一个支持向量机模型</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVCsvm <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>svm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>plot_decision_regions<span class="token punctuation">(</span>X_combined_std<span class="token punctuation">,</span> y_combined<span class="token punctuation">,</span>                       classifier<span class="token operator">=</span>svm<span class="token punctuation">,</span> test_idx<span class="token operator">=</span>range<span class="token punctuation">(</span><span class="token number">105</span><span class="token punctuation">,</span><span class="token number">150</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'petal length [standardized]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'petal width [standardized]'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_5_0.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#8_10 分类指标accuracy</span><span class="token comment" spellcheck="true"># 构建指标</span><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVCX<span class="token punctuation">,</span>y <span class="token operator">=</span> datasets<span class="token punctuation">.</span>make_classification<span class="token punctuation">(</span>n_classes<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>sc <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>sc<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_train_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>X_test_std <span class="token operator">=</span> sc<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>probability<span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_std<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_std<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_scorey_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_std<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>0.83333333333333340.8333333333333334</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 8_11 混淆矩阵</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrixy_test_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test_std<span class="token punctuation">)</span>confmat <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_test_pred<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>confmat<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_test_pred<span class="token punctuation">)</span><span class="token punctuation">,</span>cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Blues<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Predicted label"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"True label"</span><span class="token punctuation">)</span></code></pre><pre><code>[[15  3] [ 2 10]]Text(0, 0.5, 'True label')</code></pre><p><img src="output_7_2.png"></p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> confusion_matrix<span class="token comment" spellcheck="true">#7、6、6</span>y_test <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span>            <span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span>            <span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">,</span><span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">]</span>y_test_pred <span class="token operator">=</span>  <span class="token punctuation">[</span><span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span> <span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span>              <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span>              <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span> <span class="token string">'neg'</span><span class="token punctuation">,</span> <span class="token string">'ind'</span><span class="token punctuation">,</span> <span class="token string">'pos'</span><span class="token punctuation">,</span><span class="token string">'neg'</span><span class="token punctuation">,</span><span class="token string">'ind'</span><span class="token punctuation">]</span>confmat <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_test_pred<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>confmat<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>confusion_matrix<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_test_pred<span class="token punctuation">)</span><span class="token punctuation">,</span>cmap<span class="token operator">=</span>plt<span class="token punctuation">.</span>cm<span class="token punctuation">.</span>Blues<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Predicted label"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"True label"</span><span class="token punctuation">)</span></code></pre><pre><code>[[6 3 1] [2 6 2] [2 1 7]]Text(0, 0.5, 'True label')</code></pre><p><img src="output_8_2.png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## ex8_12 精确率、召回率和调和值</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> precision_score<span class="token punctuation">,</span> recall_score<span class="token punctuation">,</span> f1_score<span class="token punctuation">,</span> fbeta_score<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Precision: %.3f'</span> <span class="token operator">%</span> precision_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y_test<span class="token punctuation">,</span> y_pred<span class="token operator">=</span>y_test_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Recall: %.3f'</span> <span class="token operator">%</span> recall_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y_test<span class="token punctuation">,</span> y_pred<span class="token operator">=</span>y_test_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'F1: %.3f'</span> <span class="token operator">%</span> f1_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y_test<span class="token punctuation">,</span> y_pred<span class="token operator">=</span>y_test_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'F_beta2: %.3f'</span> <span class="token operator">%</span> fbeta_score<span class="token punctuation">(</span>y_true<span class="token operator">=</span>y_test<span class="token punctuation">,</span> y_pred<span class="token operator">=</span>y_test_pred<span class="token punctuation">,</span> beta<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> classification_report<span class="token keyword">print</span><span class="token punctuation">(</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_test_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Precision: 0.769Recall: 0.833F1: 0.800F_beta2: 0.820              precision    recall  f1-score   support           0       0.88      0.83      0.86        18           1       0.77      0.83      0.80        12    accuracy                           0.83        30   macro avg       0.83      0.83      0.83        30weighted avg       0.84      0.83      0.83        30</code></pre><p>​    </p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#8_13</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> itertools <span class="token keyword">import</span> cycle<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> svm<span class="token punctuation">,</span> datasets<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_curve<span class="token punctuation">,</span> auc<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> label_binarize<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>multiclass <span class="token keyword">import</span> OneVsRestClassifier<span class="token keyword">from</span> scipy <span class="token keyword">import</span> interp<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_auc_score<span class="token comment" spellcheck="true"># Import some data to play with</span>iris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> iris<span class="token punctuation">.</span>datay <span class="token operator">=</span> iris<span class="token punctuation">.</span>target<span class="token comment" spellcheck="true"># Binarize the output</span>y <span class="token operator">=</span> label_binarize<span class="token punctuation">(</span>y<span class="token punctuation">,</span> classes<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>n_classes <span class="token operator">=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># Add noisy features to make the problem harder</span>random_state <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>RandomState<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>n_samples<span class="token punctuation">,</span> n_features <span class="token operator">=</span> X<span class="token punctuation">.</span>shapeX <span class="token operator">=</span> np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>X<span class="token punctuation">,</span> random_state<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_samples<span class="token punctuation">,</span> <span class="token number">200</span> <span class="token operator">*</span> n_features<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># shuffle and split training and test sets</span>X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">,</span>                                                    random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Learn to predict each class against the other</span>classifier <span class="token operator">=</span> OneVsRestClassifier<span class="token punctuation">(</span>svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> probability<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                                 random_state<span class="token operator">=</span>random_state<span class="token punctuation">)</span><span class="token punctuation">)</span>y_score <span class="token operator">=</span> classifier<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">.</span>decision_function<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Compute ROC curve and ROC area for each class</span>fpr <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span>tpr <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span>roc_auc <span class="token operator">=</span> dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>    fpr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> tpr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">,</span> y_score<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span><span class="token punctuation">)</span>    roc_auc<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> auc<span class="token punctuation">(</span>fpr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> tpr<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Compute micro-average ROC curve and ROC area</span>fpr<span class="token punctuation">[</span><span class="token string">"micro"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tpr<span class="token punctuation">[</span><span class="token string">"micro"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> _ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_test<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_score<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>roc_auc<span class="token punctuation">[</span><span class="token string">"micro"</span><span class="token punctuation">]</span> <span class="token operator">=</span> auc<span class="token punctuation">(</span>fpr<span class="token punctuation">[</span><span class="token string">"micro"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tpr<span class="token punctuation">[</span><span class="token string">"micro"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"auc"</span><span class="token punctuation">,</span> roc_auc<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>lw <span class="token operator">=</span> <span class="token number">2</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tpr<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'darkorange'</span><span class="token punctuation">,</span>         lw<span class="token operator">=</span>lw<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'ROC curve (area = %0.2f)'</span> <span class="token operator">%</span> roc_auc<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'navy'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span>lw<span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'False Positive Rate'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'True Positive Rate'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Receiver operating characteristic example'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">"lower right"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>auc {0: 0.9126984126984127, 1: 0.6037037037037037, 2: 0.7867647058823529, 'micro': 0.7277333333333333}</code></pre><p><img src="output_10_1.png"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据预处理</title>
      <link href="/2020/03/26/shu-ju-yu-chu-li/"/>
      <url>/2020/03/26/shu-ju-yu-chu-li/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 4_1 列表转换为数组，并查看属性</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nplist1<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span>arr1<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>list1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>arr1<span class="token punctuation">)</span><span class="token punctuation">)</span>list2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">]</span>arr2<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>list2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>arr2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr1<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span></code></pre><pre><code>[1 3 5 2 4 6 7 8]&lt;class 'numpy.ndarray'&gt;[[1 2 3 4] [5 6 7 8]]&lt;class 'numpy.ndarray'&gt;(8,)int32</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4_2 数组数据类型制定和转换</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nparr3<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype <span class="token operator">=</span> np<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr3<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>type<span class="token punctuation">(</span>arr3<span class="token punctuation">)</span><span class="token punctuation">)</span>arr4 <span class="token operator">=</span> arr3<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr4<span class="token punctuation">)</span></code></pre><pre><code>[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]&lt;class 'numpy.ndarray'&gt;[0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nparr1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##参数个数是维数</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr1<span class="token punctuation">)</span>arr2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>arr3 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##参数个数是维数</span>arr4 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr3<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr4<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>arr5 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>arr6 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">50</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr5<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr6<span class="token punctuation">)</span></code></pre><pre><code>[0.89047564 0.75284677 0.53104592 0.81625685 0.84464871][[0.80419335 0.76978933 0.9972854  0.51693425] [0.32584148 0.31802441 0.49764098 0.08908957] [0.90476187 0.6350045  0.46295265 0.17243788]][0.66652768 0.33403115 1.22880655][[-2.8255849  -0.91619008  1.79742598] [-0.95809858  0.27216564  0.01706177]][53  2 76 81  0 96  4  6 57 30][34 37 40 46 29 29 48 45 47 41]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 4_4 数组的基本运算</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> nparr1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>arr2 <span class="token operator">=</span> arr1<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>arr2<span class="token punctuation">.</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>arr3 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr3<span class="token punctuation">)</span>arr4 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr4<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr3<span class="token operator">+</span>arr4<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>arr3<span class="token operator">*</span><span class="token number">2</span><span class="token punctuation">)</span></code></pre><pre><code>[30  7 37 91 33 58 97 55 39  0 73 55][[30  7 37 91] [33 58 97 55] [39  0 73 55]][[30  7 37] [91 33 58] [97 55 39] [ 0 73 55]][6 4 6 4 3 6][1 7 5 7 8 1][ 7 11 11 11 11  7][12  8 12  8  6 12]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 4_5 数组的常用运算及函数</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> npnp<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">123</span><span class="token punctuation">)</span>arr1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>arr2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'arr1为：\n'</span><span class="token punctuation">,</span>arr1<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'arr2为：\n'</span><span class="token punctuation">,</span>arr2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'对应元素相加：\n'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>add<span class="token punctuation">(</span>arr1<span class="token punctuation">,</span>arr2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'max'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>max<span class="token punctuation">(</span>arr1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'arr1每列和为：'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>sum<span class="token punctuation">(</span>arr1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'展开排序：'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>arr1<span class="token punctuation">,</span>axis<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>arr1为： [[3 3 7 2] [4 7 2 1] [2 1 1 4]]arr2为： [[5 1 1 5] [2 8 4 3] [5 8 3 5]]对应元素相加： [[ 8  4  8  7] [ 6 15  6  4] [ 7  9  4  9]]max 7arr1每列和为： [ 9 11 10  7]展开排序： [1 1 1 2 2 2 3 3 4 4 7 7]</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file"</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'baiyun.csv'</span><span class="token punctuation">)</span>df1 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df1<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df2 <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token operator">&gt;</span><span class="token number">7.2</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df2<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df3 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token operator">&gt;</span><span class="token number">7.2</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token number">7.3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df3<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df4 <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span> <span class="token operator">==</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df4<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>   Open  Close0  6.13   6.191  6.13   6.192  6.22   6.223  6.18   6.144  6.16   6.21    Unnamed: 0  Open  High   Low  Close     Volume  Adjusted       Date90          91  7.28  7.55  7.28   7.44  6928500.0      6.27   2012/5/791          92  7.44  7.47  7.37   7.39  4018900.0      6.23   2012/5/892          93  7.36  7.38  7.22   7.25  4322200.0      6.11   2012/5/993          94  7.25  7.34  7.25   7.30  1812400.0      6.15  2012/5/1094          95  7.28  7.33  7.26   7.29  1326300.0      6.15  2012/5/11     Open  Close92   7.36   7.2594   7.28   7.2997   7.27   7.2399   7.33   7.28100  7.26   7.15    Unnamed: 0  Open  High   Low  Close     Volume  Adjusted      Date91          92  7.44  7.47  7.37   7.39  4018900.0      6.23  2012/5/8</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 4_6 series创建</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> nps1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"不加索引："</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s1<span class="token punctuation">)</span>s2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>nan<span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>index<span class="token operator">=</span>list<span class="token punctuation">(</span><span class="token string">'abcdef'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float64<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"指定索引："</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s2<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'s2的索引为：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s2<span class="token punctuation">.</span>index<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"s2的元素值为："</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s2<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'values之后的类型为：'</span><span class="token punctuation">,</span>type<span class="token punctuation">(</span>s2<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>不加索引：0    1.01    3.02    5.03    6.04    NaN5    9.0dtype: float64指定索引：a    1.0b    3.0c    5.0d    6.0e    NaNf    9.0dtype: float64s2的索引为：Index(['a', 'b', 'c', 'd', 'e', 'f'], dtype='object')s2的元素值为：[ 1.  3.  5.  6. nan  9.]values之后的类型为： &lt;class 'numpy.ndarray'&gt;</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4_7 创建DataFrame对象</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdf <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>columns<span class="token operator">=</span>list<span class="token punctuation">(</span><span class="token string">'abcd'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'df的索引为：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>index<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'df的值为：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'df的数据类型为：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>dtypes<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'df第a列的值为：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre><pre><code>df的索引为：RangeIndex(start=0, stop=3, step=1)df的值为：[[6 1 8 9] [9 6 1 1] [3 4 9 2]]df的数据类型为：a    int32b    int32c    int32d    int32dtype: objectdf第a列的值为：0    61    92    3Name: a, dtype: int32</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4_8 读取csv文件</span><span class="token keyword">import</span> os<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'test.csv'</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token string">'date'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"索引"</span><span class="token punctuation">,</span>df<span class="token punctuation">.</span>index<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"列名"</span><span class="token punctuation">,</span>df<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"索引"</span><span class="token punctuation">,</span>df<span class="token punctuation">.</span>values<span class="token punctuation">)</span></code></pre><pre><code>                 A         B         C         Ddate                                            2016/1/1  0.051358 -0.464379  0.451372 -0.3046872016/1/2 -1.374134 -0.178072  0.883113 -0.5730642016/1/3  1.877980  0.627882  0.301245  0.2526592016/1/4 -0.647477 -0.120387  2.348094 -2.3904372016/1/5 -1.729381  0.730832  0.230677  0.6234882016/1/6  0.567245 -2.081011 -1.747135 -0.408908索引 Index(['2016/1/1', '2016/1/2', '2016/1/3', '2016/1/4', '2016/1/5', '2016/1/6'], dtype='object', name='date')列名 Index(['A', 'B', 'C', 'D'], dtype='object')索引 [[ 0.05135836 -0.46437928  0.45137204 -0.30468682] [-1.37413401 -0.17807187  0.88311339 -0.57306432] [ 1.87798019  0.62788159  0.30124543  0.2526588 ] [-0.64747653 -0.12038665  2.34809374 -2.39043665] [-1.72938075  0.73083192  0.23067708  0.62348796] [ 0.56724547 -2.08101057 -1.7471353  -0.40890759]]</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4_9 (1)</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'baiyun.csv'</span><span class="token punctuation">)</span>df1 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df1<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df2 <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token operator">&gt;</span><span class="token number">7.2</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df2<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df3 <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token operator">&gt;</span><span class="token number">7.2</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token operator">&lt;</span><span class="token number">7.3</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df3<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df4 <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span> <span class="token operator">==</span> df<span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df4<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df5 <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df5<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df6 <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'High'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df6<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df7 <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Volume'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">,</span><span class="token string">'Volume'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df7<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>df8 <span class="token operator">=</span> df<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">'Volume'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'Open'</span><span class="token punctuation">,</span><span class="token string">'Close'</span><span class="token punctuation">,</span><span class="token string">'Volume'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df8<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>r3 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>len<span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>df9 <span class="token operator">=</span> df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>r3<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span>df9<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>   Open  Close0  6.13   6.191  6.13   6.192  6.22   6.223  6.18   6.144  6.16   6.21    Unnamed: 0  Open  High   Low  Close     Volume  Adjusted       Date90          91  7.28  7.55  7.28   7.44  6928500.0      6.27   2012/5/791          92  7.44  7.47  7.37   7.39  4018900.0      6.23   2012/5/892          93  7.36  7.38  7.22   7.25  4322200.0      6.11   2012/5/993          94  7.25  7.34  7.25   7.30  1812400.0      6.15  2012/5/1094          95  7.28  7.33  7.26   7.29  1326300.0      6.15  2012/5/11     Open  Close92   7.36   7.2594   7.28   7.2997   7.27   7.2399   7.33   7.28100  7.26   7.15    Unnamed: 0  Open  High   Low  Close     Volume  Adjusted      Date91          92  7.44  7.47  7.37   7.39  4018900.0      6.23  2012/5/8    Unnamed: 0  Open  High   Low  Close     Volume  Adjusted       Date8            9  6.35  6.44  6.35   6.38  2181500.0      5.38  2012/1/129           10  6.39  6.40  6.25   6.30  3540200.0      5.31  2012/1/1310          11  6.26  6.36  6.23   6.31  3099900.0      5.32  2012/1/1611          12  6.32  6.52  6.26   6.51  5754900.0      5.49  2012/1/1712          13  6.50  6.54  6.43   6.46  4295000.0      5.45  2012/1/18    High  Close8   6.44   6.389   6.40   6.3010  6.36   6.3111  6.52   6.5112  6.54   6.46    Open  Close  Volume15  6.57   6.57     NaN16  6.57   6.57     NaN17  6.57   6.57     NaN18  6.57   6.57     NaN19  6.57   6.57     NaN    Open  Close  Volume15  6.57   6.57     NaN16  6.57   6.57     NaN17  6.57   6.57     NaN18  6.57   6.57     NaN19  6.57   6.57     NaN     Unnamed: 0  Open  High   Low  Close     Volume  Adjusted       Date148         149  6.33  6.38  6.22   6.23  3076000.0      5.54  2012/7/26191         192  6.48  6.49  6.40   6.47   965700.0      5.75  2012/9/25164         165  6.36  6.40  6.33   6.35   846900.0      5.64  2012/8/17</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4_10抽取记录</span><span class="token comment" spellcheck="true">#4_9 记录抽取</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'baiyun.csv'</span><span class="token punctuation">,</span>nrows<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span>df<span class="token comment" spellcheck="true">#df1 = df.sort_values(by['High'])</span><span class="token comment" spellcheck="true">#df1</span>df2 <span class="token operator">=</span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'High'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df2<span class="token punctuation">)</span>df3 <span class="token operator">=</span> df2<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span>by<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'High'</span><span class="token punctuation">,</span><span class="token string">'Open'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>ascending <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df3<span class="token punctuation">)</span></code></pre><pre><code>    Unnamed: 0  Open  High   Low  Close   Volume  Adjusted       Date0            1  6.13  6.22  6.11   6.19  4017600      5.22   2012/1/21            2  6.13  6.22  6.11   6.19  4017600      5.22   2012/1/33            4  6.18  6.26  6.10   6.14  5630400      5.18   2012/1/54            5  6.16  6.26  6.14   6.21  4900400      5.24   2012/1/62            3  6.22  6.30  6.19   6.22  5663600      5.24   2012/1/410          11  6.26  6.36  6.23   6.31  3099900      5.32  2012/1/165            6  6.23  6.37  6.21   6.33  4477300      5.34   2012/1/99           10  6.39  6.40  6.25   6.30  3540200      5.31  2012/1/138            9  6.35  6.44  6.35   6.38  2181500      5.38  2012/1/127            8  6.43  6.47  6.37   6.38  4426600      5.38  2012/1/116            7  6.35  6.48  6.31   6.46  7500900      5.45  2012/1/1011          12  6.32  6.52  6.26   6.51  5754900      5.49  2012/1/17    Unnamed: 0  Open  High   Low  Close   Volume  Adjusted       Date0            1  6.13  6.22  6.11   6.19  4017600      5.22   2012/1/21            2  6.13  6.22  6.11   6.19  4017600      5.22   2012/1/33            4  6.18  6.26  6.10   6.14  5630400      5.18   2012/1/54            5  6.16  6.26  6.14   6.21  4900400      5.24   2012/1/62            3  6.22  6.30  6.19   6.22  5663600      5.24   2012/1/410          11  6.26  6.36  6.23   6.31  3099900      5.32  2012/1/165            6  6.23  6.37  6.21   6.33  4477300      5.34   2012/1/99           10  6.39  6.40  6.25   6.30  3540200      5.31  2012/1/138            9  6.35  6.44  6.35   6.38  2181500      5.38  2012/1/127            8  6.43  6.47  6.37   6.38  4426600      5.38  2012/1/116            7  6.35  6.48  6.31   6.46  7500900      5.45  2012/1/1011          12  6.32  6.52  6.26   6.51  5754900      5.49  2012/1/17</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">## 4_11  重新索引</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> os os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'baiyun.csv'</span><span class="token punctuation">,</span>nrows<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'原始数据：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>dtypes<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将Data列转换为日期类型，调用to_datetime()方法</span>df<span class="token punctuation">[</span><span class="token string">'Date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">'Date'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#将new_index 设置为索引</span>df<span class="token punctuation">.</span>set_index<span class="token punctuation">(</span><span class="token string">'Date'</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'重新索引后的数据：'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>index<span class="token punctuation">)</span></code></pre><pre><code>原始数据：    Unnamed: 0  Open  High   Low  Close   Volume  Adjusted       Date0            1  6.13  6.22  6.11   6.19  4017600      5.22   2012/1/21            2  6.13  6.22  6.11   6.19  4017600      5.22   2012/1/32            3  6.22  6.30  6.19   6.22  5663600      5.24   2012/1/43            4  6.18  6.26  6.10   6.14  5630400      5.18   2012/1/54            5  6.16  6.26  6.14   6.21  4900400      5.24   2012/1/65            6  6.23  6.37  6.21   6.33  4477300      5.34   2012/1/96            7  6.35  6.48  6.31   6.46  7500900      5.45  2012/1/107            8  6.43  6.47  6.37   6.38  4426600      5.38  2012/1/118            9  6.35  6.44  6.35   6.38  2181500      5.38  2012/1/129           10  6.39  6.40  6.25   6.30  3540200      5.31  2012/1/1310          11  6.26  6.36  6.23   6.31  3099900      5.32  2012/1/1611          12  6.32  6.52  6.26   6.51  5754900      5.49  2012/1/17Unnamed: 0      int64Open          float64High          float64Low           float64Close         float64Volume          int64Adjusted      float64Date           objectdtype: object重新索引后的数据：            Unnamed: 0  Open  High   Low  Close   Volume  AdjustedDate                                                              2012-01-02           1  6.13  6.22  6.11   6.19  4017600      5.222012-01-03           2  6.13  6.22  6.11   6.19  4017600      5.222012-01-04           3  6.22  6.30  6.19   6.22  5663600      5.242012-01-05           4  6.18  6.26  6.10   6.14  5630400      5.182012-01-06           5  6.16  6.26  6.14   6.21  4900400      5.242012-01-09           6  6.23  6.37  6.21   6.33  4477300      5.342012-01-10           7  6.35  6.48  6.31   6.46  7500900      5.452012-01-11           8  6.43  6.47  6.37   6.38  4426600      5.382012-01-12           9  6.35  6.44  6.35   6.38  2181500      5.382012-01-13          10  6.39  6.40  6.25   6.30  3540200      5.312012-01-16          11  6.26  6.36  6.23   6.31  3099900      5.322012-01-17          12  6.32  6.52  6.26   6.51  5754900      5.49DatetimeIndex(['2012-01-02', '2012-01-03', '2012-01-04', '2012-01-05',               '2012-01-06', '2012-01-09', '2012-01-10', '2012-01-11',               '2012-01-12', '2012-01-13', '2012-01-16', '2012-01-17'],              dtype='datetime64[ns]', name='Date', freq=None)</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#4_12</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> os os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file'</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'baiyun.csv'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##查看原始数据</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##查看Unnamed:0列和Adjusted列</span>df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Unnamed: 0'</span><span class="token punctuation">,</span><span class="token string">'Adjusted'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##查看含缺失值的列</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##删除确实值所在的行</span>df<span class="token punctuation">.</span>dropna<span class="token punctuation">(</span>inplace <span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>   Unnamed: 0  Open  High   Low  Close     Volume  Adjusted      Date0           1  6.13  6.22  6.11   6.19  4017600.0      5.22  2012/1/21           2  6.13  6.22  6.11   6.19  4017600.0      5.22  2012/1/32           3  6.22  6.30  6.19   6.22  5663600.0      5.24  2012/1/43           4  6.18  6.26  6.10   6.14  5630400.0      5.18  2012/1/54           5  6.16  6.26  6.14   6.21  4900400.0      5.24  2012/1/6   Open  High   Low  Close     Volume      Date0  6.13  6.22  6.11   6.19  4017600.0  2012/1/21  6.13  6.22  6.11   6.19  4017600.0  2012/1/32  6.22  6.30  6.19   6.22  5663600.0  2012/1/43  6.18  6.26  6.10   6.14  5630400.0  2012/1/54  6.16  6.26  6.14   6.21  4900400.0  2012/1/6&lt;class 'pandas.core.frame.DataFrame'&gt;RangeIndex: 261 entries, 0 to 260Data columns (total 6 columns):Open      261 non-null float64High      261 non-null float64Low       261 non-null float64Close     261 non-null float64Volume    244 non-null float64Date      261 non-null objectdtypes: float64(5), object(1)memory usage: 12.4+ KBNone&lt;class 'pandas.core.frame.DataFrame'&gt;Int64Index: 244 entries, 0 to 260Data columns (total 6 columns):Open      244 non-null float64High      244 non-null float64Low       244 non-null float64Close     244 non-null float64Volume    244 non-null float64Date      244 non-null objectdtypes: float64(5), object(1)memory usage: 13.3+ KBNone</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 4_13 合并数据框</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npdf1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>columns<span class="token operator">=</span>list<span class="token punctuation">(</span><span class="token string">'abcd'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df1<span class="token punctuation">)</span>df2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>columns<span class="token operator">=</span>list<span class="token punctuation">(</span><span class="token string">'acd'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df2<span class="token punctuation">)</span>df3 <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>df1<span class="token punctuation">,</span>df2<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>df3<span class="token punctuation">)</span></code></pre><pre><code>          a         b         c         d0  0.288055 -0.125249  1.738351  0.9349461  0.913534 -0.294488 -1.395790 -0.1783742  0.652948 -0.261468  0.862754 -0.662991          a         c         d0 -0.938708 -0.029112 -0.9925821 -0.543940  0.717491 -0.7378992 -0.383889 -0.395397  1.159722          a         b         c         d0  0.288055 -0.125249  1.738351  0.9349461  0.913534 -0.294488 -1.395790 -0.1783742  0.652948 -0.261468  0.862754 -0.6629910 -0.938708       NaN -0.029112 -0.9925821 -0.543940       NaN  0.717491 -0.7378992 -0.383889       NaN -0.395397  1.159722C:\Users\43790\Anaconda3\lib\site-packages\ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future versionof pandas will change to not sort by default.To accept the future behavior, pass 'sort=False'.To retain the current behavior and silence the warning, pass 'sort=True'.  # Remove the CWD from sys.path while we load stuff.</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns <span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessing<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression<span class="token operator">%</span>matplotlib inline<span class="token keyword">import</span> warnings<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file\第5讲数据集"</span><span class="token punctuation">)</span>train <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"accord_sedan_training.csv"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data shape is:"</span><span class="token punctuation">,</span>train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##417*6</span><span class="token keyword">print</span><span class="token punctuation">(</span>train<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train<span class="token punctuation">[</span><span class="token string">'trim'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##看特征取值的个数</span><span class="token keyword">print</span><span class="token punctuation">(</span>train<span class="token punctuation">[</span><span class="token string">'transmission'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##数字编码用replace方法</span>train<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>to_replace<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"trim":&amp;#123;"ex":0,"lx":1,"exl":2&amp;#125;&amp;#125;,inplace=True)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train<span class="token punctuation">[</span><span class="token string">'trim'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value_counts<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>train<span class="token punctuation">[</span><span class="token string">'trim'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##利用pandas实现one-hot编码</span>cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'trim'</span><span class="token punctuation">,</span><span class="token string">'engine'</span><span class="token punctuation">,</span><span class="token string">'transmission'</span><span class="token punctuation">]</span>dummies <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>train<span class="token punctuation">[</span>cols<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##dummies为数据框</span>train_dummies <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>train<span class="token punctuation">,</span>dummies<span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##连接</span>train_dummies<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>cols<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment" spellcheck="true">##删除原数据列</span><span class="token keyword">print</span><span class="token punctuation">(</span>train_dummies<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>data shape is: (417, 6)   price  mileage  year trim engine transmission0  14995    67697  2006   ex  4 Cyl       Manual1  11988    73738  2006   ex  4 Cyl       Manual2  11999    80313  2006   lx  4 Cyl    Automatic3  12995    86096  2006   lx  4 Cyl    Automatic4  11333    79607  2006   lx  4 Cyl    Automaticex     288lx     120exl      9Name: trim, dtype: int64Automatic    382Manual        35Name: transmission, dtype: int640    2881    1202      9Name: trim, dtype: int640    01    02    13    14    1Name: trim, dtype: int64   price  mileage  year  engine_4 Cyl  engine_6 Cyl  transmission_Automatic  \0  14995    67697  2006             1             0                       0   1  11988    73738  2006             1             0                       0   2  11999    80313  2006             1             0                       1   3  12995    86096  2006             1             0                       1   4  11333    79607  2006             1             0                       1      transmission_Manual  0                    1  1                    1  2                    0  3                    0  4                    0  </code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">'C:\Users\43790\data file\第5讲数据集'</span><span class="token punctuation">)</span>names <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'dermatology_names.txt'</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>names <span class="token operator">=</span> names<span class="token punctuation">.</span>sort_index<span class="token punctuation">(</span><span class="token punctuation">)</span>names<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token number">35</span><span class="token punctuation">]</span><span class="token operator">=</span> <span class="token string">'label'</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dermatology.data"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">,</span>names<span class="token operator">=</span>names<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#data.info()</span><span class="token comment" spellcheck="true">##age列含有缺失值？</span>data<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"Age (linear)":"Age"&amp;#125;,inplace=True)</span>data<span class="token punctuation">.</span>columns<span class="token comment" spellcheck="true">#查找Age为？的行</span>indexNull <span class="token operator">=</span> data<span class="token punctuation">[</span>data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token string">'?'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token keyword">print</span><span class="token punctuation">(</span>indexNull<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#替换为空值</span>data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'?': np.nan&amp;#125;,inplace=True)</span><span class="token comment" spellcheck="true">#转换为浮点数，cannot convert float NaN to integer</span>data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float64<span class="token punctuation">)</span>data<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>round<span class="token punctuation">(</span>data<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##填充均值，对非数值型字段无改变</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>indexNull<span class="token punctuation">,</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##查看填充值</span>data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>int64<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##同样转换为整形</span><span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>indexNull<span class="token punctuation">,</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##使用众数填充</span><span class="token comment" spellcheck="true">##注意众数返回的是Series数据</span></code></pre><pre><code>Int64Index([33, 34, 35, 36, 262, 263, 264, 265], dtype='int64')33     36.034     36.035     36.036     36.0262    36.0263    36.0264    36.0265    36.0Name: Age, dtype: float6433     3634     3635     3636     36262    36263    36264    36265    36Name: Age, dtype: int64</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习基础</title>
      <link href="/2020/03/22/ji-qi-xue-xi-ji-chu/"/>
      <url>/2020/03/22/ji-qi-xue-xi-ji-chu/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习学习笔记——No-1机器学习基础"><a href="#机器学习学习笔记——No-1机器学习基础" class="headerlink" title="机器学习学习笔记——No.1机器学习基础"></a>机器学习学习笔记——No.1机器学习基础</h1><ul><li><p>Author：Singularity ZGX</p></li><li><p>Date  :2020.04.21</p></li><li><p>Source:Github &amp; CSDN &amp; Geek</p></li><li><p>Type  :Personal notes</p></li></ul><h2 id="机器学习-概述"><a href="#机器学习-概述" class="headerlink" title="机器学习 概述"></a>机器学习 概述</h2><p><code>机器学习(Machine Learning,ML)</code> 是使用计算机来彰显数据背后的真实含义，它为了把无序的数据转换成有用的信息。是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。<br>它是人工智能的核心，是使计算机具有智能的根本途径，其应用遍及人工智能的各个领域，它主要使用归纳、综合而不是演绎。</p><ol><li>海量的数据</li><li>获取有用的信息</li></ol><h2 id="机器学习-研究意义"><a href="#机器学习-研究意义" class="headerlink" title="机器学习 研究意义"></a>机器学习 研究意义</h2><p>机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能”。 “机器学习是对能通过经验自动改进的计算机算法的研究”。 “机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。” 一种经常引用的英文定义是：A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p><p>机器学习已经有了十分广泛的应用，例如：数据挖掘、计算机视觉、自然语言处理、生物特征识别、搜索引擎、医学诊断、检测信用卡欺诈、证券市场分析、DNA序列测序、语音和手写识别、战略游戏和机器人运用。</p><h2 id="机器学习-场景"><a href="#机器学习-场景" class="headerlink" title="机器学习 场景"></a>机器学习 场景</h2><ul><li><p>例如：识别动物猫</p><ul><li>模式识别（官方标准）：人们通过大量的经验，得到结论，从而判断它就是猫。</li><li>机器学习（数据学习）：人们通过阅读进行学习，观察它会叫、小眼睛、两只耳朵、四条腿、一条尾巴，得到结论，从而判断它就是猫。</li><li>深度学习（深入数据）：人们通过深入了解它，发现它会’喵喵’的叫、与同类的猫科动物很类似，得到结论，从而判断它就是猫。（深度学习常用领域：语音识别、图像识别）</li></ul></li><li><p>模式识别（pattern recognition）: 模式识别是最古老的（作为一个术语而言，可以说是很过时的）。</p><ul><li>我们把环境与客体统称为“模式”，识别是对模式的一种认知，是如何让一个计算机程序去做一些看起来很“智能”的事情。</li><li>通过融于智慧和直觉后，通过构建程序，识别一些事物，而不是人，例如: 识别数字。</li></ul></li><li><p>机器学习（machine learning）: 机器学习是最基础的（当下初创公司和研究实验室的热点领域之一）。</p><ul><li>在90年代初，人们开始意识到一种可以更有效地构建模式识别算法的方法，那就是用数据（可以通过廉价劳动力采集获得）去替换专家（具有很多图像方面知识的人）。</li><li>“机器学习”强调的是，在给计算机程序（或者机器）输入一些数据后，它必须做一些事情，那就是学习这些数据，而这个学习的步骤是明确的。</li><li>机器学习（Machine Learning）是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身性能的学科。</li></ul></li><li><p>深度学习（deep learning）: 深度学习是非常崭新和有影响力的前沿领域，我们甚至不会去思考-后深度学习时代。</p><ul><li>深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。</li></ul></li><li><p>参考地址： </p><ul><li><a href="http://www.csdn.net/article/2015-03-24/2824301">深度学习 vs 机器学习 vs 模式识别</a></li><li><a href="http://baike.baidu.com/link?url=76P-uA4EBrC3G-I__P1tqeO7eoDS709Kp4wYuHxc7GNkz_xn0NxuAtEohbpey7LUa2zUQLJxvIKUx4bnrEfOmsWLKbDmvG1PCoRkJisMTQka6-QReTrIxdYY3v93f55q">深度学习 百科资料</a></li></ul></li></ul><blockquote><p>机器学习已应用于多个领域，远远超出大多数人的想象，横跨：计算机科学、工程技术和统计学等多个学科。</p></blockquote><ul><li>搜索引擎: 根据你的搜索点击，优化你下次的搜索结果,是机器学习来帮助搜索引擎判断哪个结果更适合你（也判断哪个广告更适合你）。</li><li>垃圾邮件: 会自动的过滤垃圾广告邮件到垃圾箱内。</li><li>超市优惠券: 你会发现，你在购买小孩子尿布的时候，售货员会赠送你一张优惠券可以兑换6罐啤酒。</li><li>邮局邮寄: 手写软件自动识别寄送贺卡的地址。</li><li>申请贷款: 通过你最近的金融活动信息进行综合评定，决定你是否合格。</li></ul><h2 id="机器学习-组成"><a href="#机器学习-组成" class="headerlink" title="机器学习 组成"></a>机器学习 组成</h2><h3 id="主要任务"><a href="#主要任务" class="headerlink" title="主要任务"></a>主要任务</h3><ul><li>分类（classification）：将实例数据划分到合适的类别中。<ul><li>应用实例：判断网站是否被黑客入侵（二分类 ），手写数字的自动识别（多分类）</li></ul></li><li>回归（regression）：主要用于预测数值型数据。<ul><li>应用实例：股票价格波动的预测，房屋价格的预测等。</li></ul></li></ul><h3 id="监督学习（supervised-learning）"><a href="#监督学习（supervised-learning）" class="headerlink" title="监督学习（supervised learning）"></a>监督学习（supervised learning）</h3><ul><li>必须确定目标变量的值，以便机器学习算法可以发现特征和目标变量之间的关系。在监督学习中，给定一组数据，我们知道正确的输出结果应该是什么样子，并且知道在输入和输出之间有着一个特定的关系。 (包括：分类和回归)</li><li>样本集：训练数据 + 测试数据<ul><li>训练样本 = 特征(feature) + 目标变量(label: 分类-离散值/回归-连续值)</li><li>特征通常是训练样本集的列，它们是独立测量得到的。</li><li>目标变量: 目标变量是机器学习预测算法的测试结果。<ul><li>在分类算法中目标变量的类型通常是标称型(如：真与假)，而在回归算法中通常是连续型(如：1~100)。</li></ul></li></ul></li><li>监督学习需要注意的问题：<ul><li>偏置方差权衡</li><li>功能的复杂性和数量的训练数据</li><li>输入空间的维数</li><li>噪声中的输出值</li></ul></li><li><code>知识表示</code>：<ul><li>可以采用规则集的形式【例如：数学成绩大于90分为优秀】</li><li>可以采用概率分布的形式【例如：通过统计分布发现，90%的同学数学成绩，在70分以下，那么大于70分定为优秀】</li><li>可以使用训练样本集中的一个实例【例如：通过样本集合，我们训练出一个模型实例，得出 年轻，数学成绩中高等，谈吐优雅，我们认为是优秀】</li></ul></li></ul><h3 id="非监督学习（unsupervised-learing）"><a href="#非监督学习（unsupervised-learing）" class="headerlink" title="非监督学习（unsupervised learing）"></a>非监督学习（unsupervised learing）</h3><ul><li>在机器学习，无监督学习的问题是，在未加标签的数据中，试图找到隐藏的结构。因为提供给学习者的实例是未标记的，因此没有错误或报酬信号来评估潜在的解决方案。</li><li>无监督学习是密切相关的统计数据密度估计的问题。然而无监督学习还包括寻求，总结和解释数据的主要特点等诸多技术。在无监督学习使用的许多方法是基于用于处理数据的数据挖掘方法。</li><li>数据没有类别信息，也不会给定目标值。</li><li>非监督学习包括的类型：<ul><li>聚类：在无监督学习中，将数据集分成由类似的对象组成多个类的过程称为聚类。</li><li>密度估计：通过样本分布的紧密程度，来估计与分组的相似性。</li><li>此外，无监督学习还可以减少数据特征的维度，以便我们可以使用二维或三维图形更加直观地展示数据信息。<h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3>这个算法可以训练程序做出某一决定。程序在某一情况下尝试所有的可能行动，记录不同行动的结果并试着找出最好的一次尝试来做决定。 属于这一类算法的有马尔可夫决策过程。<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3></li></ul></li></ul><p><img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B.jpg" alt="机器学习训练过程图"></p><h3 id="算法汇总"><a href="#算法汇总" class="headerlink" title="算法汇总"></a>算法汇总</h3><p><img src="ml_algorithm.jpg" alt="算法汇总"></p><h2 id="机器学习-使用"><a href="#机器学习-使用" class="headerlink" title="机器学习 使用"></a>机器学习 使用</h2><blockquote><p>选择算法需要考虑的两个问题</p></blockquote><ol><li>算法场景<ul><li>预测明天是否下雨，因为可以用历史的天气情况做预测，所以选择监督学习算法</li><li>给一群陌生的人进行分组，但是我们并没有这些人的类别信息，所以选择无监督学习算法、通过他们身高、体重等特征进行处理。</li></ul></li><li>需要收集或分析的数据是什么</li></ol><blockquote><p>举例</p></blockquote><p><img src="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80-%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95.jpg" alt="选择算法图"></p><blockquote><p>机器学习 开发流程</p></blockquote><ol><li>收集数据: 收集样本数据</li><li>准备数据: 注意数据的格式</li><li>分析数据: 为了确保数据集中没有垃圾数据；<ul><li>如果是算法可以处理的数据格式或可信任的数据源，则可以跳过该步骤；</li><li>另外该步骤需要人工干预，会降低自动化系统的价值。</li></ul></li><li>训练算法: [机器学习算法核心]如果使用无监督学习算法，由于不存在目标变量值，则可以跳过该步骤</li><li>测试算法: [机器学习算法核心]评估算法效果</li><li>使用算法: 将机器学习算法转为应用程序</li></ol><h2 id="机器学习-数学基础"><a href="#机器学习-数学基础" class="headerlink" title="机器学习 数学基础"></a>机器学习 数学基础</h2><ul><li>微积分</li><li>统计学/概率论</li><li>线性代数<h2 id="机器学习-工具"><a href="#机器学习-工具" class="headerlink" title="机器学习 工具"></a>机器学习 工具</h2></li></ul><h3 id="Python语言"><a href="#Python语言" class="headerlink" title="Python语言"></a>Python语言</h3><ol><li>可执行伪代码</li><li>Python比较流行：使用广泛、代码范例多、丰富模块库，开发周期短</li><li>Python语言的特色：清晰简练、易于理解</li><li>Python语言的缺点：唯一不足的是性能问题</li><li>Python相关的库<ul><li>科学函数库：<code>SciPy</code>、<code>NumPy</code>(底层语言：C和Fortran)</li><li>绘图工具库：<code>Matplotlib</code></li><li>数据分析库 <code>Pandas</code><h3 id="数学工具"><a href="#数学工具" class="headerlink" title="数学工具"></a>数学工具</h3></li></ul></li></ol><ul><li>Matlab<h2 id="附：机器学习专业术语"><a href="#附：机器学习专业术语" class="headerlink" title="附：机器学习专业术语"></a>附：机器学习专业术语</h2></li><li>模型（model）：计算机层面的认知</li><li>学习算法（learning algorithm），从数据中产生模型的方法</li><li>数据集（data set）：一组记录的合集</li><li>示例（instance）：对于某个对象的描述</li><li>样本（sample）：也叫示例</li><li>属性（attribute）：对象的某方面表现或特征</li><li>特征（feature）：同属性</li><li>属性值（attribute value）：属性上的取值</li><li>属性空间（attribute space）：属性张成的空间</li><li>样本空间/输入空间（samplespace）：同属性空间</li><li>特征向量（feature vector）：在属性空间里每个点对应一个坐标向量，把一个示例称作特征向量</li><li>维数（dimensionality）：描述样本参数的个数（也就是空间是几维的）</li><li>学习（learning）/训练（training）：从数据中学得模型</li><li>训练数据（training data）：训练过程中用到的数据</li><li>训练样本（training sample）:训练用到的每个样本</li><li>训练集（training set）：训练样本组成的集合</li><li>假设（hypothesis）：学习模型对应了关于数据的某种潜在规则</li><li>真相（ground-truth）:真正存在的潜在规律</li><li>学习器（learner）：模型的另一种叫法，把学习算法在给定数据和参数空间的实例化</li><li>预测（prediction）：判断一个东西的属性</li><li>标记（label）：关于示例的结果信息，比如我是一个“好人”。</li><li>样例（example）：拥有标记的示例</li><li>标记空间/输出空间（label space）：所有标记的集合</li><li>分类（classification）：预测是离散值，比如把人分为好人和坏人之类的学习任务</li><li>回归（regression）：预测值是连续值，比如你的好人程度达到了0.9，0.6之类的</li><li>二分类（binary classification）：只涉及两个类别的分类任务</li><li>正类（positive class）：二分类里的一个</li><li>反类（negative class）：二分类里的另外一个</li><li>多分类（multi-class classification）：涉及多个类别的分类</li><li>测试（testing）：学习到模型之后对样本进行预测的过程</li><li>测试样本（testing sample）：被预测的样本</li><li>聚类（clustering）：把训练集中的对象分为若干组</li><li>簇（cluster）：每一个组叫簇</li><li>监督学习（supervised learning）：典范–分类和回归</li><li>无监督学习（unsupervised learning）：典范–聚类</li><li>未见示例（unseen instance）：“新样本“，没训练过的样本</li><li>泛化（generalization）能力：学得的模型适用于新样本的能力</li><li>分布（distribution）：样本空间的全体样本服从的一种规律</li><li>独立同分布（independent and identically distributed，简称i,i,d.）:获得的每个样本都是独立地从这个分布上采样获得的。</li></ul><h2 id="机器学习基础补充"><a href="#机器学习基础补充" class="headerlink" title="机器学习基础补充"></a>机器学习基础补充</h2><h3 id="数据集的划分"><a href="#数据集的划分" class="headerlink" title="数据集的划分"></a>数据集的划分</h3><ul><li>训练集（Training set） —— 学习样本数据集，通过匹配一些参数来建立一个模型，主要用来训练模型。类比考研前做的解题大全。</li><li>验证集（validation set） —— 对学习出来的模型，调整模型的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。类比 考研之前做的模拟考试。</li><li>测试集（Test set） —— 测试训练好的模型的分辨能力。类比 考研。这次真的是一考定终身。</li></ul><h3 id="模型拟合程度"><a href="#模型拟合程度" class="headerlink" title="模型拟合程度"></a>模型拟合程度</h3><ul><li>欠拟合（Underfitting）：模型没有很好地捕捉到数据特征，不能够很好地拟合数据，对训练样本的一般性质尚未学好。类比，光看书不做题觉得自己什么都会了，上了考场才知道自己啥都不会。</li><li>过拟合（Overfitting）：模型把训练样本学习“太好了”，可能把一些训练样本自身的特性当做了所有潜在样本都有的一般性质，导致泛化能力下降。类比，做课后题全都做对了，超纲题也都认为是考试必考题目，上了考场还是啥都不会。 </li></ul><p>通俗来说，欠拟合和过拟合都可以用一句话来说，欠拟合就是：“你太天真了！”，过拟合就是：“你想太多了！”。</p><h3 id="常见的模型指标"><a href="#常见的模型指标" class="headerlink" title="常见的模型指标"></a>常见的模型指标</h3><ul><li>正确率 —— 提取出的正确信息条数 / 提取出的信息条数</li><li>召回率 —— 提取出的正确信息条数 / 样本中的信息条数</li><li>F 值 —— 正确率 * 召回率 * 2 / （正确率 + 召回率）（F值即为正确率和召回率的调和平均值）</li></ul><p>举个例子如下：</p><p>举个例子如下：<br>某池塘有 1400 条鲤鱼，300 只虾，300 只乌龟。现在以捕鲤鱼为目的。撒了一张网，逮住了 700 条鲤鱼，200 只<br>虾， 100 只乌龟。那么这些指标分别如下：<br>正确率 = 700 / (700 + 200 + 100) = 70%<br>召回率 = 700 / 1400 = 50%<br>F 值 = 70% * 50% * 2 / (70% + 50%) = 58.3%</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul><li>分类问题 —— 说白了就是将一些未知类别的数据分到现在已知的类别中去。比如，根据你的一些信息，判断你是高富帅，还是穷屌丝。评判分类效果好坏的三个指标就是上面介绍的三个指标：正确率，召回率，F值。</li><li>回归问题 —— 对数值型连续随机变量进行预测和建模的监督学习算法。回归往往会通过计算 误差（Error）来确定模型的精确性。</li><li>聚类问题 —— 聚类是一种无监督学习任务，该算法基于数据的内部结构寻找观察样本的自然族群（即集群）。聚类问题的标准一般基于距离：簇内距离（Intra-cluster Distance） 和 簇间距离（Inter-cluster Distance） 。簇内距离是越小越好，也就是簇内的元素越相似越好；而簇间距离越大越好，也就是说簇间（不同簇）元素越不相同越好。一般的，衡量聚类问题会给出一个结合簇内距离和簇间距离的公式。</li></ul><p>下面这个图可以比较直观地展示出来：</p><p><img src="ml_add_1.jpg"></p><h3 id="特征工程的一些小东西"><a href="#特征工程的一些小东西" class="headerlink" title="特征工程的一些小东西"></a>特征工程的一些小东西</h3><ul><li><p>特征选择 —— 也叫特征子集选择（FSS，Feature Subset Selection）。是指从已有的 M 个特征（Feature）中选择 N 个特征使得系统的特定指标最优化，是从原始特征中选择出一些最有效特征以降低数据集维度的过程，是提高算法性能的一个重要手段，也是模式识别中关键的数据预处理步骤。</p></li><li><p>特征提取 —— 特征提取是计算机视觉和图像处理中的一个概念。它指的是使用计算机提取图像信息，决定每个图像的点是否属于一个图像特征。特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点，连续的曲线或者连续的区域。</p></li></ul><p>下面给出一个特征工程的图：</p><p><img src="ml_add_2.jpg"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>十大经典排序算法整理汇总（附代码）</title>
      <link href="/2020/02/16/sort-algorithms/"/>
      <url>/2020/02/16/sort-algorithms/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文整理并总结了十大经典的排序算法（冒泡排序、选择排序、插入排序、快速排序、归并排序、希尔排序、计数排序、基数排序、桶排序、堆排序）的时间复杂度、空间复杂度等性质。</p><p><strong>本文并不会详细讲解每种排序算法的原理</strong>，网上有很多很好的教程，大家可以自己去搜了看。</p><p>最后我还亲自手写了十种排序算法的 c++ 代码，大家可以用来通过 <a href="https://leetcode-cn.com/problems/sort-an-array/" title="LeetCode 912. 排序数组">LeetCode 912. 排序数组</a> 这道题。</p><h2 id="性质汇总"><a href="#性质汇总" class="headerlink" title="性质汇总"></a>性质汇总</h2><blockquote><p>如果发现表中有错误，请留言告知。</p></blockquote><table><thead><tr><th>算法</th><th>最好</th><th>最坏</th><th>平均</th><th>空间</th><th align="center">稳定性</th><th align="center">是否基于比较</th></tr></thead><tbody><tr><td>冒泡排序</td><td>$O(n)$</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(1)$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td>选择排序</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(1)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr><tr><td>插入排序</td><td>$O(n)$</td><td>$O(n^2)$</td><td>$O(n^2)$</td><td>$O(1)$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td>快速排序</td><td>$O(n\log n)$</td><td>$O(n^2)$</td><td>$O(n\log n)$</td><td>$O(\log n)$~$O(n)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr><tr><td>归并排序</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(n)$</td><td align="center">$\checkmark$</td><td align="center">$\checkmark$</td></tr><tr><td>希尔排序</td><td>$O(n^{1.3})$</td><td>$O(n^2)$</td><td>$O(n\log n)$~$O(n^2)$</td><td>$O(1)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr><tr><td>计数排序</td><td>$O(n+k)$</td><td>$O(n+k)$</td><td>$O(n+k)$</td><td>$O(n+k)$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td>基数排序</td><td>$O(nk)$</td><td>$O(nk)$</td><td>$O(nk)$</td><td>$O(n+k)$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td>桶排序</td><td>$O(n)$</td><td>$O(n)$</td><td>$O(n)$</td><td>$O(n+m)$</td><td align="center">$\checkmark$</td><td align="center">$\times$</td></tr><tr><td>堆排序</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(n\log n)$</td><td>$O(1)$</td><td align="center">$\times$</td><td align="center">$\checkmark$</td></tr></tbody></table><blockquote><p>如果表格显示有问题的话，还可以直接看下面的汇总图：</p></blockquote><p><img src="1.png" alt="十大经典排序算法性质汇总"></p><h3 id="维基百科"><a href="#维基百科" class="headerlink" title="维基百科"></a>维基百科</h3><p>我觉得还是英文维基百科讲的比较详细、严谨。如果大家看的比较累的话，可以自己百度搜索相应的教程。</p><p><strong>冒泡排序</strong><br><a href="https://en.wikipedia.org/wiki/Bubble_sort">https://en.wikipedia.org/wiki/Bubble_sort</a></p><p><strong>选择排序</strong><br><a href="https://en.wikipedia.org/wiki/Selection_sort">https://en.wikipedia.org/wiki/Selection_sort</a></p><p><strong>插入排序</strong><br><a href="https://en.wikipedia.org/wiki/Insertion_sort">https://en.wikipedia.org/wiki/Insertion_sort</a></p><p><strong>快速排序</strong><br><a href="https://en.wikipedia.org/wiki/Quicksort">https://en.wikipedia.org/wiki/Quicksort</a></p><p><strong>归并排序</strong><br><a href="https://en.wikipedia.org/wiki/Merge_sort">https://en.wikipedia.org/wiki/Merge_sort</a></p><p><strong>希尔排序</strong><br><a href="https://en.wikipedia.org/wiki/Shellsort">https://en.wikipedia.org/wiki/Shellsort</a></p><p><strong>计数排序</strong><br><a href="https://en.wikipedia.org/wiki/Counting_sort">https://en.wikipedia.org/wiki/Counting_sort</a></p><p><strong>基数排序</strong><br><a href="https://en.wikipedia.org/wiki/Radix_sort">https://en.wikipedia.org/wiki/Radix_sort</a></p><p><strong>桶排序</strong><br><a href="https://en.wikipedia.org/wiki/Bucket_sort">https://en.wikipedia.org/wiki/Bucket_sort</a></p><p><strong>堆排序</strong><br><a href="https://en.wikipedia.org/wiki/Heapsort">https://en.wikipedia.org/wiki/Heapsort</a></p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>所有的排序算法接口都是相同的，也就是 <code>vector&lt;int&gt; xxxSort(vector&lt;int&gt;&amp; nums)</code> 。只需要你传入一个 <code>vector&lt;int&gt;</code> 类型的数组，就能返回排序后的结果。</p><p>运行下来可以发现，桶排序速度是比较快的。而冒泡排序、选择排序和插入排序因为时间复杂度太高无法通过本题，基数排序因为无法处理负数也不能通过本题。</p><pre class=" language-cpp"><code class="language-cpp"><span class="token keyword">class</span> <span class="token class-name">Solution</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token keyword">public</span><span class="token operator">:</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">sortArray</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> <span class="token function">quickSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 冒泡排序（超时）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">bubbleSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> n<span class="token number">-2</span><span class="token punctuation">;</span> j <span class="token operator">>=</span> i<span class="token punctuation">;</span> <span class="token operator">--</span>j<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">></span> nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 选择排序（超时）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">selectSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> idx <span class="token operator">=</span> i<span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> i<span class="token punctuation">;</span> j <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    idx <span class="token operator">=</span> j<span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 插入排序（超时）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">insertSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> i<span class="token punctuation">;</span> j <span class="token operator">></span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token operator">--</span>j<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>j<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 快速排序（24 ms）</span>    <span class="token keyword">void</span> <span class="token function">qSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">,</span> <span class="token keyword">int</span> l<span class="token punctuation">,</span> <span class="token keyword">int</span> r<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>l <span class="token operator">>=</span> r<span class="token punctuation">)</span> <span class="token keyword">return</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> m <span class="token operator">=</span> l<span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> l<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> r<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>m<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>m<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">qSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> m<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">qSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">quickSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token function">qSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 归并排序（192 ms）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">mSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">,</span> <span class="token keyword">int</span> l<span class="token punctuation">,</span> <span class="token keyword">int</span> r<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span>l <span class="token operator">>=</span> r<span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>nums<span class="token punctuation">[</span>l<span class="token punctuation">]</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> m <span class="token operator">=</span> l<span class="token operator">+</span><span class="token punctuation">(</span>r<span class="token operator">-</span>l<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> lnums <span class="token operator">=</span> <span class="token function">mSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> l<span class="token punctuation">,</span> m<span class="token punctuation">)</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> rnums <span class="token operator">=</span> <span class="token function">mSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> res<span class="token punctuation">;</span>        <span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;=</span> m<span class="token operator">-</span>l <span class="token operator">&amp;&amp;</span> j <span class="token operator">&lt;=</span> r<span class="token operator">-</span>m<span class="token number">-1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>lnums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;</span> rnums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>lnums<span class="token punctuation">[</span>i<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>rnums<span class="token punctuation">[</span>j<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;=</span> m<span class="token operator">-</span>l<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>lnums<span class="token punctuation">[</span>i<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>j <span class="token operator">&lt;=</span> r<span class="token operator">-</span>m<span class="token number">-1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>rnums<span class="token punctuation">[</span>j<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> res<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">mergeSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        nums <span class="token operator">=</span> <span class="token function">mSort</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 归并排序 + 非递归（80 ms）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">mergeSortNR</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> len <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> len <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> len <span class="token operator">&lt;&lt;=</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> l <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> l <span class="token operator">&lt;</span> n<span class="token operator">-</span>len<span class="token punctuation">;</span> l <span class="token operator">+</span><span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>len<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">int</span> m <span class="token operator">=</span> l<span class="token operator">+</span>len<span class="token number">-1</span><span class="token punctuation">;</span>                <span class="token keyword">int</span> r <span class="token operator">=</span> <span class="token function">min</span><span class="token punctuation">(</span>n<span class="token number">-1</span><span class="token punctuation">,</span> l<span class="token operator">+</span><span class="token number">2</span><span class="token operator">*</span>len<span class="token number">-1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> res<span class="token punctuation">;</span>                <span class="token keyword">int</span> i <span class="token operator">=</span> l<span class="token punctuation">,</span> j <span class="token operator">=</span> m<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span>                <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;=</span> m <span class="token operator">&amp;&amp;</span> j <span class="token operator">&lt;=</span> r<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span> <span class="token keyword">else</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                        res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token keyword">while</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;=</span> m<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token keyword">while</span> <span class="token punctuation">(</span>j <span class="token operator">&lt;=</span> r<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token operator">++</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> l<span class="token punctuation">;</span> i <span class="token operator">&lt;=</span> r<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> res<span class="token punctuation">[</span>i<span class="token operator">-</span>l<span class="token punctuation">]</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 希尔排序（40 ms）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">shellSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> gap <span class="token operator">=</span> n<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">;</span> gap <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">;</span> gap <span class="token operator">/</span><span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> gap<span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> i<span class="token punctuation">;</span> j<span class="token operator">-</span>gap <span class="token operator">>=</span> <span class="token number">0</span> <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>j<span class="token operator">-</span>gap<span class="token punctuation">]</span> <span class="token operator">></span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span> j <span class="token operator">-</span><span class="token operator">=</span> gap<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                    <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>j<span class="token operator">-</span>gap<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 计数排序（32 ms）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">countSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>n<span class="token punctuation">)</span> <span class="token keyword">return</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> minv <span class="token operator">=</span> <span class="token operator">*</span><span class="token function">min_element</span><span class="token punctuation">(</span>nums<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nums<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> maxv <span class="token operator">=</span> <span class="token operator">*</span><span class="token function">max_element</span><span class="token punctuation">(</span>nums<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nums<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> m <span class="token operator">=</span> maxv<span class="token operator">-</span>minv<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">count</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            count<span class="token punctuation">[</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">-</span>minv<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> res<span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> m<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> count<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                res<span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>i<span class="token operator">+</span>minv<span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> res<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 基数排序（不适用于负数）</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">radixSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> maxv <span class="token operator">=</span> <span class="token operator">*</span><span class="token function">max_element</span><span class="token punctuation">(</span>nums<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nums<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> maxd <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>maxv <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            maxv <span class="token operator">/</span><span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>            maxd<span class="token operator">++</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">rank</span><span class="token punctuation">(</span>n<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> base <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span>maxd <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            count<span class="token punctuation">.</span><span class="token function">assign</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                count<span class="token punctuation">[</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">/</span>base<span class="token punctuation">)</span><span class="token operator">%</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                count<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span><span class="token operator">=</span> count<span class="token punctuation">[</span>i<span class="token number">-1</span><span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> n<span class="token number">-1</span><span class="token punctuation">;</span> i <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token operator">--</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                rank<span class="token punctuation">[</span><span class="token operator">--</span>count<span class="token punctuation">[</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">/</span>base<span class="token punctuation">)</span><span class="token operator">%</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> rank<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>            maxd<span class="token operator">--</span><span class="token punctuation">;</span>            base <span class="token operator">*</span><span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 桶排序 (20 ms)</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">bucketSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> maxv <span class="token operator">=</span> <span class="token operator">*</span><span class="token function">max_element</span><span class="token punctuation">(</span>nums<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nums<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> minv <span class="token operator">=</span> <span class="token operator">*</span><span class="token function">min_element</span><span class="token punctuation">(</span>nums<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nums<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> bs <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> m <span class="token operator">=</span> <span class="token punctuation">(</span>maxv<span class="token operator">-</span>minv<span class="token punctuation">)</span><span class="token operator">/</span>bs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span>        vector<span class="token operator">&lt;</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token operator">></span> <span class="token function">bucket</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> n<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            bucket<span class="token punctuation">[</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">-</span>minv<span class="token punctuation">)</span><span class="token operator">/</span>bs<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">push_back</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> idx <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> m<span class="token punctuation">;</span> <span class="token operator">++</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> sz <span class="token operator">=</span> bucket<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            bucket<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token function">quickSort</span><span class="token punctuation">(</span>bucket<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> j <span class="token operator">&lt;</span> sz<span class="token punctuation">;</span> <span class="token operator">++</span>j<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>                nums<span class="token punctuation">[</span>idx<span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> bucket<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">;</span>            <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token comment" spellcheck="true">// 堆排序（32 ms）</span>    <span class="token keyword">void</span> <span class="token function">adjust</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">,</span> <span class="token keyword">int</span> p<span class="token punctuation">,</span> <span class="token keyword">int</span> s<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>p<span class="token operator">+</span><span class="token number">1</span> <span class="token operator">&lt;</span> s<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> c1 <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>p<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> c2 <span class="token operator">=</span> <span class="token number">2</span><span class="token operator">*</span>p<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">;</span>            <span class="token keyword">int</span> c <span class="token operator">=</span> <span class="token punctuation">(</span>c2<span class="token operator">&lt;</span>s <span class="token operator">&amp;&amp;</span> nums<span class="token punctuation">[</span>c2<span class="token punctuation">]</span><span class="token operator">></span>nums<span class="token punctuation">[</span>c1<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">?</span> c2 <span class="token operator">:</span> c1<span class="token punctuation">;</span>            <span class="token keyword">if</span> <span class="token punctuation">(</span>nums<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token operator">></span> nums<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token keyword">else</span> <span class="token keyword">break</span><span class="token punctuation">;</span>            p <span class="token operator">=</span> c<span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>    vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span> <span class="token function">heapSort</span><span class="token punctuation">(</span>vector<span class="token operator">&lt;</span><span class="token keyword">int</span><span class="token operator">></span><span class="token operator">&amp;</span> nums<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>        <span class="token keyword">int</span> n <span class="token operator">=</span> nums<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> n<span class="token operator">/</span><span class="token number">2</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">>=</span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token operator">--</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token function">adjust</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> i<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> n<span class="token number">-1</span><span class="token punctuation">;</span> i <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">;</span> <span class="token operator">--</span>i<span class="token punctuation">)</span> <span class="token operator">&amp;</span>#<span class="token number">123</span><span class="token punctuation">;</span>            <span class="token function">swap</span><span class="token punctuation">(</span>nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>            <span class="token function">adjust</span><span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>        <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span>        <span class="token keyword">return</span> nums<span class="token punctuation">;</span>    <span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token operator">&amp;</span>#<span class="token number">125</span><span class="token punctuation">;</span><span class="token punctuation">;</span></code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 编程算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> leetcode </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于改进的 PageRank 算法的社交网络意见领袖影响力研究</title>
      <link href="/2019/12/05/pagerank/"/>
      <url>/2019/12/05/pagerank/</url>
      
        <content type="html"><![CDATA[<h1 id="基于改进的-PageRank-算法的社交网络意见领袖影响力研究"><a href="#基于改进的-PageRank-算法的社交网络意见领袖影响力研究" class="headerlink" title="基于改进的 PageRank 算法的社交网络意见领袖影响力研究"></a>基于改进的 PageRank 算法的社交网络意见领袖影响力研究</h1><p><img src="%E5%B9%BB%E7%81%AF%E7%89%872.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%873.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%875.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%876.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%877.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%879.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8710.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8711.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8712.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8713.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8714.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8715.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8716.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8717.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8718.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8719.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8720.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8721.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8722.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8723.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8724.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8725.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8726.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8727.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8728.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8729.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8730.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8731.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8732.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8733.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8734.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8735.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8736.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8737.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8739.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8740.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8741.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8742.JPG" alt="PageRank"></p><p><img src="%E5%B9%BB%E7%81%AF%E7%89%8743.JPG" alt="PageRank"></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 复杂网络&amp;社交网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> 复杂网络 </tag>
            
            <tag> 社交网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归</title>
      <link href="/2019/10/22/xian-xing-hui-gui/"/>
      <url>/2019/10/22/xian-xing-hui-gui/</url>
      
        <content type="html"><![CDATA[<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6_1</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token punctuation">,</span>linear_model<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error<span class="token punctuation">,</span>r2_score<span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pdos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file"</span><span class="token punctuation">)</span>diabetes_X <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"diabetes_X.csv"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">.</span>values  <span class="token comment" spellcheck="true">##442*10</span>diabetes_y <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"diabetes_y.csv"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true">##csv默认读入数据维度为2 ndim=2，转为ndim=1</span><span class="token comment" spellcheck="true"># diabetes_X = diabetes_X[:, np.newaxis, 2] # 只取出第二列数据建模</span><span class="token comment" spellcheck="true"># 输入特征上拆分训练集和测试集</span>diabetes_X_train <span class="token operator">=</span> diabetes_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">]</span>diabetes_X_test <span class="token operator">=</span> diabetes_X<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">##目标特征上拆分训练集和测试集</span>diabetes_y_train <span class="token operator">=</span> diabetes_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">]</span>diabetes_y_test <span class="token operator">=</span> diabetes_y<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#生成线性回归模型对象</span>regr <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## 训练模型</span>regr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>diabetes_X_train<span class="token punctuation">,</span>diabetes_y_train<span class="token punctuation">)</span><span class="token comment" spellcheck="true">##测试集上预测</span>diabetes_y_pred <span class="token operator">=</span> regr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>diabetes_X_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true">##系数</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Coefficients:\n'</span><span class="token punctuation">,</span>regr<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># The mean squared error</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Mean squared error: %.2f'</span>      <span class="token operator">%</span> mean_squared_error<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># The coefficient of determination: 1 is perfect prediction</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Coefficient of determination: %.2f'</span>      <span class="token operator">%</span> r2_score<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span> diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Coefficients: [ 3.03499549e-01 -2.37639315e+02  5.10530605e+02  3.27736980e+02 -8.14131709e+02  4.92814588e+02  1.02848452e+02  1.84606489e+02  7.43519617e+02  7.60951722e+01]Mean squared error: 2004.57Coefficient of determination: 0.59</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6_2</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_modelX <span class="token operator">=</span> <span class="token number">1.0</span><span class="token operator">/</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token operator">+</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>y <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>n_alphas <span class="token operator">=</span> <span class="token number">200</span>alpha <span class="token operator">=</span> np<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>n_alphas<span class="token punctuation">)</span>coefs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> a <span class="token keyword">in</span> alpha<span class="token punctuation">:</span>    ridge <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>Ridge<span class="token punctuation">(</span>alpha<span class="token operator">=</span>a<span class="token punctuation">,</span>fit_intercept<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>    ridge<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>    coefs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>ridge<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span><span class="token string">'text.usetex'</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span><span class="token string">'font.family'</span><span class="token punctuation">:</span> <span class="token string">'stixgeneral'</span><span class="token punctuation">,</span><span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span> <span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span><span class="token comment" spellcheck="true"># plt.rcParams['axes.unicode_minus']=False</span>ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>alpha<span class="token punctuation">,</span>coefs<span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_xscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span>ax<span class="token punctuation">.</span>get_xlim<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'alpha'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Ridge coefficients as a function of the regularization"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'tight'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_1_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6_4</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LassoCV<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_regressionX<span class="token punctuation">,</span> y <span class="token operator">=</span> make_regression<span class="token punctuation">(</span>noise<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>reg <span class="token operator">=</span> LassoCV<span class="token punctuation">(</span>cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>reg<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>reg<span class="token punctuation">.</span>alpha_reg<span class="token punctuation">.</span>alphas_</code></pre><pre><code>array([6.92751635e+01, 6.46062493e+01, 6.02520044e+01, 5.61912209e+01,       5.24041207e+01, 4.88722584e+01, 4.55784317e+01, 4.25065980e+01,       3.96417955e+01, 3.69700712e+01, 3.44784121e+01, 3.21546825e+01,       2.99875645e+01, 2.79665031e+01, 2.60816544e+01, 2.43238381e+01,       2.26844929e+01, 2.11556340e+01, 1.97298150e+01, 1.84000915e+01,       1.71599870e+01, 1.60034613e+01, 1.49248815e+01, 1.39189945e+01,       1.29809008e+01, 1.21060316e+01, 1.12901256e+01, 1.05292089e+01,       9.81957544e+00, 9.15776892e+00, 8.54056594e+00, 7.96496038e+00,       7.42814871e+00, 6.92751635e+00, 6.46062493e+00, 6.02520044e+00,       5.61912209e+00, 5.24041207e+00, 4.88722584e+00, 4.55784317e+00,       4.25065980e+00, 3.96417955e+00, 3.69700712e+00, 3.44784121e+00,       3.21546825e+00, 2.99875645e+00, 2.79665031e+00, 2.60816544e+00,       2.43238381e+00, 2.26844929e+00, 2.11556340e+00, 1.97298150e+00,       1.84000915e+00, 1.71599870e+00, 1.60034613e+00, 1.49248815e+00,       1.39189945e+00, 1.29809008e+00, 1.21060316e+00, 1.12901256e+00,       1.05292089e+00, 9.81957544e-01, 9.15776892e-01, 8.54056594e-01,       7.96496038e-01, 7.42814871e-01, 6.92751635e-01, 6.46062493e-01,       6.02520044e-01, 5.61912209e-01, 5.24041207e-01, 4.88722584e-01,       4.55784317e-01, 4.25065980e-01, 3.96417955e-01, 3.69700712e-01,       3.44784121e-01, 3.21546825e-01, 2.99875645e-01, 2.79665031e-01,       2.60816544e-01, 2.43238381e-01, 2.26844929e-01, 2.11556340e-01,       1.97298150e-01, 1.84000915e-01, 1.71599870e-01, 1.60034613e-01,       1.49248815e-01, 1.39189945e-01, 1.29809008e-01, 1.21060316e-01,       1.12901256e-01, 1.05292089e-01, 9.81957544e-02, 9.15776892e-02,       8.54056594e-02, 7.96496038e-02, 7.42814871e-02, 6.92751635e-02])</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6-3 超参数取值（正则化系数）分析</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error<span class="token punctuation">,</span>r2_score<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> linear_model<span class="token keyword">import</span> os<span class="token keyword">import</span> mathos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file\第6讲_数据集"</span><span class="token punctuation">)</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"winequality-red.csv"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">';'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"winequality-red.csv"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>valuesX <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>train_indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i<span class="token operator">%</span><span class="token number">3</span><span class="token operator">!=</span><span class="token number">0</span><span class="token punctuation">]</span>test_indices <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> i<span class="token operator">%</span><span class="token number">3</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">]</span>X_train <span class="token operator">=</span> X<span class="token punctuation">[</span>train_indices<span class="token punctuation">]</span>y_train <span class="token operator">=</span> y<span class="token punctuation">[</span>train_indices<span class="token punctuation">]</span>X_test <span class="token operator">=</span> X<span class="token punctuation">[</span>test_indices<span class="token punctuation">]</span>y_test <span class="token operator">=</span> y<span class="token punctuation">[</span>test_indices<span class="token punctuation">]</span>alphaList <span class="token operator">=</span> list<span class="token punctuation">(</span>np<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>rmseList <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>r2List <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> a <span class="token keyword">in</span> alphaList<span class="token punctuation">:</span>    ridge <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>Ridge<span class="token punctuation">(</span>alpha<span class="token operator">=</span>a<span class="token punctuation">)</span>    ridge<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>    pred <span class="token operator">=</span> ridge<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>    rmse <span class="token operator">=</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span>    rmseList<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rmse<span class="token punctuation">)</span>    r2List<span class="token punctuation">.</span>append<span class="token punctuation">(</span>r2_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rmseList<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>r2List<span class="token punctuation">)</span>x <span class="token operator">=</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>rmseList<span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>rmseList<span class="token punctuation">,</span><span class="token string">'k'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'-log(alpha)'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Error(rmse)'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><pre><code>[0.6578610918808593, 0.6576172144640243, 0.6575216482641756, 0.6574190680109293, 0.6573941628851252, 0.6573913087155857][0.35552862060828627, 0.35600635940252034, 0.35619351859408976, 0.35639438401189105, 0.3564431467448207, 0.3564487349185034]</code></pre><p><img src="output_3_1.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6_5</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> matplotlib<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LassoCV<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file\第6讲_数据集"</span><span class="token punctuation">)</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"winequality-red.csv"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>valuesX <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>wineModel <span class="token operator">=</span> LassoCV<span class="token punctuation">(</span>cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">'text.usetex'</span><span class="token punctuation">:</span><span class="token boolean">False</span><span class="token punctuation">,</span>    <span class="token string">'font.family'</span><span class="token punctuation">:</span><span class="token string">'stixgeneral'</span><span class="token punctuation">,</span>    <span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span><span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>wineModel<span class="token punctuation">.</span>alphas_<span class="token punctuation">,</span>wineModel<span class="token punctuation">.</span>mse_path_<span class="token punctuation">,</span><span class="token string">':'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>wineModel<span class="token punctuation">.</span>alphas_<span class="token punctuation">,</span>wineModel<span class="token punctuation">.</span>mse_path_<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'Average MSE Across Folds'</span><span class="token punctuation">,</span>linewidth<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>axvline<span class="token punctuation">(</span>wineModel<span class="token punctuation">.</span>alpha_<span class="token punctuation">,</span>linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'CV Estimate of Best alpha'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>semilogx<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>ax<span class="token punctuation">.</span>invert_xaxis<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'alpha'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Mean Square Error'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'tight'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p><img src="output_4_0.png" alt="png"></p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6_6 ElasticNet调用示例</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> ElasticNet<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_regressionX<span class="token punctuation">,</span>y <span class="token operator">=</span> make_regression<span class="token punctuation">(</span>n_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>regr <span class="token operator">=</span>ElasticNet<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>regr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>regr<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>regr<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span></code></pre><pre><code>[18.83816048 64.55968825]1.4512607561654032</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#6_7 多项式特征构造及拟合</span><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> PolynomialFeatures<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npmodel <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'poly'</span><span class="token punctuation">,</span>PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span>LinearRegression<span class="token punctuation">(</span>fit_intercept<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>X <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>y <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">-</span> <span class="token number">2</span><span class="token operator">*</span>x <span class="token operator">+</span> x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">-</span> x<span class="token operator">**</span><span class="token number">3</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>newaxisais<span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span>model<span class="token punctuation">.</span>named_stepst<span class="token punctuation">[</span><span class="token string">'linear'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>coef_array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># poly = PolynomialFeatures(degree=3)</span><span class="token comment" spellcheck="true"># X_poly = poly.fit_transform(X[:,np.newaxis])</span><span class="token comment" spellcheck="true"># reg = LinearRegression(fit_intercept=False).fit(X_poly,y)</span><span class="token comment" spellcheck="true"># reg.coef_</span></code></pre><pre><code>---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-23-2cba805742ae&gt; in &lt;module&gt;      8       9 X = np.arange(5)---&gt; 10 y = 3 - 2*x + x**2 - x**3     11 model = model.fit(x[:,np.newaxisais],y)     12 model.named_stepst['linear'].coef_TypeError: unsupported operand type(s) for *: 'int' and 'range'</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#实验2</span><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> matplotlib<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LassoCV<span class="token keyword">import</span> osos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file\第6讲_数据集"</span><span class="token punctuation">)</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"winequality-red.csv"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>valuesX <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>y <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>X_std <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> X<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span>X<span class="token punctuation">.</span>std<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>y_std <span class="token operator">=</span> <span class="token punctuation">(</span>y <span class="token operator">-</span> y<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span>y<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">## X,y均不标准化</span><span class="token comment" spellcheck="true">##LassoCV拟合，交叉验证折数设置10，其余去默认值</span>wineModel <span class="token operator">=</span>LassoCV<span class="token punctuation">(</span>cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>wineModel_std <span class="token operator">=</span> LassoCV<span class="token punctuation">(</span>cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_std<span class="token punctuation">,</span>y_std<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>min<span class="token punctuation">(</span>wineModel<span class="token punctuation">.</span>mse_path_<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##X,y均标准化</span>wineModel_std <span class="token operator">=</span> LassoCV<span class="token punctuation">(</span>cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_std<span class="token punctuation">,</span>y_std<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>min<span class="token punctuation">(</span>wineModel_std<span class="token punctuation">.</span>mse_path_<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">##X标准化，y不标准化</span>wineModel_s <span class="token operator">=</span> LassoCV<span class="token punctuation">(</span>cv<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_std<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>min<span class="token punctuation">(</span>wineModel_s<span class="token punctuation">.</span>mse_path_<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#结果可视化</span>matplotlib<span class="token punctuation">.</span>rcParams<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>    <span class="token string">'text.usetex'</span><span class="token punctuation">:</span><span class="token boolean">False</span><span class="token punctuation">,</span>    <span class="token string">'font.family'</span><span class="token punctuation">:</span><span class="token string">'stixgeneral'</span><span class="token punctuation">,</span>    <span class="token string">'mathtext.fontset'</span><span class="token punctuation">:</span><span class="token string">'stix'</span><span class="token punctuation">,</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span></code></pre><pre><code>0.43936067309291360.66558492060028130.4338019871536979</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true">#实验三 </span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error<span class="token punctuation">,</span>r2_score<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets<span class="token punctuation">,</span>linear_model<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> os<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> preprocessingos<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>r<span class="token string">"C:\Users\43790\data file\第6讲_数据集"</span><span class="token punctuation">)</span>diabetes_X <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"diabetes_X.csv"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">.</span>valuesdiabetes_X <span class="token operator">=</span> preprocessing<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>diabetes_X<span class="token punctuation">)</span>diabetes_y <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"diabetes_y.csv"</span><span class="token punctuation">,</span>header<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">.</span>values<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>diabetes_X_train <span class="token operator">=</span> diabetes_X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">]</span>diabetes_X_test <span class="token operator">=</span> diabetes_X<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">:</span><span class="token punctuation">]</span>diabetes_y_train <span class="token operator">=</span> diabetes_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">]</span>diabetes_y_test <span class="token operator">=</span> diabetes_y<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">20</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true">#生成线性回归模型对象</span>eNet <span class="token operator">=</span> linear_model<span class="token punctuation">.</span>ElasticNet<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true">#训练模型</span>eNet<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>diabetes_X_train<span class="token punctuation">,</span>diabetes_y_train<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#测试机上预测</span>diabetes_y_pred <span class="token operator">=</span> eNet<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>diabetes_X_test<span class="token punctuation">)</span><span class="token comment" spellcheck="true">#系数</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Coefficients:\n'</span><span class="token punctuation">,</span>eNet<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Mean squared error:%.2f'</span>     <span class="token operator">%</span> mean_squared_error<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span>diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Coefficient of determination:%.2f'</span>     <span class="token operator">%</span> r2_score<span class="token punctuation">(</span>diabetes_y_test<span class="token punctuation">,</span>diabetes_y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>Coefficients: [ 0.93589839 -5.66546804 17.8357516  11.47502646 -0.36761974 -2.26769739 -8.27362297  5.46316595 15.13823101  5.34079096]Mean squared error:2380.82Coefficient of determination:0.51</code></pre><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
            <tag> 学习笔记 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
