<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="GMN-complement-tensorflow, SUIBE DeepLearning 张国祥 guoxiang 上外贸 数据分析 深度学习 上海对外经贸大学">
    <meta name="description" content="上海对外经贸大学 | 管理科学与工程 | 图网络、数据分析">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>GMN-complement-tensorflow | Singularity&#39;s Blog</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.1.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Singularity&#39;s Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Singularity&#39;s Blog</div>
        <div class="logo-desc">
            
            上海对外经贸大学 | 管理科学与工程 | 图网络、数据分析
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/17.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">GMN-complement-tensorflow</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">机器学习</span>
                            </a>
                        
                            <a href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/">
                                <span class="chip bg-color">图模型</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">论文学习</span>
                            </a>
                        
                            <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                <span class="chip bg-color">图神经网络</span>
                            </a>
                        
                            <a href="/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">
                                <span class="chip bg-color">论文复现</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%9B%BE%E6%A8%A1%E5%9E%8B/" class="post-category">
                                图模型
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-01-16
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    11.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    70 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <pre class=" language-python"><code class="language-python">注：该代码为DeepMind公布的基于Tensorflow实现的GMN模型，理论与实现相配合，若需基于pytorch框架的GMN模型实现代码，请关注我的GitHub。
Refference：DeepMind</code></pre>
<h1 id="Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects"><a href="#Graph-Matching-Networks-for-Learning-the-Similarity-of-Graph-Structured-Objects" class="headerlink" title="Graph Matching Networks for Learning the Similarity of Graph Structured Objects"></a>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</h1><p>This is the example code for our ICML 2019 paper.  Please refer to the paper for more details:</p>
<blockquote>
<p>Yujia Li, Chenjie Gu, Thomas Dullien, Oriol Vinyals, Pushmeet Kohli.  <em>Graph Matching Networks for Learning the Similarity of Graph Structured Objects</em>.  ICML 2019.  <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.12787">[arXiv]</a></p>
</blockquote>
<h2 id="Graph-similarity-learning"><a href="#Graph-similarity-learning" class="headerlink" title="Graph similarity learning"></a>Graph similarity learning</h2><p>Our goal is to learn a similarity function between graphs.  Given two graphs $G_1, G_2$, a graph similarity model can be written as a function $f(G_1, G_2)$ that computes a scalar similarity value.</p>
<p>In this project we build models to learn such a similarity function based on examples of similar / dissimilar pairs or triplets.  Because of learning, our model can adapt to different notions of similarity and to different types of graph structure, as long as training data is available.</p>
<p>In the following we will sometimes use the term “distance” and say the model learns a “distance function” $d(G_1, G_2)$ between graphs when convenient.  But this is just the opposite of a similarity function, and you may simply say $f(G_1, G_2) = - d(G_1, G_2)$.</p>
<h2 id="Some-dependencies-and-imports"><a href="#Some-dependencies-and-imports" class="headerlink" title="Some dependencies and imports"></a>Some dependencies and imports</h2><p>If you want to run the notebook locally, make sure you have all the dependencies first.  You can use the following command</p>
<pre><code>pip3 install --user -r requirements.txt</code></pre>
<p>Note the code should work for both python 3 and 2, but python 3 is recommended.</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Let's disable all the warnings first</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>simplefilter<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span></code></pre>
<p>These are all the dependencies that will be used in this notebook.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> abc
<span class="token keyword">import</span> collections
<span class="token keyword">import</span> contextlib
<span class="token keyword">import</span> copy
<span class="token keyword">import</span> random
<span class="token keyword">import</span> time

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> six
<span class="token keyword">import</span> sonnet <span class="token keyword">as</span> snt
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf</code></pre>
<h2 id="The-models"><a href="#The-models" class="headerlink" title="The models"></a>The models</h2><h3 id="The-graph-embedding-model"><a href="#The-graph-embedding-model" class="headerlink" title="The graph embedding model"></a>The graph embedding model</h3><p>The simpler variant of our model is based on embedding each graph <strong>independently</strong> into a vector and then use an existing distance (or similarity) metric in the vector space to compute the distance between graphs.  More concretely, we define</p>
<p>$$d(G_1, G_2) = d_H(embed(G_1), embed(G_2)),$$</p>
<p>where $embed$ is a model that maps any graph $G$ into an $H$-dimensional vector, and $d_H$ is a distance metric in that vector space.  Typical examples are Euclidean distance in $\mathbb{R}^H$, i.e. $d_H(x, y) = \sqrt{\sum_{i=1}^H (x_i - y_i)^2}$, or Hamming distance in $H$-dimensional space of binary vectors, i.e. $d_H(x, y)=\sum_{i=1}^H \mathbb{I}[x_i \ne y_i]$.</p>
<p>Each graph input contains a set of nodes $V$ and edges $E$.  Each node $i\in V$ may have a feature vector $x_i$ associated with it, and each edge $(i, j)\in E$ may also have a feature vector $x_{ij}$ encoding e.g. edge type or attributes.  The embedding model will therefore jointly reason about the graph structure as well as the graph features to come up with an embedding that reflects the notion of similarity described by the training examples.</p>
<p>The embedding model is composed of 3 parts:</p>
<ol>
<li><p>An encoder that maps $x_i$ and $x_{ij}$ into a nice hidden representation space.  Here we use separate MLPs (fully connected neural nets) for node and edge representations:<br>$$\begin{array}{rcl}<br>h_i^{(0)} &amp;=&amp; \mathrm{MLP_{node}}(x_i) \<br>e_{ij} &amp;=&amp; \mathrm{MLP_{edge}}(x_{ij})<br>\end{array}<br>$$</p>
</li>
<li><p>A graph neural network (GNN) that communicates information across the graph and computes node representations that encode local neighborhood structure and semantics.  More concretely, the GNN computes node representations through an iterative message passing process.  In the $t$-th round of message passing, we compute a message vector on each edge, and then each node aggregates all the incoming messages and updates its own representation:<br>$$\begin{array}{rcl}<br>m_{i\rightarrow j} &amp;=&amp; f_\mathrm{message}(h_i^{(t)}, h_j^{(t)}, e_{ij}) \<br>h_i^{(t+1)} &amp;=&amp; f_\mathrm{node}(h_i^{(t)}, \sum_{j:(j,i)\in E} m_{j\rightarrow i})<br>\end{array}<br>$$<br>Here both $f_\mathrm{message}$ and $f_\mathrm{node}$ are neural modules.  We use MLPs for $f_\mathrm{message}$, while $f_\mathrm{node}$ can also be MLPs or even recurrent neural network cores like LSTMs or GRUs.  The GNNs have the nice property of being equivariant to node permutations, and nodes on isomorphic graphs (with the same node and edge features) will have the same representations regardless of the ordering.</p>
</li>
<li><p>After we obtained the final node representations after $T$ rounds of message passing, we aggregate across them to get graph representations $h_G=f_G({h_i^{(T)}}<em>{i\in V})$.  This could be implemented by a simple sum that reduces the node representations into a single vector and then transform it:<br>$$h_G = \mathrm{MLP_G}\left(\sum</em>{i\in V} h_i^{(T)}\right).$$<br>We used the following gated aggregation module proposed in <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.05493">Li et al., 2015</a> which we found to work consistently better:<br>$$h_G = \mathrm{MLP_G}\left(\sum_{i\in V} \sigma(\mathrm{MLP_{gate}}(h_i^{(T)})) \odot \mathrm{MLP}(h_i^{(T)})\right).$$<br>The key to this function is to make sure it is invariant to node orderings, both the above forms satisfy this condition.  The gated variant gives the model the capacity to explicitly modulate each node’s contribution to the graph representation.</p>
</li>
</ol>
<h4 id="The-graph-encoder"><a href="#The-graph-encoder" class="headerlink" title="The graph encoder"></a>The graph encoder</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphEncoder</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Encoder module that projects node and edge features to some embeddings."""</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               node_hidden_sizes<span class="token operator">=</span>None<span class="token punctuation">,</span>
               edge_hidden_sizes<span class="token operator">=</span>None<span class="token punctuation">,</span>
               name<span class="token operator">=</span><span class="token string">'graph-encoder'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Constructor.

    Args:
      node_hidden_sizes: if provided should be a list of ints, hidden sizes of
        node encoder network, the last element is the size of the node outputs.
        If not provided, node features will pass through as is.
      edge_hidden_sizes: if provided should be a list of ints, hidden sizes of
        edge encoder network, the last element is the size of the edge outptus.
        If not provided, edge features will pass through as is.
      name: name of this module.
    """</span>
    super<span class="token punctuation">(</span>GraphEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># this also handles the case of an empty list</span>
    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes <span class="token keyword">if</span> node_hidden_sizes <span class="token keyword">else</span> None
    self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token operator">=</span> edge_hidden_sizes

  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_features<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Encode node and edge features.

    Args:
      node_features: [n_nodes, node_feat_dim] float tensor.
      edge_features: if provided, should be [n_edges, edge_feat_dim] float
        tensor.

    Returns:
      node_outputs: [n_nodes, node_embedding_dim] float tensor, node embeddings.
      edge_outputs: if edge_features is not None and edge_hidden_sizes is not
        None, this is [n_edges, edge_embedding_dim] float tensor, edge
        embeddings; otherwise just the input edge_features.
    """</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token keyword">is</span> None<span class="token punctuation">:</span>
      node_outputs <span class="token operator">=</span> node_features
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      node_outputs <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
          self<span class="token punctuation">.</span>_node_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'node-feature-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>node_features<span class="token punctuation">)</span>

    <span class="token keyword">if</span> edge_features <span class="token keyword">is</span> None <span class="token operator">or</span> self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token keyword">is</span> None<span class="token punctuation">:</span>
      edge_outputs <span class="token operator">=</span> edge_features
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      edge_outputs <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
          self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'edge-feature-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>edge_features<span class="token punctuation">)</span>

    <span class="token keyword">return</span> node_outputs<span class="token punctuation">,</span> edge_outputs</code></pre>
<h4 id="The-message-passing-layers"><a href="#The-message-passing-layers" class="headerlink" title="The message passing layers"></a>The message passing layers</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">graph_prop_once</span><span class="token punctuation">(</span>node_states<span class="token punctuation">,</span>
                    from_idx<span class="token punctuation">,</span>
                    to_idx<span class="token punctuation">,</span>
                    message_net<span class="token punctuation">,</span>
                    aggregation_module<span class="token operator">=</span>tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>
                    edge_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""One round of propagation (message passing) in a graph.

  Args:
    node_states: [n_nodes, node_state_dim] float tensor, node state vectors, one
      row for each node.
    from_idx: [n_edges] int tensor, index of the from nodes.
    to_idx: [n_edges] int tensor, index of the to nodes.
    message_net: a network that maps concatenated edge inputs to message
      vectors.
    aggregation_module: a module that aggregates messages on edges to aggregated
      messages for each node.  Should be a callable and can be called like the
      following,
      `aggregated_messages = aggregation_module(messages, to_idx, n_nodes)`,
      where messages is [n_edges, edge_message_dim] tensor, to_idx is the index
      of the to nodes, i.e. where each message should go to, and n_nodes is an
      int which is the number of nodes to aggregate into.
    edge_features: if provided, should be a [n_edges, edge_feature_dim] float
      tensor, extra features for each edge.

  Returns:
    aggregated_messages: an [n_nodes, edge_message_dim] float tensor, the
      aggregated messages, one row for each node.
  """</span>
  from_states <span class="token operator">=</span> tf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">)</span>
  to_states <span class="token operator">=</span> tf<span class="token punctuation">.</span>gather<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> to_idx<span class="token punctuation">)</span>

  edge_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>from_states<span class="token punctuation">,</span> to_states<span class="token punctuation">]</span>
  <span class="token keyword">if</span> edge_features <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
    edge_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>edge_features<span class="token punctuation">)</span>

  edge_inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>edge_inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
  messages <span class="token operator">=</span> message_net<span class="token punctuation">(</span>edge_inputs<span class="token punctuation">)</span>

  <span class="token keyword">return</span> aggregation_module<span class="token punctuation">(</span>messages<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> tf<span class="token punctuation">.</span>shape<span class="token punctuation">(</span>node_states<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">GraphPropLayer</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Implementation of a graph propagation (message passing) layer."""</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               node_state_dim<span class="token punctuation">,</span>
               edge_hidden_sizes<span class="token punctuation">,</span>
               node_hidden_sizes<span class="token punctuation">,</span>
               edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
               node_update_type<span class="token operator">=</span><span class="token string">'residual'</span><span class="token punctuation">,</span>
               use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
               name<span class="token operator">=</span><span class="token string">'graph-net'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Constructor.

    Args:
      node_state_dim: int, dimensionality of node states.
      edge_hidden_sizes: list of ints, hidden sizes for the edge message
        net, the last element in the list is the size of the message vectors.
      node_hidden_sizes: list of ints, hidden sizes for the node update
        net.
      edge_net_init_scale: initialization scale for the edge networks.  This
        is typically set to a small value such that the gradient does not blow
        up.
      node_update_type: type of node updates, one of &amp;#123;mlp, gru, residual&amp;#125;.
      use_reverse_direction: set to True to also propagate messages in the
        reverse direction.
      reverse_dir_param_different: set to True to have the messages computed
        using a different set of parameters than for the forward direction.
      layer_norm: set to True to use layer normalization in a few places.
      name: name of this module.
    """</span>
    super<span class="token punctuation">(</span>GraphPropLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>_node_state_dim <span class="token operator">=</span> node_state_dim
    self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token operator">=</span> edge_hidden_sizes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span>

    <span class="token comment" spellcheck="true"># output size is node_state_dim</span>
    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>node_state_dim<span class="token punctuation">]</span>
    self<span class="token punctuation">.</span>_edge_net_init_scale <span class="token operator">=</span> edge_net_init_scale
    self<span class="token punctuation">.</span>_node_update_type <span class="token operator">=</span> node_update_type

    self<span class="token punctuation">.</span>_use_reverse_direction <span class="token operator">=</span> use_reverse_direction
    self<span class="token punctuation">.</span>_reverse_dir_param_different <span class="token operator">=</span> reverse_dir_param_different

    self<span class="token punctuation">.</span>_layer_norm <span class="token operator">=</span> layer_norm

  <span class="token keyword">def</span> <span class="token function">_compute_aggregated_messages</span><span class="token punctuation">(</span>
      self<span class="token punctuation">,</span> node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Compute aggregated messages for each node.

    Args:
      node_states: [n_nodes, input_node_state_dim] float tensor, node states.
      from_idx: [n_edges] int tensor, from node indices for each edge.
      to_idx: [n_edges] int tensor, to node indices for each edge.
      edge_features: if not None, should be [n_edges, edge_embedding_dim]
        tensor, edge features.

    Returns:
      aggregated_messages: [n_nodes, aggregated_message_dim] float tensor, the
        aggregated messages for each node.
    """</span>
    self<span class="token punctuation">.</span>_message_net <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
        self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span>
        initializers<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
            <span class="token string">'w'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>variance_scaling_initializer<span class="token punctuation">(</span>
                scale<span class="token operator">=</span>self<span class="token punctuation">.</span>_edge_net_init_scale<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'b'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>zeros_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>
        name<span class="token operator">=</span><span class="token string">'message-mlp'</span><span class="token punctuation">)</span>

    aggregated_messages <span class="token operator">=</span> graph_prop_once<span class="token punctuation">(</span>
        node_states<span class="token punctuation">,</span>
        from_idx<span class="token punctuation">,</span>
        to_idx<span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>_message_net<span class="token punctuation">,</span>
        aggregation_module<span class="token operator">=</span>tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>
        edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># optionally compute message vectors in the reverse direction</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_use_reverse_direction<span class="token punctuation">:</span>
      <span class="token keyword">if</span> self<span class="token punctuation">.</span>_reverse_dir_param_different<span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_reverse_message_net <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span>
            initializers<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
                <span class="token string">'w'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>variance_scaling_initializer<span class="token punctuation">(</span>
                    scale<span class="token operator">=</span>self<span class="token punctuation">.</span>_edge_net_init_scale<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token string">'b'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>zeros_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>
            name<span class="token operator">=</span><span class="token string">'reverse-message-mlp'</span><span class="token punctuation">)</span>
      <span class="token keyword">else</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_reverse_message_net <span class="token operator">=</span> self<span class="token punctuation">.</span>_message_net

      reverse_aggregated_messages <span class="token operator">=</span> graph_prop_once<span class="token punctuation">(</span>
          node_states<span class="token punctuation">,</span>
          to_idx<span class="token punctuation">,</span>
          from_idx<span class="token punctuation">,</span>
          self<span class="token punctuation">.</span>_reverse_message_net<span class="token punctuation">,</span>
          aggregation_module<span class="token operator">=</span>tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>
          edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>

      aggregated_messages <span class="token operator">+=</span> reverse_aggregated_messages

    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_layer_norm<span class="token punctuation">:</span>
      aggregated_messages <span class="token operator">=</span> snt<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>aggregated_messages<span class="token punctuation">)</span>

    <span class="token keyword">return</span> aggregated_messages

  <span class="token keyword">def</span> <span class="token function">_compute_node_update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                           node_states<span class="token punctuation">,</span>
                           node_state_inputs<span class="token punctuation">,</span>
                           node_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Compute node updates.

    Args:
      node_states: [n_nodes, node_state_dim] float tensor, the input node
        states.
      node_state_inputs: a list of tensors used to compute node updates.  Each
        element tensor should have shape [n_nodes, feat_dim], where feat_dim can
        be different.  These tensors will be concatenated along the feature
        dimension.
      node_features: extra node features if provided, should be of size
        [n_nodes, extra_node_feat_dim] float tensor, can be used to implement
        different types of skip connections.

    Returns:
      new_node_states: [n_nodes, node_state_dim] float tensor, the new node
        state tensor.

    Raises:
      ValueError: if node update type is not supported.
    """</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_update_type <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'mlp'</span><span class="token punctuation">,</span> <span class="token string">'residual'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      node_state_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_states<span class="token punctuation">)</span>
    <span class="token keyword">if</span> node_features <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
      node_state_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_features<span class="token punctuation">)</span>

    <span class="token keyword">if</span> len<span class="token punctuation">(</span>node_state_inputs<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
      node_state_inputs <span class="token operator">=</span> node_state_inputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      node_state_inputs <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>node_state_inputs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_update_type <span class="token operator">==</span> <span class="token string">'gru'</span><span class="token punctuation">:</span>
      _<span class="token punctuation">,</span> new_node_states <span class="token operator">=</span> snt<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_node_state_dim<span class="token punctuation">)</span><span class="token punctuation">(</span>
          node_state_inputs<span class="token punctuation">,</span> node_states<span class="token punctuation">)</span>
      <span class="token keyword">return</span> new_node_states
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      mlp_output <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
          self<span class="token punctuation">.</span>_node_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'node-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>node_state_inputs<span class="token punctuation">)</span>
      <span class="token keyword">if</span> self<span class="token punctuation">.</span>_layer_norm<span class="token punctuation">:</span>
        mlp_output <span class="token operator">=</span> snt<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>mlp_output<span class="token punctuation">)</span>
      <span class="token keyword">if</span> self<span class="token punctuation">.</span>_node_update_type <span class="token operator">==</span> <span class="token string">'mlp'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> mlp_output
      <span class="token keyword">elif</span> self<span class="token punctuation">.</span>_node_update_type <span class="token operator">==</span> <span class="token string">'residual'</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> node_states <span class="token operator">+</span> mlp_output
      <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown node update type %s'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>_node_update_type<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
             node_states<span class="token punctuation">,</span>
             from_idx<span class="token punctuation">,</span>
             to_idx<span class="token punctuation">,</span>
             edge_features<span class="token operator">=</span>None<span class="token punctuation">,</span>
             node_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Run one propagation step.

    Args:
      node_states: [n_nodes, input_node_state_dim] float tensor, node states.
      from_idx: [n_edges] int tensor, from node indices for each edge.
      to_idx: [n_edges] int tensor, to node indices for each edge.
      edge_features: if not None, should be [n_edges, edge_embedding_dim]
        tensor, edge features.
      node_features: extra node features if provided, should be of size
        [n_nodes, extra_node_feat_dim] float tensor, can be used to implement
        different types of skip connections.

    Returns:
      node_states: [n_nodes, node_state_dim] float tensor, new node states.
    """</span>
    aggregated_messages <span class="token operator">=</span> self<span class="token punctuation">.</span>_compute_aggregated_messages<span class="token punctuation">(</span>
        node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>

    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_compute_node_update<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span>
                                     <span class="token punctuation">[</span>aggregated_messages<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                     node_features<span class="token operator">=</span>node_features<span class="token punctuation">)</span></code></pre>
<h4 id="Graph-aggregator"><a href="#Graph-aggregator" class="headerlink" title="Graph aggregator"></a>Graph aggregator</h4><pre class=" language-python"><code class="language-python">AGGREGATION_TYPE <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
    <span class="token string">'sum'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_sum<span class="token punctuation">,</span>
    <span class="token string">'mean'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_mean<span class="token punctuation">,</span>
    <span class="token string">'sqrt_n'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_sqrt_n<span class="token punctuation">,</span>
    <span class="token string">'max'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>unsorted_segment_max<span class="token punctuation">,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>


<span class="token keyword">class</span> <span class="token class-name">GraphAggregator</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""This module computes graph representations by aggregating from parts."""</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               node_hidden_sizes<span class="token punctuation">,</span>
               graph_transform_sizes<span class="token operator">=</span>None<span class="token punctuation">,</span>
               gated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               aggregation_type<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">,</span>
               name<span class="token operator">=</span><span class="token string">'graph-aggregator'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Constructor.

    Args:
      node_hidden_sizes: the hidden layer sizes of the node transformation nets.
        The last element is the size of the aggregated graph representation.
      graph_transform_sizes: sizes of the transformation layers on top of the
        graph representations.  The last element of this list is the final
        dimensionality of the output graph representations.
      gated: set to True to do gated aggregation, False not to.
      aggregation_type: one of &amp;#123;sum, max, mean, sqrt_n&amp;#125;.
      name: name of this module.
    """</span>
    super<span class="token punctuation">(</span>GraphAggregator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes
    self<span class="token punctuation">.</span>_graph_transform_sizes <span class="token operator">=</span> graph_transform_sizes
    self<span class="token punctuation">.</span>_graph_state_dim <span class="token operator">=</span> node_hidden_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
    self<span class="token punctuation">.</span>_gated <span class="token operator">=</span> gated
    self<span class="token punctuation">.</span>_aggregation_type <span class="token operator">=</span> aggregation_type
    self<span class="token punctuation">.</span>_aggregation_op <span class="token operator">=</span> AGGREGATION_TYPE<span class="token punctuation">[</span>aggregation_type<span class="token punctuation">]</span>

  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node_states<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Compute aggregated graph representations.

    Args:
      node_states: [n_nodes, node_state_dim] float tensor, node states of a
        batch of graphs concatenated together along the first dimension.
      graph_idx: [n_nodes] int tensor, graph ID for each node.
      n_graphs: integer, number of graphs in this batch.

    Returns:
      graph_states: [n_graphs, graph_state_dim] float tensor, graph
        representations, one row for each graph.
    """</span>
    node_hidden_sizes <span class="token operator">=</span> self<span class="token punctuation">.</span>_node_hidden_sizes
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_gated<span class="token punctuation">:</span>
      node_hidden_sizes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>_graph_state_dim <span class="token operator">*</span> <span class="token number">2</span>

    node_states_g <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
        node_hidden_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'node-state-g-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>node_states<span class="token punctuation">)</span>

    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_gated<span class="token punctuation">:</span>
      gates <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>node_states_g<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>self<span class="token punctuation">.</span>_graph_state_dim<span class="token punctuation">]</span><span class="token punctuation">)</span>
      node_states_g <span class="token operator">=</span> node_states_g<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>_graph_state_dim<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">*</span> gates

    graph_states <span class="token operator">=</span> self<span class="token punctuation">.</span>_aggregation_op<span class="token punctuation">(</span>node_states_g<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># unsorted_segment_max does not handle empty graphs in the way we want</span>
    <span class="token comment" spellcheck="true"># it assigns the lowest possible float to empty segments, we want to reset</span>
    <span class="token comment" spellcheck="true"># them to zero.</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_aggregation_type <span class="token operator">==</span> <span class="token string">'max'</span><span class="token punctuation">:</span>
      <span class="token comment" spellcheck="true"># reset everything that's smaller than -1e5 to 0.</span>
      graph_states <span class="token operator">*=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>graph_states <span class="token operator">></span> <span class="token operator">-</span><span class="token number">1e5</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># transform the reduced graph states further</span>

    <span class="token comment" spellcheck="true"># pylint: disable=g-explicit-length-test</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>_graph_transform_sizes <span class="token keyword">is</span> <span class="token operator">not</span> None <span class="token operator">and</span>
        len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_graph_transform_sizes<span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      graph_states <span class="token operator">=</span> snt<span class="token punctuation">.</span>nets<span class="token punctuation">.</span>MLP<span class="token punctuation">(</span>
          self<span class="token punctuation">.</span>_graph_transform_sizes<span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'graph-transform-mlp'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>graph_states<span class="token punctuation">)</span>

    <span class="token keyword">return</span> graph_states</code></pre>
<h4 id="Putting-them-together"><a href="#Putting-them-together" class="headerlink" title="Putting them together"></a>Putting them together</h4><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphEmbeddingNet</span><span class="token punctuation">(</span>snt<span class="token punctuation">.</span>AbstractModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""A graph to embedding mapping network."""</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               encoder<span class="token punctuation">,</span>
               aggregator<span class="token punctuation">,</span>
               node_state_dim<span class="token punctuation">,</span>
               edge_hidden_sizes<span class="token punctuation">,</span>
               node_hidden_sizes<span class="token punctuation">,</span>
               n_prop_layers<span class="token punctuation">,</span>
               share_prop_params<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
               edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
               node_update_type<span class="token operator">=</span><span class="token string">'residual'</span><span class="token punctuation">,</span>
               use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
               name<span class="token operator">=</span><span class="token string">'graph-embedding-net'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Constructor.

    Args:
      encoder: GraphEncoder, encoder that maps features to embeddings.
      aggregator: GraphAggregator, aggregator that produces graph
        representations.
      node_state_dim: dimensionality of node states.
      edge_hidden_sizes: sizes of the hidden layers of the edge message nets.
      node_hidden_sizes: sizes of the hidden layers of the node update nets.
      n_prop_layers: number of graph propagation layers.
      share_prop_params: set to True to share propagation parameters across all
        graph propagation layers, False not to.
      edge_net_init_scale: scale of initialization for the edge message nets.
      node_update_type: type of node updates, one of &amp;#123;mlp, gru, residual&amp;#125;.
      use_reverse_direction: set to True to also propagate messages in the
        reverse direction.
      reverse_dir_param_different: set to True to have the messages computed
        using a different set of parameters than for the forward direction.
      layer_norm: set to True to use layer normalization in a few places.
      name: name of this module.
    """</span>
    super<span class="token punctuation">(</span>GraphEmbeddingNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">)</span>

    self<span class="token punctuation">.</span>_encoder <span class="token operator">=</span> encoder
    self<span class="token punctuation">.</span>_aggregator <span class="token operator">=</span> aggregator
    self<span class="token punctuation">.</span>_node_state_dim <span class="token operator">=</span> node_state_dim
    self<span class="token punctuation">.</span>_edge_hidden_sizes <span class="token operator">=</span> edge_hidden_sizes
    self<span class="token punctuation">.</span>_node_hidden_sizes <span class="token operator">=</span> node_hidden_sizes
    self<span class="token punctuation">.</span>_n_prop_layers <span class="token operator">=</span> n_prop_layers
    self<span class="token punctuation">.</span>_share_prop_params <span class="token operator">=</span> share_prop_params
    self<span class="token punctuation">.</span>_edge_net_init_scale <span class="token operator">=</span> edge_net_init_scale
    self<span class="token punctuation">.</span>_node_update_type <span class="token operator">=</span> node_update_type
    self<span class="token punctuation">.</span>_use_reverse_direction <span class="token operator">=</span> use_reverse_direction
    self<span class="token punctuation">.</span>_reverse_dir_param_different <span class="token operator">=</span> reverse_dir_param_different
    self<span class="token punctuation">.</span>_layer_norm <span class="token operator">=</span> layer_norm

    self<span class="token punctuation">.</span>_prop_layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    self<span class="token punctuation">.</span>_layer_class <span class="token operator">=</span> GraphPropLayer

  <span class="token keyword">def</span> <span class="token function">_build_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> layer_id<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Build one layer in the network."""</span>
    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_layer_class<span class="token punctuation">(</span>
        self<span class="token punctuation">.</span>_node_state_dim<span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>_edge_hidden_sizes<span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>_node_hidden_sizes<span class="token punctuation">,</span>
        edge_net_init_scale<span class="token operator">=</span>self<span class="token punctuation">.</span>_edge_net_init_scale<span class="token punctuation">,</span>
        node_update_type<span class="token operator">=</span>self<span class="token punctuation">.</span>_node_update_type<span class="token punctuation">,</span>
        use_reverse_direction<span class="token operator">=</span>self<span class="token punctuation">.</span>_use_reverse_direction<span class="token punctuation">,</span>
        reverse_dir_param_different<span class="token operator">=</span>self<span class="token punctuation">.</span>_reverse_dir_param_different<span class="token punctuation">,</span>
        layer_norm<span class="token operator">=</span>self<span class="token punctuation">.</span>_layer_norm<span class="token punctuation">,</span>
        name<span class="token operator">=</span><span class="token string">'graph-prop-%d'</span> <span class="token operator">%</span> layer_id<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">_apply_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                   layer<span class="token punctuation">,</span>
                   node_states<span class="token punctuation">,</span>
                   from_idx<span class="token punctuation">,</span>
                   to_idx<span class="token punctuation">,</span>
                   graph_idx<span class="token punctuation">,</span>
                   n_graphs<span class="token punctuation">,</span>
                   edge_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Apply one layer on the given inputs."""</span>
    <span class="token keyword">del</span> graph_idx<span class="token punctuation">,</span> n_graphs
    <span class="token keyword">return</span> layer<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
             node_features<span class="token punctuation">,</span>
             edge_features<span class="token punctuation">,</span>
             from_idx<span class="token punctuation">,</span>
             to_idx<span class="token punctuation">,</span>
             graph_idx<span class="token punctuation">,</span>
             n_graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Compute graph representations.

    Args:
      node_features: [n_nodes, node_feat_dim] float tensor.
      edge_features: [n_edges, edge_feat_dim] float tensor.
      from_idx: [n_edges] int tensor, index of the from node for each edge.
      to_idx: [n_edges] int tensor, index of the to node for each edge.
      graph_idx: [n_nodes] int tensor, graph id for each node.
      n_graphs: int, number of graphs in the batch.

    Returns:
      graph_representations: [n_graphs, graph_representation_dim] float tensor,
        graph representations.
    """</span>
    <span class="token keyword">if</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">)</span> <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>_n_prop_layers<span class="token punctuation">:</span>
      <span class="token comment" spellcheck="true"># build the layers</span>
      <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n_prop_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> <span class="token operator">not</span> self<span class="token punctuation">.</span>_share_prop_params<span class="token punctuation">:</span>
          layer <span class="token operator">=</span> self<span class="token punctuation">.</span>_build_layer<span class="token punctuation">(</span>i<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
          layer <span class="token operator">=</span> self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>

    node_features<span class="token punctuation">,</span> edge_features <span class="token operator">=</span> self<span class="token punctuation">.</span>_encoder<span class="token punctuation">(</span>node_features<span class="token punctuation">,</span> edge_features<span class="token punctuation">)</span>
    node_states <span class="token operator">=</span> node_features

    layer_outputs <span class="token operator">=</span> <span class="token punctuation">[</span>node_states<span class="token punctuation">]</span>

    <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>_prop_layers<span class="token punctuation">:</span>
      <span class="token comment" spellcheck="true"># node_features could be wired in here as well, leaving it out for now as</span>
      <span class="token comment" spellcheck="true"># it is already in the inputs</span>
      node_states <span class="token operator">=</span> self<span class="token punctuation">.</span>_apply_layer<span class="token punctuation">(</span>
          layer<span class="token punctuation">,</span>
          node_states<span class="token punctuation">,</span>
          from_idx<span class="token punctuation">,</span>
          to_idx<span class="token punctuation">,</span>
          graph_idx<span class="token punctuation">,</span>
          n_graphs<span class="token punctuation">,</span>
          edge_features<span class="token punctuation">)</span>
      layer_outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node_states<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># these tensors may be used e.g. for visualization</span>
    self<span class="token punctuation">.</span>_layer_outputs <span class="token operator">=</span> layer_outputs
    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_aggregator<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">reset_n_prop_layers</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_prop_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Set n_prop_layers to the provided new value.

    This allows us to train with certain number of propagation layers and
    evaluate with a different number of propagation layers.

    This only works if n_prop_layers is smaller than the number used for
    training, or when share_prop_params is set to True, in which case this can
    be arbitrarily large.

    Args:
      n_prop_layers: the new number of propagation layers to set.
    """</span>
    self<span class="token punctuation">.</span>_n_prop_layers <span class="token operator">=</span> n_prop_layers

  @property
  <span class="token keyword">def</span> <span class="token function">n_prop_layers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_n_prop_layers

  <span class="token keyword">def</span> <span class="token function">get_layer_outputs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Get the outputs at each layer."""</span>
    <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_layer_outputs'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">return</span> self<span class="token punctuation">.</span>_layer_outputs
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'No layer outputs available.'</span><span class="token punctuation">)</span></code></pre>
<h3 id="The-graph-matching-networks"><a href="#The-graph-matching-networks" class="headerlink" title="The graph matching networks"></a>The graph matching networks</h3><p>The graph matching networks (GMNs) compute the similarity score for a pair of graphs jointly on the pair.  In our current formulation, it still computes a representation for each graph, but the representations for a pair of graphs are computed jointly on the pair, through a cross-graph attention-based matching mechanism.</p>
<p>More concretely, the graph matching model can be formulated as</p>
<p>$$d(G_1, G_2) = d_H(embed_and_match(G_1, G_2))$$</p>
<p>where $embed_and_match(G_1, G_2)$ returns a pair of graph representations.</p>
<p>Similar to the embedding model, our GMNs computes graph representations through 3 steps.  The difference to the embedding model is in the message passing step, where each node not only gets messages from within the same graph, but also gets cross-graph messages by attending to all the nodes in the other graph.  This can be formulated as follows.</p>
<p>We first have within-graph messages as before:<br>$$<br>m_{i\rightarrow j} = f_\mathrm{message}(h_i^{(t)}, h_j^{(t)}, e_{ij}).<br>$$</p>
<p>In addition, we also allow each node in one graph to attend to all the other nodes in the other graph.  The cross graph attention weight (node $i$ in one graph attending to node $j$ in the other graph, and vice versa) is computed as<br>$$\begin{array}{rcl}<br>a_{i\rightarrow j} &amp;=&amp; \frac{\exp(s(h_i^{(t)}, h_j^{(t)}))}{\sum_j \exp(s(h_i^{(t)}, h_j^{(t)}))} \<br>a_{j\rightarrow i} &amp;=&amp; \frac{\exp(s(h_i^{(t)}, h_j^{(t)}))}{\sum_i \exp(s(h_i^{(t)}, h_j^{(t)}))},<br>\end{array}<br>$$<br>where $s(., .)$ is again a vector space similarity function, like Euclidean, dot-product or cosine.  Also note the different indices being summed over in the normalizers.</p>
<p>The cross-graph message is then computed as<br>$$\begin{array}{rcl}<br>\mu_i &amp;=&amp; \sum_j a_{i\rightarrow j} (h_i^{(t)} - h_j^{(t)}) = h_i^{(t)} - \sum_j a_{i\rightarrow j} h_j^{(t)}, \<br>\mu_j &amp;=&amp; \sum_i a_{j\rightarrow i} (h_j^{(t)} - h_i^{(t)}) = h_j^{(t)} - \sum_i a_{j\rightarrow i} h_i^{(t)}.<br>\end{array}<br>$$<br>Here we are computing an attention-weighted sum of all the node representations from the other graph, and then take the difference.  This is essentially <strong>matching</strong> one node in one graph to nodes most similar to it in the other graph, and then compute the difference.</p>
<p>The node updates are then computed as<br>$$<br>h_i^{(t+1)} = f_\mathrm{node}\left(h_i^{(t)}, \sum_{j:(j,i)\in E} m_{j\rightarrow i}, \mu_i\right).<br>$$</p>
<p>The graph encoder and the graph aggregators are the same as in the embedding model.</p>
<h4 id="A-few-similarity-functions"><a href="#A-few-similarity-functions" class="headerlink" title="A few similarity functions"></a>A few similarity functions</h4><p>These are the functions $s(., .)$ that will be used in the cross-graph attention.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">pairwise_euclidean_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute the pairwise Euclidean similarity between x and y.

  This function computes the following similarity value between each pair of x_i
  and y_j: s(x_i, y_j) = -|x_i - y_j|^2.

  Args:
    x: NxD float tensor.
    y: MxD float tensor.

  Returns:
    s: NxM float tensor, the pairwise euclidean similarity.
  """</span>
  s <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  diag_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>x <span class="token operator">*</span> x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  diag_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>y <span class="token operator">*</span> y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> s <span class="token operator">-</span> diag_x <span class="token operator">-</span> diag_y


<span class="token keyword">def</span> <span class="token function">pairwise_dot_product_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute the dot product similarity between x and y.

  This function computes the following similarity value between each pair of x_i
  and y_j: s(x_i, y_j) = x_i^T y_j.

  Args:
    x: NxD float tensor.
    y: MxD float tensor.

  Returns:
    s: NxM float tensor, the pairwise dot product similarity.
  """</span>
  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">pairwise_cosine_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute the cosine similarity between x and y.

  This function computes the following similarity value between each pair of x_i
  and y_j: s(x_i, y_j) = x_i^T y_j / (|x_i||y_j|).

  Args:
    x: NxD float tensor.
    y: MxD float tensor.

  Returns:
    s: NxM float tensor, the pairwise cosine similarity.
  """</span>
  x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
  y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>y<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> transpose_b<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>


PAIRWISE_SIMILARITY_FUNCTION <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
    <span class="token string">'euclidean'</span><span class="token punctuation">:</span> pairwise_euclidean_similarity<span class="token punctuation">,</span>
    <span class="token string">'dotproduct'</span><span class="token punctuation">:</span> pairwise_dot_product_similarity<span class="token punctuation">,</span>
    <span class="token string">'cosine'</span><span class="token punctuation">:</span> pairwise_cosine_similarity<span class="token punctuation">,</span>
<span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>


<span class="token keyword">def</span> <span class="token function">get_pairwise_similarity</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Get pairwise similarity metric by name.

  Args:
    name: string, name of the similarity metric, one of &amp;#123;dot-product, cosine,
      euclidean&amp;#125;.

  Returns:
    similarity: a (x, y) -> sim function.

  Raises:
    ValueError: if name is not supported.
  """</span>
  <span class="token keyword">if</span> name <span class="token operator">not</span> <span class="token keyword">in</span> PAIRWISE_SIMILARITY_FUNCTION<span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Similarity metric name "%s" not supported.'</span> <span class="token operator">%</span> name<span class="token punctuation">)</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> PAIRWISE_SIMILARITY_FUNCTION<span class="token punctuation">[</span>name<span class="token punctuation">]</span></code></pre>
<h4 id="The-cross-graph-attention"><a href="#The-cross-graph-attention" class="headerlink" title="The cross-graph attention"></a>The cross-graph attention</h4><p>We implement this cross-graph attention in batches of pairs.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">compute_cross_attention</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> sim<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute cross attention.

  x_i attend to y_j:
  a_&amp;#123;i->j&amp;#125; = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))
  y_j attend to x_i:
  a_&amp;#123;j->i&amp;#125; = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))
  attention_x = sum_j a_&amp;#123;i->j&amp;#125; y_j
  attention_y = sum_i a_&amp;#123;j->i&amp;#125; x_i

  Args:
    x: NxD float tensor.
    y: MxD float tensor.
    sim: a (x, y) -> similarity function.

  Returns:
    attention_x: NxD float tensor.
    attention_y: NxD float tensor.
  """</span>
  a <span class="token operator">=</span> sim<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
  a_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># i->j</span>
  a_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># j->i</span>
  attention_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a_x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
  attention_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a_y<span class="token punctuation">,</span> x<span class="token punctuation">,</span> transpose_a<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> attention_x<span class="token punctuation">,</span> attention_y


<span class="token keyword">def</span> <span class="token function">batch_block_pair_attention</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>
                               block_idx<span class="token punctuation">,</span>
                               n_blocks<span class="token punctuation">,</span>
                               similarity<span class="token operator">=</span><span class="token string">'dotproduct'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute batched attention between pairs of blocks.

  This function partitions the batch data into blocks according to block_idx.
  For each pair of blocks, x = data[block_idx == 2i], and
  y = data[block_idx == 2i+1], we compute

  x_i attend to y_j:
  a_&amp;#123;i->j&amp;#125; = exp(sim(x_i, y_j)) / sum_j exp(sim(x_i, y_j))
  y_j attend to x_i:
  a_&amp;#123;j->i&amp;#125; = exp(sim(x_i, y_j)) / sum_i exp(sim(x_i, y_j))

  and

  attention_x = sum_j a_&amp;#123;i->j&amp;#125; y_j
  attention_y = sum_i a_&amp;#123;j->i&amp;#125; x_i.

  Args:
    data: NxD float tensor.
    block_idx: N-dim int tensor.
    n_blocks: integer.
    similarity: a string, the similarity metric.

  Returns:
    attention_output: NxD float tensor, each x_i replaced by attention_x_i.

  Raises:
    ValueError: if n_blocks is not an integer or not a multiple of 2.
  """</span>
  <span class="token keyword">if</span> <span class="token operator">not</span> isinstance<span class="token punctuation">(</span>n_blocks<span class="token punctuation">,</span> int<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'n_blocks (%s) has to be an integer.'</span> <span class="token operator">%</span> str<span class="token punctuation">(</span>n_blocks<span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">if</span> n_blocks <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'n_blocks (%d) must be a multiple of 2.'</span> <span class="token operator">%</span> n_blocks<span class="token punctuation">)</span>

  sim <span class="token operator">=</span> get_pairwise_similarity<span class="token punctuation">(</span>similarity<span class="token punctuation">)</span>

  results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

  <span class="token comment" spellcheck="true"># This is probably better than doing boolean_mask for each i</span>
  partitions <span class="token operator">=</span> tf<span class="token punctuation">.</span>dynamic_partition<span class="token punctuation">(</span>data<span class="token punctuation">,</span> block_idx<span class="token punctuation">,</span> n_blocks<span class="token punctuation">)</span>

  <span class="token comment" spellcheck="true"># It is rather complicated to allow n_blocks be a tf tensor and do this in a</span>
  <span class="token comment" spellcheck="true"># dynamic loop, and probably unnecessary to do so.  Therefore we are</span>
  <span class="token comment" spellcheck="true"># restricting n_blocks to be a integer constant here and using the plain for</span>
  <span class="token comment" spellcheck="true"># loop.</span>
  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_blocks<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    y <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
    attention_x<span class="token punctuation">,</span> attention_y <span class="token operator">=</span> compute_cross_attention<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> sim<span class="token punctuation">)</span>
    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>attention_x<span class="token punctuation">)</span>
    results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>attention_y<span class="token punctuation">)</span>

  results <span class="token operator">=</span> tf<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>results<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token comment" spellcheck="true"># the shape of the first dimension is lost after concat, reset it back</span>
  results<span class="token punctuation">.</span>set_shape<span class="token punctuation">(</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
  <span class="token keyword">return</span> results</code></pre>
<h4 id="Graph-matching-layer-and-graph-matching-networks"><a href="#Graph-matching-layer-and-graph-matching-networks" class="headerlink" title="Graph matching layer and graph matching networks"></a>Graph matching layer and graph matching networks</h4><p>This only involves a small set of changes from the graph embedding model.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphPropMatchingLayer</span><span class="token punctuation">(</span>GraphPropLayer<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""A graph propagation layer that also does cross graph matching.

  It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1
  forms the first pair and graph 2 and 3 are the second pair etc., and computes
  cross-graph attention-based matching for each pair.
  """</span>

  <span class="token keyword">def</span> <span class="token function">_build</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
             node_states<span class="token punctuation">,</span>
             from_idx<span class="token punctuation">,</span>
             to_idx<span class="token punctuation">,</span>
             graph_idx<span class="token punctuation">,</span>
             n_graphs<span class="token punctuation">,</span>
             similarity<span class="token operator">=</span><span class="token string">'dotproduct'</span><span class="token punctuation">,</span>
             edge_features<span class="token operator">=</span>None<span class="token punctuation">,</span>
             node_features<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Run one propagation step with cross-graph matching.

    Args:
      node_states: [n_nodes, node_state_dim] float tensor, node states.
      from_idx: [n_edges] int tensor, from node indices for each edge.
      to_idx: [n_edges] int tensor, to node indices for each edge.
      graph_idx: [n_onodes] int tensor, graph id for each node.
      n_graphs: integer, number of graphs in the batch.
      similarity: type of similarity to use for the cross graph attention.
      edge_features: if not None, should be [n_edges, edge_feat_dim] tensor,
        extra edge features.
      node_features: if not None, should be [n_nodes, node_feat_dim] tensor,
        extra node features.

    Returns:
      node_states: [n_nodes, node_state_dim] float tensor, new node states.

    Raises:
      ValueError: if some options are not provided correctly.
    """</span>
    aggregated_messages <span class="token operator">=</span> self<span class="token punctuation">.</span>_compute_aggregated_messages<span class="token punctuation">(</span>
        node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># new stuff here</span>
    cross_graph_attention <span class="token operator">=</span> batch_block_pair_attention<span class="token punctuation">(</span>
        node_states<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span> similarity<span class="token operator">=</span>similarity<span class="token punctuation">)</span>
    attention_input <span class="token operator">=</span> node_states <span class="token operator">-</span> cross_graph_attention

    <span class="token keyword">return</span> self<span class="token punctuation">.</span>_compute_node_update<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span>
                                     <span class="token punctuation">[</span>aggregated_messages<span class="token punctuation">,</span> attention_input<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                     node_features<span class="token operator">=</span>node_features<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">GraphMatchingNet</span><span class="token punctuation">(</span>GraphEmbeddingNet<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Graph matching net.

  This class uses graph matching layers instead of the simple graph prop layers.

  It assumes the incoming graph data is batched and paired, i.e. graph 0 and 1
  forms the first pair and graph 2 and 3 are the second pair etc., and computes
  cross-graph attention-based matching for each pair.
  """</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               encoder<span class="token punctuation">,</span>
               aggregator<span class="token punctuation">,</span>
               node_state_dim<span class="token punctuation">,</span>
               edge_hidden_sizes<span class="token punctuation">,</span>
               node_hidden_sizes<span class="token punctuation">,</span>
               n_prop_layers<span class="token punctuation">,</span>
               share_prop_params<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
               edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
               node_update_type<span class="token operator">=</span><span class="token string">'residual'</span><span class="token punctuation">,</span>
               use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
               similarity<span class="token operator">=</span><span class="token string">'dotproduct'</span><span class="token punctuation">,</span>
               name<span class="token operator">=</span><span class="token string">'graph-matching-net'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    super<span class="token punctuation">(</span>GraphMatchingNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>
        encoder<span class="token punctuation">,</span>
        aggregator<span class="token punctuation">,</span>
        node_state_dim<span class="token punctuation">,</span>
        edge_hidden_sizes<span class="token punctuation">,</span>
        node_hidden_sizes<span class="token punctuation">,</span>
        n_prop_layers<span class="token punctuation">,</span>
        share_prop_params<span class="token operator">=</span>share_prop_params<span class="token punctuation">,</span>
        edge_net_init_scale<span class="token operator">=</span>edge_net_init_scale<span class="token punctuation">,</span>
        node_update_type<span class="token operator">=</span>node_update_type<span class="token punctuation">,</span>
        use_reverse_direction<span class="token operator">=</span>use_reverse_direction<span class="token punctuation">,</span>
        reverse_dir_param_different<span class="token operator">=</span>reverse_dir_param_different<span class="token punctuation">,</span>
        layer_norm<span class="token operator">=</span>layer_norm<span class="token punctuation">,</span>
        name<span class="token operator">=</span>name<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>_similarity <span class="token operator">=</span> similarity
    self<span class="token punctuation">.</span>_layer_class <span class="token operator">=</span> GraphPropMatchingLayer

  <span class="token keyword">def</span> <span class="token function">_apply_layer</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                   layer<span class="token punctuation">,</span>
                   node_states<span class="token punctuation">,</span>
                   from_idx<span class="token punctuation">,</span>
                   to_idx<span class="token punctuation">,</span>
                   graph_idx<span class="token punctuation">,</span>
                   n_graphs<span class="token punctuation">,</span>
                   edge_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Apply one layer on the given inputs."""</span>
    <span class="token keyword">return</span> layer<span class="token punctuation">(</span>node_states<span class="token punctuation">,</span> from_idx<span class="token punctuation">,</span> to_idx<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span>
                 similarity<span class="token operator">=</span>self<span class="token punctuation">.</span>_similarity<span class="token punctuation">,</span> edge_features<span class="token operator">=</span>edge_features<span class="token punctuation">)</span></code></pre>
<h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><h3 id="Labeled-data-examples"><a href="#Labeled-data-examples" class="headerlink" title="Labeled data examples"></a>Labeled data examples</h3><p>We train on either pairs of graphs or triplets of graphs.  For pairs of graphs, we assume each pair $(G_1, G_2)$ comes with a label $t\in{-1, 1}$.  $t=1$ if $G_1$ and $G_2$ are similar, and $t=-1$ otherwise.</p>
<p>For triplets of graphs, we assume within each triplet $(G_1, G_2, G_3)$, $G_1$ is similar to $G_2$ but not similar to $G_3$.</p>
<p>The goal of training is to learn the parameters of the function $f(G_1, G_2)$ such that similar graphs have high similarity (or small distance) and dissimilar graphs have low similarity (or high distance).</p>
<h3 id="Training-on-pairs"><a href="#Training-on-pairs" class="headerlink" title="Training on pairs"></a>Training on pairs</h3><p>Given a dataset of pairs $(G_1, G_2)$ and labels $t\in{-1, 1}$, we can use the following margin-based loss if using Euclidean distance:</p>
<p>$$<br>L_\mathrm{pair} = \mathbb{E}_{(G_1, G_2, t)}[\max{0, \gamma - t(1 - d(G_1, G_2))}]<br>$$</p>
<p>This loss encourages similar graphs to have distance smaller than $1-\gamma$, and dissimilar graphs to have distance greater than $1 + \gamma$, where $\gamma$ is a margin parameter.</p>
<p>Alternatively, for many applications it is beneficial to have the representation of graphs be binary which allows efficient indexing and hashing.  In this case, Hamming distance (similarity) is more appropriate.  On the other hand, the Hamming distance is not differentiable, so we use a smooth approximation<br>$$<br>s(G_1, G_2) = \frac{1}{H}\sum_{i=1}^H \tanh(h_{G_1, i}) \cdot \tanh(h_{G_2, i}),<br>$$<br>where $s$ is now a similarity (rather than distance) function, $h_{G, i}$ is the i-th dimension of the smooth representation vector for G.  We get binary codes by thresholding $h_{G,i}$ at 0, i.e. $\hat{h}<em>{G,i}=1$ if $h</em>{G,i}\ge 0$ and $-1$ otherwise.</p>
<p>The loss we use with these binary representations is defined as</p>
<p>$$<br>L_\mathrm{pair} = \mathbb{E}_{(G_1, G_2, t)}[(t - s(G_1, G_2))^2] / 4.<br>$$</p>
<p>The factor of $1/4$ is used to normalize the loss to between 0 and 1.</p>
<p>These are just two possible losses, many other types of losses could also be used.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">euclidean_distance</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""This is the squared Euclidean distance."""</span>
  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">approximate_hamming_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Approximate Hamming similarity."""</span>
  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> tf<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">pairwise_loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> loss_type<span class="token operator">=</span><span class="token string">'margin'</span><span class="token punctuation">,</span> margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute pairwise loss.

  Args:
    x: [N, D] float tensor, representations for N examples.
    y: [N, D] float tensor, representations for another N examples.
    labels: [N] int tensor, with values in -1 or +1.  labels[i] = +1 if x[i]
      and y[i] are similar, and -1 otherwise.
    loss_type: margin or hamming.
    margin: float scalar, margin for the margin loss.

  Returns:
    loss: [N] float tensor.  Loss for each pair of representations.
  """</span>
  labels <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
  <span class="token keyword">if</span> loss_type <span class="token operator">==</span> <span class="token string">'margin'</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>margin <span class="token operator">-</span> labels <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> euclidean_distance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">elif</span> loss_type <span class="token operator">==</span> <span class="token string">'hamming'</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">0.25</span> <span class="token operator">*</span> <span class="token punctuation">(</span>labels <span class="token operator">-</span> approximate_hamming_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown loss_type %s'</span> <span class="token operator">%</span> loss_type<span class="token punctuation">)</span></code></pre>
<h3 id="Training-on-triplets"><a href="#Training-on-triplets" class="headerlink" title="Training on triplets"></a>Training on triplets</h3><p>Given a dataset of triplets $(G_1, G_2, G_3)$ where $G_1$ is similar to $G_2$ but not similar to $G_3$, we can again use a margin loss or Hamming similarity-based loss.</p>
<p>The following margin loss can be used with Euclidean distance:</p>
<p>$$<br>L_\mathrm{triplet} = \mathbb{E}_{(G_1, G_2, G_3)}[\max{0, d(G_1, G_2) - d(G_1, G_3) + \gamma}],<br>$$<br>which encourages $d(G_1, G_2)$ to be smaller by $d(G_1, G_3)$ by at least a margin of $\gamma$.</p>
<p>If using Hamming distance (similarity) we could use the following loss:</p>
<p>$$<br>L_\mathrm{triplet} = \mathbb{E}_{(G_1, G_2, G_3)}[(s(G_1, G_2) - 1)^2 + (s(G_1, G_3) + 1)^2] / 8<br>$$</p>
<p>The factor of $1/8$ is again used to normalize the loss to within 0 and 1.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">triplet_loss</span><span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">,</span> loss_type<span class="token operator">=</span><span class="token string">'margin'</span><span class="token punctuation">,</span> margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute triplet loss.

  This function computes loss on a triplet of inputs (x, y, z).  A similarity or
  distance value is computed for each pair of (x, y) and (x, z).  Since the
  representations for x can be different in the two pairs (like our matching
  model) we distinguish the two x representations by x_1 and x_2.

  Args:
    x_1: [N, D] float tensor.
    y: [N, D] float tensor.
    x_2: [N, D] float tensor.
    z: [N, D] float tensor.
    loss_type: margin or hamming.
    margin: float scalar, margin for the margin loss.

  Returns:
    loss: [N] float tensor.  Loss for each pair of representations.
  """</span>
  <span class="token keyword">if</span> loss_type <span class="token operator">==</span> <span class="token string">'margin'</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>margin <span class="token operator">+</span>
                      euclidean_distance<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">-</span>
                      euclidean_distance<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token keyword">elif</span> loss_type <span class="token operator">==</span> <span class="token string">'hamming'</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">0.125</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>approximate_hamming_similarity<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span>
                    <span class="token punctuation">(</span>approximate_hamming_similarity<span class="token punctuation">(</span>x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown loss_type %s'</span> <span class="token operator">%</span> loss_type<span class="token punctuation">)</span></code></pre>
<h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p>We use an abstract <code>GraphSimilarityDataset</code> class to define the general interface for the training and evaluatin data used in graph similarity learning.</p>
<p>We also assume a certain format for packing the graphs into tensors as described below.</p>
<pre class=" language-python"><code class="language-python">GraphData <span class="token operator">=</span> collections<span class="token punctuation">.</span>namedtuple<span class="token punctuation">(</span><span class="token string">'GraphData'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>
    <span class="token string">'from_idx'</span><span class="token punctuation">,</span>
    <span class="token string">'to_idx'</span><span class="token punctuation">,</span>
    <span class="token string">'node_features'</span><span class="token punctuation">,</span>
    <span class="token string">'edge_features'</span><span class="token punctuation">,</span>
    <span class="token string">'graph_idx'</span><span class="token punctuation">,</span>
    <span class="token string">'n_graphs'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


@six<span class="token punctuation">.</span>add_metaclass<span class="token punctuation">(</span>abc<span class="token punctuation">.</span>ABCMeta<span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">GraphSimilarityDataset</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Base class for all the graph similarity learning datasets.

  This class defines some common interfaces a graph similarity dataset can have,
  in particular the functions that creates iterators over pairs and triplets.
  """</span>

  @abc<span class="token punctuation">.</span>abstractmethod
  <span class="token keyword">def</span> <span class="token function">triplets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Create an iterator over triplets.

    Args:
      batch_size: int, number of triplets in a batch.

    Yields:
      graphs: a `GraphData` instance.  The batch of triplets put together.  Each
        triplet has 3 graphs (x, y, z).  Here the first graph is duplicated once
        so the graphs for each triplet are ordered as (x, y, x, z) in the batch.
        The batch contains `batch_size` number of triplets, hence `4*batch_size`
        many graphs.
    """</span>
    <span class="token keyword">pass</span>

  @abc<span class="token punctuation">.</span>abstractmethod
  <span class="token keyword">def</span> <span class="token function">pairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Create an iterator over pairs.

    Args:
      batch_size: int, number of pairs in a batch.

    Yields:
      graphs: a `GraphData` instance.  The batch of pairs put together.  Each
        pair has 2 graphs (x, y).  The batch contains `batch_size` number of
        pairs, hence `2*batch_size` many graphs.
      labels: [batch_size] int labels for each pair, +1 for similar, -1 for not.
    """</span>
    <span class="token keyword">pass</span></code></pre>
<h2 id="The-graph-edit-distance-task"><a href="#The-graph-edit-distance-task" class="headerlink" title="The graph edit distance task"></a>The graph edit distance task</h2><p>Here we use the synthetic task of learning approximate graph edit distances (GEDs) to test the effectiveness of the graph similarity learning models.</p>
<p>Given two graphs $G_1$ and $G_2$, we say the edit distance between them is the number of actions needed to transform one into another.  Since the difference in graph size (number of nodes, number of edges) is trivial to identify, we only consider the case of substituting one edge with another edge, and define the edit distance between two equal-size graphs to be the number of edge changes needed to make them identical (or isomorphic).</p>
<p>We train a graph similarity or distance model that aligns with the GED, by giving graphs with small edit distance a high similarity score or low learned distance, and otherwise low similarity score or high learned distance.  Note that we don’t try to match the learned graph distance with the actual GED, as we don’t assume the exact scale of the GED is available during training.</p>
<p>To get training data, we sample graph $G$ from the Erdos-Renyi model (other random graph models could be used as well), and then:</p>
<ul>
<li>apply a node permutation to $G$ to get $G_1$,</li>
<li>apply $k_1$ edge changes to $G$ to get $G_2$,</li>
<li>apply $k_2$ edge changes to $G$ to get $G_3$.</li>
</ul>
<p>Each edge change action substitutes one edge $(i,j)$ by another edge $(i’, j’)$ where $i’$ and $j’$ are picked randomly.  In this case, we have roughly $GED(G_1, G_2)\approx k_1$ and $GED(G_1, G_3)\approx k_2$.  We make $k_1 &lt; k_2$ and say $(G_1, G_2)$ is a positive pair that are similar and $(G_1, G_3)$ is a negative pair hence not similar.</p>
<p>Note that the above GED for $G_1, G_2$ and $G_3$ only holds approximately, and $GED(G_1, G_2)\le k_1$ and $GED(G_1, G_3)\le k_2$, because of the potential symmetry in $G$, i.e. it is possible that changing one edge may only change the graph into another isomorphic graph.  However the probability of this happening is relatively small and decreases with increasing graph size.  So we ignore this possibility in this task.</p>
<h3 id="A-few-graph-manipulation-primitives"><a href="#A-few-graph-manipulation-primitives" class="headerlink" title="A few graph manipulation primitives"></a>A few graph manipulation primitives</h3><p>These primitives assume the incoming graphs are instances of <code>networkx.Graph</code>.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">permute_graph_nodes</span><span class="token punctuation">(</span>g<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Permute node ordering of a graph, returns a new graph."""</span>
  n <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>
  new_g <span class="token operator">=</span> nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
  new_g<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">)</span>
  perm <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>permutation<span class="token punctuation">(</span>n<span class="token punctuation">)</span>
  edges <span class="token operator">=</span> g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span>
  new_edges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> edges<span class="token punctuation">:</span>
    new_edges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>perm<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span> perm<span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  new_g<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>new_edges<span class="token punctuation">)</span>
  <span class="token keyword">return</span> new_g


<span class="token keyword">def</span> <span class="token function">substitute_random_edges</span><span class="token punctuation">(</span>g<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Substitutes n edges from graph g with another n randomly picked edges."""</span>
  g <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>g<span class="token punctuation">)</span>
  n_nodes <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>
  edges <span class="token operator">=</span> list<span class="token punctuation">(</span>g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  <span class="token comment" spellcheck="true"># sample n edges without replacement</span>
  e_remove <span class="token operator">=</span> <span class="token punctuation">[</span>edges<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>
      np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>len<span class="token punctuation">(</span>edges<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> n<span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
  edge_set <span class="token operator">=</span> set<span class="token punctuation">(</span>edges<span class="token punctuation">)</span>
  e_add <span class="token operator">=</span> set<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">while</span> len<span class="token punctuation">(</span>e_add<span class="token punctuation">)</span> <span class="token operator">&lt;</span> n<span class="token punctuation">:</span>
    e <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> replace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># make sure e does not exist and is not already chosen to be added</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> edge_set <span class="token operator">and</span> <span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> edge_set <span class="token operator">and</span>
        <span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> e_add <span class="token operator">and</span> <span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">not</span> <span class="token keyword">in</span> e_add<span class="token punctuation">)</span><span class="token punctuation">:</span>
      e_add<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> e<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> e_remove<span class="token punctuation">:</span>
    g<span class="token punctuation">.</span>remove_edge<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j<span class="token punctuation">)</span>
  <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> e_add<span class="token punctuation">:</span>
    g<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j<span class="token punctuation">)</span>
  <span class="token keyword">return</span> g</code></pre>
<h3 id="Dataset-for-training-fixed-dataset-for-evaluation"><a href="#Dataset-for-training-fixed-dataset-for-evaluation" class="headerlink" title="Dataset for training, fixed dataset for evaluation"></a>Dataset for training, fixed dataset for evaluation</h3><p>For training we use a procedure to generate graphs in pairs or triplets on the fly, and wrap this process into a <code>Dataset</code> instance.  For evaluation we need to<br>use a fixed set to make sure the evaluation results are consistent and comparable, and we do that by controlling random seeds.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">GraphEditDistanceDataset</span><span class="token punctuation">(</span>GraphSimilarityDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Graph edit distance dataset."""</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               n_nodes_range<span class="token punctuation">,</span>
               p_edge_range<span class="token punctuation">,</span>
               n_changes_positive<span class="token punctuation">,</span>
               n_changes_negative<span class="token punctuation">,</span>
               permute<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Constructor.

    Args:
      n_nodes_range: a tuple (n_min, n_max).  The minimum and maximum number of
        nodes in a graph to generate.
      p_edge_range: a tuple (p_min, p_max).  The minimum and maximum edge
        probability.
      n_changes_positive: the number of edge substitutions for a pair to be
        considered positive (similar).
      n_changes_negative: the number of edge substitutions for a pair to be
        considered negative (not similar).
      permute: if True (default), permute node orderings in addition to
        changing edges; if False, the node orderings across a pair or triplet of
        graphs will be the same, useful for visualization.
    """</span>
    self<span class="token punctuation">.</span>_n_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_n_max <span class="token operator">=</span> n_nodes_range
    self<span class="token punctuation">.</span>_p_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_p_max <span class="token operator">=</span> p_edge_range
    self<span class="token punctuation">.</span>_k_pos <span class="token operator">=</span> n_changes_positive
    self<span class="token punctuation">.</span>_k_neg <span class="token operator">=</span> n_changes_negative
    self<span class="token punctuation">.</span>_permute <span class="token operator">=</span> permute

  <span class="token keyword">def</span> <span class="token function">_get_graph</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Generate one graph."""</span>
    n_nodes <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_n_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_n_max <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    p_edge <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_p_min<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_p_max<span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># do a little bit of filtering</span>
    n_trials <span class="token operator">=</span> <span class="token number">100</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_trials<span class="token punctuation">)</span><span class="token punctuation">:</span>
      g <span class="token operator">=</span> nx<span class="token punctuation">.</span>erdos_renyi_graph<span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> p_edge<span class="token punctuation">)</span>
      <span class="token keyword">if</span> nx<span class="token punctuation">.</span>is_connected<span class="token punctuation">(</span>g<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> g

    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Failed to generate a connected graph.'</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">_get_pair</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> positive<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Generate one pair of graphs."""</span>
    g <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_permute<span class="token punctuation">:</span>
      permuted_g <span class="token operator">=</span> permute_graph_nodes<span class="token punctuation">(</span>g<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      permuted_g <span class="token operator">=</span> g
    n_changes <span class="token operator">=</span> self<span class="token punctuation">.</span>_k_pos <span class="token keyword">if</span> positive <span class="token keyword">else</span> self<span class="token punctuation">.</span>_k_neg
    changed_g <span class="token operator">=</span> substitute_random_edges<span class="token punctuation">(</span>g<span class="token punctuation">,</span> n_changes<span class="token punctuation">)</span>
    <span class="token keyword">return</span> permuted_g<span class="token punctuation">,</span> changed_g

  <span class="token keyword">def</span> <span class="token function">_get_triplet</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Generate one triplet of graphs."""</span>
    g <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> self<span class="token punctuation">.</span>_permute<span class="token punctuation">:</span>
      permuted_g <span class="token operator">=</span> permute_graph_nodes<span class="token punctuation">(</span>g<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      permuted_g <span class="token operator">=</span> g
    pos_g <span class="token operator">=</span> substitute_random_edges<span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_k_pos<span class="token punctuation">)</span>
    neg_g <span class="token operator">=</span> substitute_random_edges<span class="token punctuation">(</span>g<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_k_neg<span class="token punctuation">)</span>
    <span class="token keyword">return</span> permuted_g<span class="token punctuation">,</span> pos_g<span class="token punctuation">,</span> neg_g

  <span class="token keyword">def</span> <span class="token function">triplets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Yields batches of triplet data."""</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
      batch_graphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
      <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_triplet<span class="token punctuation">(</span><span class="token punctuation">)</span>
        batch_graphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g1<span class="token punctuation">,</span> g3<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token keyword">yield</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">pairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Yields batches of pair data."""</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
      batch_graphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
      batch_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
      positive <span class="token operator">=</span> <span class="token boolean">True</span>
      <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        g1<span class="token punctuation">,</span> g2 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_pair<span class="token punctuation">(</span>positive<span class="token punctuation">)</span>
        batch_graphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">)</span><span class="token punctuation">)</span>
        batch_labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> positive <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        positive <span class="token operator">=</span> <span class="token operator">not</span> positive

      packed_graphs <span class="token operator">=</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>
      labels <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>batch_labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
      <span class="token keyword">yield</span> packed_graphs<span class="token punctuation">,</span> labels

  <span class="token keyword">def</span> <span class="token function">_pack_batch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Pack a batch of graphs into a single `GraphData` instance.

    Args:
      graphs: a list of generated networkx graphs.

    Returns:
      graph_data: a `GraphData` instance, with node and edge indices properly
        shifted.
    """</span>
    graphs <span class="token operator">=</span> tf<span class="token punctuation">.</span>nest<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span>
    from_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    to_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    graph_idx <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    n_total_nodes <span class="token operator">=</span> <span class="token number">0</span>
    n_total_edges <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> g <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      n_nodes <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>
      n_edges <span class="token operator">=</span> g<span class="token punctuation">.</span>number_of_edges<span class="token punctuation">(</span><span class="token punctuation">)</span>
      edges <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>g<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
      <span class="token comment" spellcheck="true"># shift the node indices for the edges</span>
      from_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> n_total_nodes<span class="token punctuation">)</span>
      to_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>edges<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> n_total_nodes<span class="token punctuation">)</span>
      graph_idx<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>n_nodes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span> <span class="token operator">*</span> i<span class="token punctuation">)</span>

      n_total_nodes <span class="token operator">+=</span> n_nodes
      n_total_edges <span class="token operator">+=</span> n_edges

    <span class="token keyword">return</span> GraphData<span class="token punctuation">(</span>
        from_idx<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>from_idx<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        to_idx<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>to_idx<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token comment" spellcheck="true"># this task only cares about the structures, the graphs have no features</span>
        node_features<span class="token operator">=</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n_total_nodes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
        edge_features<span class="token operator">=</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>n_total_edges<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">,</span>
        graph_idx<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>graph_idx<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        n_graphs<span class="token operator">=</span>len<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token punctuation">)</span>


@contextlib<span class="token punctuation">.</span>contextmanager
<span class="token keyword">def</span> <span class="token function">reset_random_state</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""This function creates a context that uses the given seed."""</span>
  np_rnd_state <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>get_state<span class="token punctuation">(</span><span class="token punctuation">)</span>
  rnd_state <span class="token operator">=</span> random<span class="token punctuation">.</span>getstate<span class="token punctuation">(</span><span class="token punctuation">)</span>
  np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
  random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token keyword">try</span><span class="token punctuation">:</span>
    <span class="token keyword">yield</span>
  <span class="token keyword">finally</span><span class="token punctuation">:</span>
    random<span class="token punctuation">.</span>setstate<span class="token punctuation">(</span>rnd_state<span class="token punctuation">)</span>
    np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>set_state<span class="token punctuation">(</span>np_rnd_state<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">FixedGraphEditDistanceDataset</span><span class="token punctuation">(</span>GraphEditDistanceDataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""A fixed dataset of pairs or triplets for the graph edit distance task.

  This dataset can be used for evaluation.
  """</span>

  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               n_nodes_range<span class="token punctuation">,</span>
               p_edge_range<span class="token punctuation">,</span>
               n_changes_positive<span class="token punctuation">,</span>
               n_changes_negative<span class="token punctuation">,</span>
               dataset_size<span class="token punctuation">,</span>
               permute<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
               seed<span class="token operator">=</span><span class="token number">1234</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    super<span class="token punctuation">(</span>FixedGraphEditDistanceDataset<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>
        n_nodes_range<span class="token punctuation">,</span> p_edge_range<span class="token punctuation">,</span> n_changes_positive<span class="token punctuation">,</span> n_changes_negative<span class="token punctuation">,</span>
        permute<span class="token operator">=</span>permute<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>_dataset_size <span class="token operator">=</span> dataset_size
    self<span class="token punctuation">.</span>_seed <span class="token operator">=</span> seed

  <span class="token keyword">def</span> <span class="token function">triplets</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Yield triplets."""</span>

    <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_triplets'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      triplets <span class="token operator">=</span> self<span class="token punctuation">.</span>_triplets
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      <span class="token comment" spellcheck="true"># get a fixed set of triplets</span>
      <span class="token keyword">with</span> reset_random_state<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
        triplets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_dataset_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
          g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g3 <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_triplet<span class="token punctuation">(</span><span class="token punctuation">)</span>
          triplets<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> g1<span class="token punctuation">,</span> g3<span class="token punctuation">)</span><span class="token punctuation">)</span>
      self<span class="token punctuation">.</span>_triplets <span class="token operator">=</span> triplets

    ptr <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> ptr <span class="token operator">+</span> batch_size <span class="token operator">&lt;=</span> len<span class="token punctuation">(</span>triplets<span class="token punctuation">)</span><span class="token punctuation">:</span>
      batch_graphs <span class="token operator">=</span> triplets<span class="token punctuation">[</span>ptr<span class="token punctuation">:</span>ptr <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>
      <span class="token keyword">yield</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>
      ptr <span class="token operator">+=</span> batch_size

  <span class="token keyword">def</span> <span class="token function">pairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Yield pairs and labels."""</span>

    <span class="token keyword">if</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_pairs'</span><span class="token punctuation">)</span> <span class="token operator">and</span> hasattr<span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'_labels'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      pairs <span class="token operator">=</span> self<span class="token punctuation">.</span>_pairs
      labels <span class="token operator">=</span> self<span class="token punctuation">.</span>_labels
    <span class="token keyword">else</span><span class="token punctuation">:</span>
      <span class="token comment" spellcheck="true"># get a fixed set of pairs first</span>
      <span class="token keyword">with</span> reset_random_state<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
        pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        positive <span class="token operator">=</span> <span class="token boolean">True</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_dataset_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
          pairs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>_get_pair<span class="token punctuation">(</span>positive<span class="token punctuation">)</span><span class="token punctuation">)</span>
          labels<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span> <span class="token keyword">if</span> positive <span class="token keyword">else</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
          positive <span class="token operator">=</span> <span class="token operator">not</span> positive
      labels <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

      self<span class="token punctuation">.</span>_pairs <span class="token operator">=</span> pairs
      self<span class="token punctuation">.</span>_labels <span class="token operator">=</span> labels

    ptr <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">while</span> ptr <span class="token operator">+</span> batch_size <span class="token operator">&lt;=</span> len<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      batch_graphs <span class="token operator">=</span> pairs<span class="token punctuation">[</span>ptr<span class="token punctuation">:</span>ptr <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>
      packed_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>_pack_batch<span class="token punctuation">(</span>batch_graphs<span class="token punctuation">)</span>
      <span class="token keyword">yield</span> packed_batch<span class="token punctuation">,</span> labels<span class="token punctuation">[</span>ptr<span class="token punctuation">:</span>ptr <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>
      ptr <span class="token operator">+=</span> batch_size</code></pre>
<h2 id="Building-the-model-and-the-training-and-evaluation-pipelines"><a href="#Building-the-model-and-the-training-and-evaluation-pipelines" class="headerlink" title="Building the model, and the training and evaluation pipelines"></a>Building the model, and the training and evaluation pipelines</h2><h3 id="Configs"><a href="#Configs" class="headerlink" title="Configs"></a>Configs</h3><p>We put all the configs for model building and training into a single <code>dict</code>, but any part of our code can also be used separately with separate configs if you want.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_default_config</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""The default configs."""</span>
  node_state_dim <span class="token operator">=</span> <span class="token number">32</span>
  graph_rep_dim <span class="token operator">=</span> <span class="token number">128</span>
  graph_embedding_net_config <span class="token operator">=</span> dict<span class="token punctuation">(</span>
      node_state_dim<span class="token operator">=</span>node_state_dim<span class="token punctuation">,</span>
      edge_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>node_state_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> node_state_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      node_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>node_state_dim <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      n_prop_layers<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># set to False to not share parameters across message passing layers</span>
      share_prop_params<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># initialize message MLP with small parameter weights to prevent</span>
      <span class="token comment" spellcheck="true"># aggregated message vectors blowing up, alternatively we could also use</span>
      <span class="token comment" spellcheck="true"># e.g. layer normalization to keep the scale of these under control.</span>
      edge_net_init_scale<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># other types of update like `mlp` and `residual` can also be used here.</span>
      node_update_type<span class="token operator">=</span><span class="token string">'gru'</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># set to False if your graph already contains edges in both directions.</span>
      use_reverse_direction<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># set to True if your graph is directed</span>
      reverse_dir_param_different<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># we didn't use layer norm in our experiments but sometimes this can help.</span>
      layer_norm<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
  graph_matching_net_config <span class="token operator">=</span> graph_embedding_net_config<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  graph_matching_net_config<span class="token punctuation">[</span><span class="token string">'similarity'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'dotproduct'</span>

  <span class="token keyword">return</span> dict<span class="token punctuation">(</span>
      encoder<span class="token operator">=</span>dict<span class="token punctuation">(</span>
          node_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>node_state_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>
          edge_hidden_sizes<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">,</span>
      aggregator<span class="token operator">=</span>dict<span class="token punctuation">(</span>
          node_hidden_sizes<span class="token operator">=</span><span class="token punctuation">[</span>graph_rep_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>
          graph_transform_sizes<span class="token operator">=</span><span class="token punctuation">[</span>graph_rep_dim<span class="token punctuation">]</span><span class="token punctuation">,</span>
          gated<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
          aggregation_type<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      graph_embedding_net<span class="token operator">=</span>graph_embedding_net_config<span class="token punctuation">,</span>
      graph_matching_net<span class="token operator">=</span>graph_matching_net_config<span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># Set to `embedding` to use the graph embedding net.</span>
      model_type<span class="token operator">=</span><span class="token string">'matching'</span><span class="token punctuation">,</span>
      data<span class="token operator">=</span>dict<span class="token punctuation">(</span>
          problem<span class="token operator">=</span><span class="token string">'graph_edit_distance'</span><span class="token punctuation">,</span>
          dataset_params<span class="token operator">=</span>dict<span class="token punctuation">(</span>
              <span class="token comment" spellcheck="true"># always generate graphs with 20 nodes and p_edge=0.2.</span>
              n_nodes_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              p_edge_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
              n_changes_positive<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
              n_changes_negative<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
              validation_dataset_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      training<span class="token operator">=</span>dict<span class="token punctuation">(</span>
          batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
          learning_rate<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span>
          mode<span class="token operator">=</span><span class="token string">'pair'</span><span class="token punctuation">,</span>
          loss<span class="token operator">=</span><span class="token string">'margin'</span><span class="token punctuation">,</span>
          margin<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>
          <span class="token comment" spellcheck="true"># A small regularizer on the graph vector scales to avoid the graph</span>
          <span class="token comment" spellcheck="true"># vectors blowing up.  If numerical issues is particularly bad in the</span>
          <span class="token comment" spellcheck="true"># model we can add `snt.LayerNorm` to the outputs of each layer, the</span>
          <span class="token comment" spellcheck="true"># aggregated messages and aggregated node representations to</span>
          <span class="token comment" spellcheck="true"># keep the network activation scale in a reasonable range.</span>
          graph_vec_regularizer_weight<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">,</span>
          <span class="token comment" spellcheck="true"># Add gradient clipping to avoid large gradients.</span>
          clip_value<span class="token operator">=</span><span class="token number">10.0</span><span class="token punctuation">,</span>
          <span class="token comment" spellcheck="true"># Increase this to train longer.</span>
          n_training_steps<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span>
          <span class="token comment" spellcheck="true"># Print training information every this many training steps.</span>
          print_after<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
          <span class="token comment" spellcheck="true"># Evaluate on validation set every `eval_after * print_after` steps.</span>
          eval_after<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      evaluation<span class="token operator">=</span>dict<span class="token punctuation">(</span>
          batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      seed<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
      <span class="token punctuation">)</span></code></pre>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><p>We evaluate the performance of the models by measuring how well they do on held-out data.  We look at two metrics, triplet accuracy and pair AUC.</p>
<p>For each triplet $(G_1, G_2, G_3)$, a model is said to make a correct prediction if it predicts $d(G_1, G_2) &lt; d(G_1, G_3)$, i.e. similar graphs have a smaller distance (or larger similarity) than dissimilar graphs.  We average the accuracy across a dataset to get the <strong>triplet accuracy</strong> metric.</p>
<p>For each pair $(G_1, G_2)$ a model computes a distance $d(G_1, G_2)$.  To compute the <strong>pair AUC</strong> metric, we rank all the pairs by the distance from low to high (similarity from high to low), and then compute the area under the ROC curve for positive pairs.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">exact_hamming_similarity</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute the binary Hamming similarity."""</span>
  match <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>x <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">,</span> y <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>match<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">compute_similarity</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute the distance between x and y vectors.

  The distance will be computed based on the training loss type.

  Args:
    config: a config dict.
    x: [n_examples, feature_dim] float tensor.
    y: [n_examples, feature_dim] float tensor.

  Returns:
    dist: [n_examples] float tensor.

  Raises:
    ValueError: if loss type is not supported.
  """</span>
  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'margin'</span><span class="token punctuation">:</span>
    <span class="token comment" spellcheck="true"># similarity is negative distance</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>euclidean_distance<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
  <span class="token keyword">elif</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'hamming'</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> exact_hamming_similarity<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown loss type %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">auc</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> <span class="token operator">**</span>auc_args<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Compute the AUC for pair classification.

  See `tf.metrics.auc` for more details about this metric.

  Args:
    scores: [n_examples] float.  Higher scores mean higher preference of being
      assigned the label of +1.
    labels: [n_examples] int.  Labels are either +1 or -1.
    **auc_args: other arguments that can be used by `tf.metrics.auc`.

  Returns:
    auc: the area under the ROC curve.
  """</span>
  scores_max <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_max<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
  scores_min <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_min<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
  <span class="token comment" spellcheck="true"># normalize scores to [0, 1] and add a small epislon for safety</span>
  scores <span class="token operator">=</span> <span class="token punctuation">(</span>scores <span class="token operator">-</span> scores_min<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>scores_max <span class="token operator">-</span> scores_min <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span>

  labels <span class="token operator">=</span> <span class="token punctuation">(</span>labels <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
  <span class="token comment" spellcheck="true"># The following code should be used according to the tensorflow official</span>
  <span class="token comment" spellcheck="true"># documentation:</span>
  <span class="token comment" spellcheck="true"># value, _ = tf.metrics.auc(labels, scores, **auc_args)</span>

  <span class="token comment" spellcheck="true"># However `tf.metrics.auc` is currently (as of July 23, 2019) buggy so we have</span>
  <span class="token comment" spellcheck="true"># to use the following:</span>
  _<span class="token punctuation">,</span> value <span class="token operator">=</span> tf<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>auc<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> scores<span class="token punctuation">,</span> <span class="token operator">**</span>auc_args<span class="token punctuation">)</span>
  <span class="token keyword">return</span> value</code></pre>
<h3 id="Build-the-model"><a href="#Build-the-model" class="headerlink" title="Build the model"></a>Build the model</h3><p>We need to:</p>
<ul>
<li>set up the placeholders</li>
<li>build the model</li>
<li>build the computation graphs for training and evaluation</li>
<li>build the metrics and statistics to monitor</li>
</ul>
<p>We assume the graphs are batched, if a batch contains pairs $(G_1^1, G_2^1), (G_1^2, G_2^2), …$, then the graphs will be packed in a batch as a sequence of graphs $(G_1^1, G_2^1, G_1^2, G_2^2, …)$.  If a batch contains triplets $(G_1^1, G_2^1, G_3^1), (G_1^2, G_2^2, G_3^2)$ then the graphs will be packed in a batch as a sequence of $(G_1^1, G_2^1, G_1^1, G_3^1, G_1^2, G_2^2, G_1^2, G_3^2), …$.  Note that the first graph in each triplet is duplicated once to make the cross-graph attention more easily computable as it requires the graphs to appear in pairs.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">reshape_and_split_tensor</span><span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> n_splits<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Reshape and split a 2D tensor along the last dimension.

  Args:
    tensor: a [num_examples, feature_dim] tensor.  num_examples must be a
      multiple of `n_splits`.
    n_splits: int, number of splits to split the tensor into.

  Returns:
    splits: a list of `n_splits` tensors.  The first split is [tensor[0],
      tensor[n_splits], tensor[n_splits * 2], ...], the second split is
      [tensor[1], tensor[n_splits + 1], tensor[n_splits * 2 + 1], ...], etc..
  """</span>
  feature_dim <span class="token operator">=</span> tensor<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
  <span class="token comment" spellcheck="true"># feature dim must be known, otherwise you can provide that as an input</span>
  <span class="token keyword">assert</span> isinstance<span class="token punctuation">(</span>feature_dim<span class="token punctuation">,</span> int<span class="token punctuation">)</span>
  tensor <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> feature_dim <span class="token operator">*</span> n_splits<span class="token punctuation">]</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> tf<span class="token punctuation">.</span>split<span class="token punctuation">(</span>tensor<span class="token punctuation">,</span> n_splits<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">build_placeholders</span><span class="token punctuation">(</span>node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Build the placeholders needed for the model.

  Args:
    node_feature_dim: int.
    edge_feature_dim: int.

  Returns:
    placeholders: a placeholder name -> placeholder tensor dict.
  """</span>
  <span class="token comment" spellcheck="true"># `n_graphs` must be specified as an integer, as `tf.dynamic_partition`</span>
  <span class="token comment" spellcheck="true"># requires so.</span>
  <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
      <span class="token string">'node_features'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">,</span> node_feature_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token string">'edge_features'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token string">'from_idx'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token string">'to_idx'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token string">'graph_idx'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token comment" spellcheck="true"># only used for pairwise training and evaluation</span>
      <span class="token string">'labels'</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>


<span class="token keyword">def</span> <span class="token function">build_model</span><span class="token punctuation">(</span>config<span class="token punctuation">,</span> node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Create model for training and evaluation.

  Args:
    config: a dictionary of configs, like the one created by the
      `get_default_config` function.
    node_feature_dim: int, dimensionality of node features.
    edge_feature_dim: int, dimensionality of edge features.

  Returns:
    tensors: a (potentially nested) name => tensor dict.
    placeholders: a (potentially nested) name => tensor dict.
    model: a GraphEmbeddingNet or GraphMatchingNet instance.

  Raises:
    ValueError: if the specified model or training settings are not supported.
  """</span>
  encoder <span class="token operator">=</span> GraphEncoder<span class="token punctuation">(</span><span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'encoder'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  aggregator <span class="token operator">=</span> GraphAggregator<span class="token punctuation">(</span><span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'aggregator'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'model_type'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'embedding'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> GraphEmbeddingNet<span class="token punctuation">(</span>
        encoder<span class="token punctuation">,</span> aggregator<span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'graph_embedding_net'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  <span class="token keyword">elif</span> config<span class="token punctuation">[</span><span class="token string">'model_type'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'matching'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> GraphMatchingNet<span class="token punctuation">(</span>
        encoder<span class="token punctuation">,</span> aggregator<span class="token punctuation">,</span> <span class="token operator">**</span>config<span class="token punctuation">[</span><span class="token string">'graph_matching_net'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown model type: %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'model_type'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

  training_n_graphs_in_batch <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span>
  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'pair'</span><span class="token punctuation">:</span>
    training_n_graphs_in_batch <span class="token operator">*=</span> <span class="token number">2</span>
  <span class="token keyword">elif</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'triplet'</span><span class="token punctuation">:</span>
    training_n_graphs_in_batch <span class="token operator">*=</span> <span class="token number">4</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown training mode: %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

  placeholders <span class="token operator">=</span> build_placeholders<span class="token punctuation">(</span>node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span>

  <span class="token comment" spellcheck="true"># training</span>
  model_inputs <span class="token operator">=</span> placeholders<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">del</span> model_inputs<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
  model_inputs<span class="token punctuation">[</span><span class="token string">'n_graphs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> training_n_graphs_in_batch
  graph_vectors <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>

  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'pair'</span><span class="token punctuation">:</span>
    x<span class="token punctuation">,</span> y <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>graph_vectors<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> pairwise_loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         loss_type<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         margin<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'margin'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment" spellcheck="true"># optionally monitor the similarity between positive and negative pairs</span>
    is_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>equal<span class="token punctuation">(</span>placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    is_neg <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> is_pos
    n_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>is_pos<span class="token punctuation">)</span>
    n_neg <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>is_neg<span class="token punctuation">)</span>
    sim <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    sim_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>sim <span class="token operator">*</span> is_pos<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>n_pos <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span>
    sim_neg <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>sim <span class="token operator">*</span> is_neg<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>n_neg <span class="token operator">+</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">)</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>graph_vectors<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> triplet_loss<span class="token punctuation">(</span>x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">,</span>
                        loss_type<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        margin<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'margin'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    sim_pos <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>
    sim_neg <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">)</span>

  graph_vec_scale <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>graph_vectors<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'graph_vec_regularizer_weight'</span><span class="token punctuation">]</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
    loss <span class="token operator">+=</span> <span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'graph_vec_regularizer_weight'</span><span class="token punctuation">]</span> <span class="token operator">*</span>
             <span class="token number">0.5</span> <span class="token operator">*</span> graph_vec_scale<span class="token punctuation">)</span>

  <span class="token comment" spellcheck="true"># monitor scale of the parameters and gradients, these are typically helpful</span>
  optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>
      learning_rate<span class="token operator">=</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'learning_rate'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  grads_and_params <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>compute_gradients<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
  grads<span class="token punctuation">,</span> params <span class="token operator">=</span> zip<span class="token punctuation">(</span><span class="token operator">*</span>grads_and_params<span class="token punctuation">)</span>
  grads<span class="token punctuation">,</span> _ <span class="token operator">=</span> tf<span class="token punctuation">.</span>clip_by_global_norm<span class="token punctuation">(</span>grads<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'clip_value'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  train_step <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>apply_gradients<span class="token punctuation">(</span>zip<span class="token punctuation">(</span>grads<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">)</span>

  grad_scale <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_norm<span class="token punctuation">(</span>grads<span class="token punctuation">)</span>
  param_scale <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_norm<span class="token punctuation">(</span>params<span class="token punctuation">)</span>

  <span class="token comment" spellcheck="true"># evaluation</span>
  model_inputs<span class="token punctuation">[</span><span class="token string">'n_graphs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'evaluation'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span>
  eval_pairs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>
  x<span class="token punctuation">,</span> y <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>eval_pairs<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
  similarity <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
  pair_auc <span class="token operator">=</span> auc<span class="token punctuation">(</span>similarity<span class="token punctuation">,</span> placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

  model_inputs<span class="token punctuation">[</span><span class="token string">'n_graphs'</span><span class="token punctuation">]</span> <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'evaluation'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">4</span>
  eval_triplets <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>
  x_1<span class="token punctuation">,</span> y<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>eval_triplets<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
  sim_1 <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_1<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
  sim_2 <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x_2<span class="token punctuation">,</span> z<span class="token punctuation">)</span>
  triplet_acc <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>cast<span class="token punctuation">(</span>sim_1 <span class="token operator">></span> sim_2<span class="token punctuation">,</span> dtype<span class="token operator">=</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
      <span class="token string">'train_step'</span><span class="token punctuation">:</span> train_step<span class="token punctuation">,</span>
      <span class="token string">'metrics'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
          <span class="token string">'training'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
              <span class="token string">'loss'</span><span class="token punctuation">:</span> loss<span class="token punctuation">,</span>
              <span class="token string">'grad_scale'</span><span class="token punctuation">:</span> grad_scale<span class="token punctuation">,</span>
              <span class="token string">'param_scale'</span><span class="token punctuation">:</span> param_scale<span class="token punctuation">,</span>
              <span class="token string">'graph_vec_scale'</span><span class="token punctuation">:</span> graph_vec_scale<span class="token punctuation">,</span>
              <span class="token string">'sim_pos'</span><span class="token punctuation">:</span> sim_pos<span class="token punctuation">,</span>
              <span class="token string">'sim_neg'</span><span class="token punctuation">:</span> sim_neg<span class="token punctuation">,</span>
              <span class="token string">'sim_diff'</span><span class="token punctuation">:</span> sim_pos <span class="token operator">-</span> sim_neg<span class="token punctuation">,</span>
          <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>
          <span class="token string">'validation'</span><span class="token punctuation">:</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
              <span class="token string">'pair_auc'</span><span class="token punctuation">:</span> pair_auc<span class="token punctuation">,</span>
              <span class="token string">'triplet_acc'</span><span class="token punctuation">:</span> triplet_acc<span class="token punctuation">,</span>
          <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>
      <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;,</span>
  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;, placeholders, model</span></code></pre>
<h3 id="The-training-pipeline"><a href="#The-training-pipeline" class="headerlink" title="The training pipeline"></a>The training pipeline</h3><p>For this we need to build the datasets, handle <code>feed_dict</code>s and run some evaluation during training.</p>
<p>Note that this training pipeline is only supposed to be used as an example and you may want to add your own checkpointing or experiment monitoring tools (e.g. tensorboard).</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_datasets</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Build the training and evaluation datasets."""</span>
  config <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>config<span class="token punctuation">)</span>

  <span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'problem'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'graph_edit_distance'</span><span class="token punctuation">:</span>
    dataset_params <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'dataset_params'</span><span class="token punctuation">]</span>
    validation_dataset_size <span class="token operator">=</span> dataset_params<span class="token punctuation">[</span><span class="token string">'validation_dataset_size'</span><span class="token punctuation">]</span>
    <span class="token keyword">del</span> dataset_params<span class="token punctuation">[</span><span class="token string">'validation_dataset_size'</span><span class="token punctuation">]</span>
    training_set <span class="token operator">=</span> GraphEditDistanceDataset<span class="token punctuation">(</span><span class="token operator">**</span>dataset_params<span class="token punctuation">)</span>
    dataset_params<span class="token punctuation">[</span><span class="token string">'dataset_size'</span><span class="token punctuation">]</span> <span class="token operator">=</span> validation_dataset_size
    validation_set <span class="token operator">=</span> FixedGraphEditDistanceDataset<span class="token punctuation">(</span><span class="token operator">**</span>dataset_params<span class="token punctuation">)</span>
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Unknown problem type: %s'</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'problem'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> training_set<span class="token punctuation">,</span> validation_set


<span class="token keyword">def</span> <span class="token function">fill_feed_dict</span><span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Create a feed dict for the given batch of data.

  Args:
    placeholders: a dict of placeholders.
    batch: a batch of data, should be either a single `GraphData` instance for
      triplet training, or a tuple of (graphs, labels) for pairwise training.

  Returns:
    feed_dict: a feed_dict that can be used in a session run call.
  """</span>
  <span class="token keyword">if</span> isinstance<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> GraphData<span class="token punctuation">)</span><span class="token punctuation">:</span>
    graphs <span class="token operator">=</span> batch
    labels <span class="token operator">=</span> None
  <span class="token keyword">else</span><span class="token punctuation">:</span>
    graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> batch

  feed_dict <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
      placeholders<span class="token punctuation">[</span><span class="token string">'node_features'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>node_features<span class="token punctuation">,</span>
      placeholders<span class="token punctuation">[</span><span class="token string">'edge_features'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>edge_features<span class="token punctuation">,</span>
      placeholders<span class="token punctuation">[</span><span class="token string">'from_idx'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>from_idx<span class="token punctuation">,</span>
      placeholders<span class="token punctuation">[</span><span class="token string">'to_idx'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>to_idx<span class="token punctuation">,</span>
      placeholders<span class="token punctuation">[</span><span class="token string">'graph_idx'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> graphs<span class="token punctuation">.</span>graph_idx<span class="token punctuation">,</span>
  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>
  <span class="token keyword">if</span> labels <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>
    feed_dict<span class="token punctuation">[</span>placeholders<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels
  <span class="token keyword">return</span> feed_dict


<span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>sess<span class="token punctuation">,</span> eval_metrics<span class="token punctuation">,</span> placeholders<span class="token punctuation">,</span> validation_set<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Evaluate model performance on the given validation set.

  Args:
    sess: a `tf.Session` instance used to run the computation.
    eval_metrics: a dict containing two tensors 'pair_auc' and 'triplet_acc'.
    placeholders: a placeholder dict.
    validation_set: a `GraphSimilarityDataset` instance, calling `pairs` and
      `triplets` functions with `batch_size` creates iterators over a finite
      sequence of batches to evaluate on.
    batch_size: number of batches to use for each session run call.

  Returns:
    metrics: a dict of metric name => value mapping.
  """</span>
  accumulated_pair_auc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  <span class="token keyword">for</span> batch <span class="token keyword">in</span> validation_set<span class="token punctuation">.</span>pairs<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    feed_dict <span class="token operator">=</span> fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>
    pair_auc <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>eval_metrics<span class="token punctuation">[</span><span class="token string">'pair_auc'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>
    accumulated_pair_auc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pair_auc<span class="token punctuation">)</span>

  accumulated_triplet_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  <span class="token keyword">for</span> batch <span class="token keyword">in</span> validation_set<span class="token punctuation">.</span>triplets<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    feed_dict <span class="token operator">=</span> fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span>
    triplet_acc <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>eval_metrics<span class="token punctuation">[</span><span class="token string">'triplet_acc'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>
    accumulated_triplet_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>triplet_acc<span class="token punctuation">)</span>

  <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
      <span class="token string">'pair_auc'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>accumulated_pair_auc<span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token string">'triplet_acc'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>accumulated_triplet_acc<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span></code></pre>
<h3 id="Let’s-run-it"><a href="#Let’s-run-it" class="headerlink" title="Let’s run it!"></a>Let’s run it!</h3><pre class=" language-python"><code class="language-python">config <span class="token operator">=</span> get_default_config<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Let's just run for a small number of training steps.  This may take you a few</span>
<span class="token comment" spellcheck="true"># minutes.</span>
config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'n_training_steps'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">5000</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Run this if you want to run the code again, otherwise tensorflow would</span>
<span class="token comment" spellcheck="true"># complain that you already created the same graph and the same variables.</span>
tf<span class="token punctuation">.</span>reset_default_graph<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># Set random seeds</span>
seed <span class="token operator">=</span> config<span class="token punctuation">[</span><span class="token string">'seed'</span><span class="token punctuation">]</span>
random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>set_random_seed<span class="token punctuation">(</span>seed <span class="token operator">+</span> <span class="token number">2</span><span class="token punctuation">)</span>

training_set<span class="token punctuation">,</span> validation_set <span class="token operator">=</span> build_datasets<span class="token punctuation">(</span>config<span class="token punctuation">)</span>

<span class="token keyword">if</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'mode'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'pair'</span><span class="token punctuation">:</span>
  training_data_iter <span class="token operator">=</span> training_set<span class="token punctuation">.</span>pairs<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  first_batch_graphs<span class="token punctuation">,</span> _ <span class="token operator">=</span> next<span class="token punctuation">(</span>training_data_iter<span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
  training_data_iter <span class="token operator">=</span> training_set<span class="token punctuation">.</span>triplets<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  first_batch_graphs <span class="token operator">=</span> next<span class="token punctuation">(</span>training_data_iter<span class="token punctuation">)</span>

node_feature_dim <span class="token operator">=</span> first_batch_graphs<span class="token punctuation">.</span>node_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
edge_feature_dim <span class="token operator">=</span> first_batch_graphs<span class="token punctuation">.</span>edge_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>

tensors<span class="token punctuation">,</span> placeholders<span class="token punctuation">,</span> model <span class="token operator">=</span> build_model<span class="token punctuation">(</span>
    config<span class="token punctuation">,</span> node_feature_dim<span class="token punctuation">,</span> edge_feature_dim<span class="token punctuation">)</span>

accumulated_metrics <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>

t_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

init_ops <span class="token operator">=</span> <span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            tf<span class="token punctuation">.</span>local_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># If we already have a session instance, close it and start a new one</span>
<span class="token keyword">if</span> <span class="token string">'sess'</span> <span class="token keyword">in</span> globals<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># We will need to keep this session instance around for e.g. visualization.</span>
<span class="token comment" spellcheck="true"># But you should probably wrap it in a `with tf.Session() sess:` context if you</span>
<span class="token comment" spellcheck="true"># want to use the code elsewhere.</span>
sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_ops<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># use xrange here if you are still on python 2</span>
<span class="token keyword">for</span> i_iter <span class="token keyword">in</span> range<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'n_training_steps'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  batch <span class="token operator">=</span> next<span class="token punctuation">(</span>training_data_iter<span class="token punctuation">)</span>
  _<span class="token punctuation">,</span> train_metrics <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>
      <span class="token punctuation">[</span>tensors<span class="token punctuation">[</span><span class="token string">'train_step'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tensors<span class="token punctuation">[</span><span class="token string">'metrics'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      feed_dict<span class="token operator">=</span>fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">)</span>

  <span class="token comment" spellcheck="true"># accumulate over minibatches to reduce variance in the training metrics</span>
  <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> train_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    accumulated_metrics<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>v<span class="token punctuation">)</span>

  <span class="token keyword">if</span> <span class="token punctuation">(</span>i_iter <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'print_after'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
    metrics_to_print <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>
        k<span class="token punctuation">:</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> accumulated_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>
    info_str <span class="token operator">=</span> <span class="token string">', '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>
        <span class="token punctuation">[</span><span class="token string">'%s %.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> metrics_to_print<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment" spellcheck="true"># reset the metrics</span>
    accumulated_metrics <span class="token operator">=</span> collections<span class="token punctuation">.</span>defaultdict<span class="token punctuation">(</span>list<span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>i_iter <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'print_after'</span><span class="token punctuation">]</span> <span class="token operator">%</span>
        config<span class="token punctuation">[</span><span class="token string">'training'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'eval_after'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      eval_metrics <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>
          sess<span class="token punctuation">,</span> tensors<span class="token punctuation">[</span><span class="token string">'metrics'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'validation'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> placeholders<span class="token punctuation">,</span>
          validation_set<span class="token punctuation">,</span> config<span class="token punctuation">[</span><span class="token string">'evaluation'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
      info_str <span class="token operator">+=</span> <span class="token string">', '</span> <span class="token operator">+</span> <span class="token string">', '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>
          <span class="token punctuation">[</span><span class="token string">'%s %.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token string">'val/'</span> <span class="token operator">+</span> k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> eval_metrics<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'iter %d, %s, time %.2fs'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
        i_iter <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> info_str<span class="token punctuation">,</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> t_start<span class="token punctuation">)</span><span class="token punctuation">)</span>
    t_start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<pre><code>iter 100, loss 0.9024, grad_scale 9.9039, param_scale 24.2281, graph_vec_scale 9.9295, sim_pos -0.5319, sim_neg -0.9309, sim_diff 0.3990, time 16.35s
iter 200, loss 0.8899, grad_scale 10.0000, param_scale 24.2434, graph_vec_scale 15.8820, sim_pos -0.5871, sim_neg -1.1029, sim_diff 0.5158, time 8.78s
iter 300, loss 0.9187, grad_scale 9.9720, param_scale 24.2605, graph_vec_scale 9.2189, sim_pos -0.5186, sim_neg -0.9006, sim_diff 0.3819, time 10.61s
iter 400, loss 0.8426, grad_scale 9.9700, param_scale 24.3224, graph_vec_scale 20.1333, sim_pos -0.5781, sim_neg -1.2868, sim_diff 0.7086, time 9.40s
iter 500, loss 0.8767, grad_scale 9.9918, param_scale 24.3770, graph_vec_scale 16.1800, sim_pos -0.6053, sim_neg -1.1185, sim_diff 0.5132, time 8.59s
iter 600, loss 0.8756, grad_scale 10.0000, param_scale 24.4452, graph_vec_scale 10.7137, sim_pos -0.5587, sim_neg -1.0466, sim_diff 0.4879, time 8.54s
iter 700, loss 0.8455, grad_scale 10.0000, param_scale 24.5081, graph_vec_scale 6.1303, sim_pos -0.6762, sim_neg -1.2543, sim_diff 0.5781, time 9.26s
iter 800, loss 0.8545, grad_scale 10.0000, param_scale 24.5715, graph_vec_scale 7.7584, sim_pos -0.6751, sim_neg -1.2628, sim_diff 0.5877, time 9.35s
iter 900, loss 0.8324, grad_scale 9.9734, param_scale 24.6531, graph_vec_scale 11.4416, sim_pos -0.6053, sim_neg -1.2179, sim_diff 0.6126, time 10.77s
iter 1000, loss 0.8502, grad_scale 10.0000, param_scale 24.7729, graph_vec_scale 21.2052, sim_pos -0.6276, sim_neg -1.1885, sim_diff 0.5610, val/pair_auc 0.6311, val/triplet_acc 0.6560, time 23.40s
iter 1100, loss 0.8568, grad_scale 10.0000, param_scale 24.9137, graph_vec_scale 9.9548, sim_pos -0.6038, sim_neg -1.1830, sim_diff 0.5791, time 9.38s
iter 1200, loss 0.8258, grad_scale 10.0000, param_scale 25.0311, graph_vec_scale 9.8263, sim_pos -0.6863, sim_neg -1.2977, sim_diff 0.6114, time 10.48s
iter 1300, loss 0.8167, grad_scale 10.0000, param_scale 25.1117, graph_vec_scale 7.9998, sim_pos -0.6577, sim_neg -1.2564, sim_diff 0.5987, time 9.64s
iter 1400, loss 0.8393, grad_scale 10.0000, param_scale 25.2091, graph_vec_scale 9.4814, sim_pos -0.6692, sim_neg -1.2338, sim_diff 0.5645, time 9.88s
iter 1500, loss 0.8124, grad_scale 10.0000, param_scale 25.3498, graph_vec_scale 10.8970, sim_pos -0.6629, sim_neg -1.2851, sim_diff 0.6222, time 10.24s
iter 1600, loss 0.7997, grad_scale 10.0000, param_scale 25.5068, graph_vec_scale 8.8850, sim_pos -0.6958, sim_neg -1.3773, sim_diff 0.6816, time 10.23s
iter 1700, loss 0.8036, grad_scale 10.0000, param_scale 25.6802, graph_vec_scale 9.1888, sim_pos -0.7241, sim_neg -1.3902, sim_diff 0.6660, time 10.28s
iter 1800, loss 0.8282, grad_scale 9.9726, param_scale 25.8778, graph_vec_scale 16.0597, sim_pos -0.7033, sim_neg -1.3089, sim_diff 0.6056, time 10.52s
iter 1900, loss 0.8561, grad_scale 9.9528, param_scale 26.1749, graph_vec_scale 16.8173, sim_pos -0.5827, sim_neg -1.1226, sim_diff 0.5399, time 11.16s
iter 2000, loss 0.8543, grad_scale 10.0000, param_scale 26.4489, graph_vec_scale 9.4414, sim_pos -0.6694, sim_neg -1.1820, sim_diff 0.5126, val/pair_auc 0.6423, val/triplet_acc 0.7120, time 15.30s
iter 2100, loss 0.8282, grad_scale 10.0000, param_scale 26.5936, graph_vec_scale 8.2912, sim_pos -0.6784, sim_neg -1.2598, sim_diff 0.5814, time 12.57s
iter 2200, loss 0.8040, grad_scale 10.0000, param_scale 26.8179, graph_vec_scale 8.7340, sim_pos -0.7254, sim_neg -1.3695, sim_diff 0.6441, time 10.05s
iter 2300, loss 0.8089, grad_scale 10.0000, param_scale 27.0014, graph_vec_scale 4.7856, sim_pos -0.7325, sim_neg -1.3514, sim_diff 0.6189, time 10.36s
iter 2400, loss 0.7894, grad_scale 10.0000, param_scale 27.1475, graph_vec_scale 5.3897, sim_pos -0.7178, sim_neg -1.3501, sim_diff 0.6323, time 10.36s
iter 2500, loss 0.8112, grad_scale 10.0000, param_scale 27.3124, graph_vec_scale 5.0839, sim_pos -0.7920, sim_neg -1.4146, sim_diff 0.6226, time 10.70s
iter 2600, loss 0.7852, grad_scale 10.0000, param_scale 27.5082, graph_vec_scale 3.7201, sim_pos -0.7722, sim_neg -1.5174, sim_diff 0.7452, time 10.81s
iter 2700, loss 0.7873, grad_scale 10.0000, param_scale 27.6644, graph_vec_scale 3.7121, sim_pos -0.7612, sim_neg -1.4150, sim_diff 0.6538, time 10.88s
iter 2800, loss 0.7846, grad_scale 10.0000, param_scale 27.8754, graph_vec_scale 4.0826, sim_pos -0.7242, sim_neg -1.3944, sim_diff 0.6703, time 9.64s
iter 2900, loss 0.7984, grad_scale 10.0000, param_scale 28.0754, graph_vec_scale 3.3628, sim_pos -0.7275, sim_neg -1.3811, sim_diff 0.6536, time 10.04s
iter 3000, loss 0.8040, grad_scale 10.0000, param_scale 28.2285, graph_vec_scale 4.7665, sim_pos -0.8204, sim_neg -1.4319, sim_diff 0.6115, val/pair_auc 0.6521, val/triplet_acc 0.7020, time 14.91s
iter 3100, loss 0.7661, grad_scale 10.0000, param_scale 28.4321, graph_vec_scale 4.5367, sim_pos -0.7861, sim_neg -1.5052, sim_diff 0.7192, time 12.70s
iter 3200, loss 0.7918, grad_scale 10.0000, param_scale 28.6223, graph_vec_scale 2.7951, sim_pos -0.7894, sim_neg -1.4368, sim_diff 0.6474, time 10.14s
iter 3300, loss 0.7888, grad_scale 10.0000, param_scale 28.7832, graph_vec_scale 2.5365, sim_pos -0.7737, sim_neg -1.4076, sim_diff 0.6339, time 11.14s
iter 3400, loss 0.7880, grad_scale 10.0000, param_scale 28.9723, graph_vec_scale 2.5840, sim_pos -0.8405, sim_neg -1.4963, sim_diff 0.6558, time 10.99s
iter 3500, loss 0.8063, grad_scale 10.0000, param_scale 29.1109, graph_vec_scale 1.5241, sim_pos -0.7049, sim_neg -1.3258, sim_diff 0.6209, time 10.09s
iter 3600, loss 0.7781, grad_scale 10.0000, param_scale 29.2500, graph_vec_scale 1.6339, sim_pos -0.8011, sim_neg -1.5460, sim_diff 0.7448, time 10.25s
iter 3700, loss 0.7626, grad_scale 10.0000, param_scale 29.3812, graph_vec_scale 2.0334, sim_pos -0.7765, sim_neg -1.5622, sim_diff 0.7857, time 11.35s
iter 3800, loss 0.7545, grad_scale 10.0000, param_scale 29.5007, graph_vec_scale 1.9816, sim_pos -0.7494, sim_neg -1.5253, sim_diff 0.7759, time 10.50s
iter 3900, loss 0.7786, grad_scale 10.0000, param_scale 29.6472, graph_vec_scale 2.2622, sim_pos -0.8190, sim_neg -1.5184, sim_diff 0.6994, time 10.94s
iter 4000, loss 0.7696, grad_scale 10.0000, param_scale 29.7945, graph_vec_scale 1.9066, sim_pos -0.7080, sim_neg -1.4729, sim_diff 0.7649, val/pair_auc 0.6588, val/triplet_acc 0.7110, time 15.44s
iter 4100, loss 0.7702, grad_scale 10.0000, param_scale 29.9186, graph_vec_scale 1.6492, sim_pos -0.7923, sim_neg -1.5920, sim_diff 0.7998, time 11.56s
iter 4200, loss 0.7618, grad_scale 10.0000, param_scale 30.0597, graph_vec_scale 1.3295, sim_pos -0.8183, sim_neg -1.5480, sim_diff 0.7297, time 12.56s
iter 4300, loss 0.7595, grad_scale 10.0000, param_scale 30.2331, graph_vec_scale 2.0479, sim_pos -0.8513, sim_neg -1.5582, sim_diff 0.7069, time 9.82s
iter 4400, loss 0.7722, grad_scale 10.0000, param_scale 30.3986, graph_vec_scale 1.1744, sim_pos -0.7996, sim_neg -1.4669, sim_diff 0.6674, time 10.90s
iter 4500, loss 0.7850, grad_scale 10.0000, param_scale 30.5059, graph_vec_scale 1.7279, sim_pos -0.8477, sim_neg -1.5368, sim_diff 0.6891, time 11.18s
iter 4600, loss 0.7562, grad_scale 10.0000, param_scale 30.6486, graph_vec_scale 1.4266, sim_pos -0.7782, sim_neg -1.5346, sim_diff 0.7564, time 10.92s
iter 4700, loss 0.7843, grad_scale 10.0000, param_scale 30.8270, graph_vec_scale 2.1109, sim_pos -0.7923, sim_neg -1.4582, sim_diff 0.6660, time 11.00s
iter 4800, loss 0.7712, grad_scale 10.0000, param_scale 30.9745, graph_vec_scale 1.9060, sim_pos -0.8056, sim_neg -1.4885, sim_diff 0.6830, time 11.01s
iter 4900, loss 0.7894, grad_scale 10.0000, param_scale 31.1943, graph_vec_scale 1.5744, sim_pos -0.7436, sim_neg -1.3567, sim_diff 0.6131, time 10.39s
iter 5000, loss 0.7866, grad_scale 10.0000, param_scale 31.4067, graph_vec_scale 1.4950, sim_pos -0.7812, sim_neg -1.4002, sim_diff 0.6190, val/pair_auc 0.6675, val/triplet_acc 0.7490, time 15.01s</code></pre>
<p>Note that albeit a bit noisy, the loss is going down, the similarity gap<br>between positive and negative pairs are growing and the evaluation results, i.e. pair AUC and triplet accuracies are going up as well.  Overall training seems to be working!</p>
<p>You can train this much longer.  We observed improvement in performance even after training for 500,000 steps, but didn’t push this much further as it is a synthetic task after all.</p>
<h2 id="Test-the-model-and-create-some-visualizations"><a href="#Test-the-model-and-create-some-visualizations" class="headerlink" title="Test the model and create some visualizations"></a>Test the model and create some visualizations</h2><p>Once the model is trained, we can test in on unseen data.  Our graph matching networks use cross-graph matching-based attention to compute graph similarity, we can visualize these attention weights to see where the model is attending to.</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># visualize on graphs of 10 nodes, bigger graphs become more difficult to</span>
<span class="token comment" spellcheck="true"># visualize</span>
vis_dataset <span class="token operator">=</span> GraphEditDistanceDataset<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> permute<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

pair_iter <span class="token operator">=</span> vis_dataset<span class="token punctuation">.</span>pairs<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> next<span class="token punctuation">(</span>pair_iter<span class="token punctuation">)</span></code></pre>
<p>Let’s split the batched graphs into individual graphs and visualize them first.</p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">split_graphs</span><span class="token punctuation">(</span>graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Split a batch of graphs into individual `nx.Graph` instances."""</span>
  g <span class="token operator">=</span> <span class="token punctuation">[</span>nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>n_graphs<span class="token punctuation">)</span><span class="token punctuation">]</span>
  node_ids <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>graph_idx<span class="token punctuation">.</span>size<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>
  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>n_graphs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    nodes_in_graph <span class="token operator">=</span> node_ids<span class="token punctuation">[</span>graphs<span class="token punctuation">.</span>graph_idx <span class="token operator">==</span> i<span class="token punctuation">]</span>
    n_nodes <span class="token operator">=</span> len<span class="token punctuation">(</span>nodes_in_graph<span class="token punctuation">)</span>
    g<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n_nodes<span class="token punctuation">)</span><span class="token punctuation">)</span>
    node_id_min <span class="token operator">=</span> nodes_in_graph<span class="token punctuation">.</span>min<span class="token punctuation">(</span><span class="token punctuation">)</span>
    node_id_max <span class="token operator">=</span> nodes_in_graph<span class="token punctuation">.</span>max<span class="token punctuation">(</span><span class="token punctuation">)</span>

    edges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> u<span class="token punctuation">,</span> v <span class="token keyword">in</span> zip<span class="token punctuation">(</span>graphs<span class="token punctuation">.</span>from_idx<span class="token punctuation">,</span> graphs<span class="token punctuation">.</span>to_idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">if</span> node_id_min <span class="token operator">&lt;=</span> u <span class="token operator">&lt;=</span> node_id_max <span class="token operator">and</span> node_id_min <span class="token operator">&lt;=</span> v <span class="token operator">&lt;=</span> node_id_max<span class="token punctuation">:</span>
        edges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>u <span class="token operator">-</span> node_id_min<span class="token punctuation">,</span> v <span class="token operator">-</span> node_id_min<span class="token punctuation">)</span><span class="token punctuation">)</span>
    g<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>edges<span class="token punctuation">)</span>

  <span class="token keyword">return</span> g</code></pre>
<pre class=" language-python"><code class="language-python">nx_graphs <span class="token operator">=</span> split_graphs<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>nx_graphs<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  label <span class="token operator">=</span> labels<span class="token punctuation">[</span>i <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">]</span>
  g1 <span class="token operator">=</span> nx_graphs<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
  g2 <span class="token operator">=</span> nx_graphs<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
  plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">121</span><span class="token punctuation">)</span>
  <span class="token comment" spellcheck="true"># Compute the positions of graphs first to make sure the visualizations are</span>
  <span class="token comment" spellcheck="true"># consistent.</span>
  pos <span class="token operator">=</span> nx<span class="token punctuation">.</span>drawing<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>g1<span class="token punctuation">)</span>
  nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>g1<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
  ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Graph 1'</span><span class="token punctuation">)</span>
  ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
  ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">122</span><span class="token punctuation">)</span>
  nx<span class="token punctuation">.</span>draw_networkx<span class="token punctuation">(</span>g2<span class="token punctuation">,</span> pos<span class="token operator">=</span>pos<span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
  ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Graph 2'</span><span class="token punctuation">)</span>
  ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span></code></pre>
<p><img src="output_55_0.png" alt="png"></p>
<p><img src="output_55_1.png" alt="png"></p>
<p>Build the computation graph for visualization.</p>
<pre class=" language-python"><code class="language-python">n_graphs <span class="token operator">=</span> graphs<span class="token punctuation">.</span>n_graphs

model_inputs <span class="token operator">=</span> placeholders<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">del</span> model_inputs<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
graph_vectors <span class="token operator">=</span> model<span class="token punctuation">(</span>n_graphs<span class="token operator">=</span>n_graphs<span class="token punctuation">,</span> <span class="token operator">**</span>model_inputs<span class="token punctuation">)</span>
x<span class="token punctuation">,</span> y <span class="token operator">=</span> reshape_and_split_tensor<span class="token punctuation">(</span>graph_vectors<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
similarity <span class="token operator">=</span> compute_similarity<span class="token punctuation">(</span>config<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

layer_outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>get_layer_outputs<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_matchings</span><span class="token punctuation">(</span>layer_outputs<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span> sim<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Build the matching attention matrices from layer outputs."""</span>
  <span class="token keyword">assert</span> n_graphs <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span>
  attention <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  <span class="token keyword">for</span> h <span class="token keyword">in</span> layer_outputs<span class="token punctuation">:</span>
    partitions <span class="token operator">=</span> tf<span class="token punctuation">.</span>dynamic_partition<span class="token punctuation">(</span>h<span class="token punctuation">,</span> graph_idx<span class="token punctuation">,</span> n_graphs<span class="token punctuation">)</span>
    attention_in_layer <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
      x <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
      y <span class="token operator">=</span> partitions<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>
      a <span class="token operator">=</span> sim<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
      a_x <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># i->j</span>
      a_y <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>a<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># j->i</span>
      attention_in_layer<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>a_x<span class="token punctuation">,</span> a_y<span class="token punctuation">)</span><span class="token punctuation">)</span>
    attention<span class="token punctuation">.</span>append<span class="token punctuation">(</span>attention_in_layer<span class="token punctuation">)</span>
  <span class="token keyword">return</span> attention</code></pre>
<pre class=" language-python"><code class="language-python">attentions <span class="token operator">=</span> build_matchings<span class="token punctuation">(</span>
    layer_outputs<span class="token punctuation">,</span> placeholders<span class="token punctuation">[</span><span class="token string">'graph_idx'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n_graphs<span class="token punctuation">,</span>
    get_pairwise_similarity<span class="token punctuation">(</span>config<span class="token punctuation">[</span><span class="token string">'graph_matching_net'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'similarity'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python">sim<span class="token punctuation">,</span> a <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>similarity<span class="token punctuation">,</span> attentions<span class="token punctuation">]</span><span class="token punctuation">,</span>
                  feed_dict<span class="token operator">=</span>fill_feed_dict<span class="token punctuation">(</span>placeholders<span class="token punctuation">,</span> <span class="token punctuation">(</span>graphs<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre>
<pre class=" language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sim<span class="token punctuation">)</span></code></pre>
<pre><code>[ 1 -1]
[-0.19060427 -2.23995686]</code></pre>
<p>Similarity for positive pair is much higher than the similarity for the negative pair.</p>
<p>Remember that with a margin loss and Euclidean distance, which is how this model is trained, the similarity value is the negative distance.  In this case the distance for positive pair is quite small, while the distance between two graphs in the negative pair is large.</p>
<h3 id="Some-tools-for-visualizing-attention"><a href="#Some-tools-for-visualizing-attention" class="headerlink" title="Some tools for visualizing attention"></a>Some tools for visualizing attention</h3><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">_plot_graph_matching_on_axis</span><span class="token punctuation">(</span>ax<span class="token punctuation">,</span> g_base<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> att<span class="token punctuation">,</span> title<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Plot graph matching on an axis."""</span>
  original_edges <span class="token operator">=</span> g_base<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span>
  g <span class="token operator">=</span> g_base<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
  n1<span class="token punctuation">,</span> n2 <span class="token operator">=</span> att<span class="token punctuation">.</span>shape
  alpha <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  att_edges <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n1<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>n2<span class="token punctuation">)</span><span class="token punctuation">:</span>
      g<span class="token punctuation">.</span>add_edge<span class="token punctuation">(</span>i<span class="token punctuation">,</span> j <span class="token operator">+</span> n1<span class="token punctuation">)</span>
      att_edges<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> j <span class="token operator">+</span> n1<span class="token punctuation">)</span><span class="token punctuation">)</span>
      alpha<span class="token punctuation">.</span>append<span class="token punctuation">(</span>att<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>

  nx<span class="token punctuation">.</span>draw_networkx_nodes<span class="token punctuation">(</span>
      g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> nodelist<span class="token operator">=</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">)</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'lavender'</span><span class="token punctuation">,</span> linewidths<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
  nx<span class="token punctuation">.</span>draw_networkx_nodes<span class="token punctuation">(</span>
      g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> nodelist<span class="token operator">=</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">,</span> n1 <span class="token operator">+</span> n2<span class="token punctuation">)</span><span class="token punctuation">,</span> node_color<span class="token operator">=</span><span class="token string">'wheat'</span><span class="token punctuation">,</span> linewidths<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
      ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
  nx<span class="token punctuation">.</span>draw_networkx_edges<span class="token punctuation">(</span>
      g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> edgelist<span class="token operator">=</span>original_edges<span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>
  <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>att_edges<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    nx<span class="token punctuation">.</span>draw_networkx_edges<span class="token punctuation">(</span>
        g<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> edgelist<span class="token operator">=</span>att_edges<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> edge_color<span class="token operator">=</span><span class="token string">'g'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span>alpha<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>
        ax<span class="token operator">=</span>ax<span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
  ax<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
  <span class="token keyword">if</span> title<span class="token punctuation">:</span>
    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>title<span class="token punctuation">)</span>

  <span class="token comment" spellcheck="true"># set xlim and ylim</span>
  coords <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>list<span class="token punctuation">(</span>pos<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
  x_min<span class="token punctuation">,</span> y_min <span class="token operator">=</span> coords<span class="token punctuation">.</span>min<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
  x_max<span class="token punctuation">,</span> y_max <span class="token operator">=</span> coords<span class="token punctuation">.</span>max<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
  x_len <span class="token operator">=</span> x_max <span class="token operator">-</span> x_min
  y_len <span class="token operator">=</span> y_max <span class="token operator">-</span> y_min
  ax<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span><span class="token punctuation">[</span>x_min <span class="token operator">-</span> x_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">,</span> x_max <span class="token operator">+</span> x_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
  ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token punctuation">[</span>y_min <span class="token operator">-</span> y_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">,</span> y_max <span class="token operator">+</span> y_len <span class="token operator">*</span> <span class="token number">0.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">plot_graph_matching_pair</span><span class="token punctuation">(</span>g1<span class="token punctuation">,</span> g2<span class="token punctuation">,</span> matchings<span class="token punctuation">,</span> pos<span class="token operator">=</span>None<span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">"""Plot a pair of graphs and the matchings between them.

  Args:
    g1: a networkx graph.
    g2: a networkx graph.
    matchings: a pair of n1 x n2 matrices.
    pos: a position dictionary, if provided.

  Returns:
    pos: position dictionary, used for other plots between these two graphs.
  """</span>
  n1 <span class="token operator">=</span> g1<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>
  n2 <span class="token operator">=</span> g2<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">assert</span> n1 <span class="token operator">>=</span> n2

  <span class="token keyword">if</span> pos <span class="token keyword">is</span> None<span class="token punctuation">:</span>
    <span class="token keyword">with</span> reset_random_state<span class="token punctuation">(</span>seed<span class="token operator">=</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
      pos1 <span class="token operator">=</span> nx<span class="token punctuation">.</span>spring_layout<span class="token punctuation">(</span>g1<span class="token punctuation">)</span>
    pos1_values <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>list<span class="token punctuation">(</span>pos1<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
    pos1_values <span class="token operator">-=</span> pos1_values<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    pos2_values <span class="token operator">=</span> pos1_values<span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
        pos1_values<span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>max<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">-</span>
        pos1_values<span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>min<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    pos <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;k: pos1_values[k] for k in pos1.keys()&amp;#125;</span>
    pos<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;(k + n2): pos2_values[k-(n1-n2)]</span>
                <span class="token keyword">for</span> k <span class="token keyword">in</span> list<span class="token punctuation">(</span>pos1<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span>n1<span class="token operator">-</span>n2<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;)</span>

  g_base <span class="token operator">=</span> nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
  g_base<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">)</span><span class="token punctuation">)</span>
  g_base<span class="token punctuation">.</span>add_nodes_from<span class="token punctuation">(</span>range<span class="token punctuation">(</span>n1<span class="token punctuation">,</span> n1 <span class="token operator">+</span> n2<span class="token punctuation">)</span><span class="token punctuation">)</span>
  g_base<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span>g1<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  g_base<span class="token punctuation">.</span>add_edges_from<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>i <span class="token operator">+</span> n1<span class="token punctuation">,</span> j <span class="token operator">+</span> n1<span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> j <span class="token keyword">in</span> g2<span class="token punctuation">.</span>edges<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

  fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">11.2</span><span class="token punctuation">,</span> <span class="token number">4.8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
  _plot_graph_matching_on_axis<span class="token punctuation">(</span>
      ax<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> g_base<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> matchings<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'left attend to right'</span><span class="token punctuation">)</span>
  _plot_graph_matching_on_axis<span class="token punctuation">(</span>
      ax<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> g_base<span class="token punctuation">,</span> pos<span class="token punctuation">,</span> matchings<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> title<span class="token operator">=</span><span class="token string">'right attend to left'</span><span class="token punctuation">)</span>
  fig<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span>pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> h_pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> w_pad<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token keyword">return</span> pos</code></pre>
<h3 id="Visualize-how-the-attention-pattern-changes-across-layers"><a href="#Visualize-how-the-attention-pattern-changes-across-layers" class="headerlink" title="Visualize how the attention pattern changes across layers"></a>Visualize how the attention pattern changes across layers</h3><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># visualize the attention across layers for the positive pair</span>
plt<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token string">'all'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  _ <span class="token operator">=</span> plot_graph_matching_pair<span class="token punctuation">(</span>nx_graphs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nx_graphs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p><img src="output_66_0.png" alt="png"></p>
<p><img src="output_66_1.png" alt="png"></p>
<p><img src="output_66_2.png" alt="png"></p>
<p><img src="output_66_3.png" alt="png"></p>
<p><img src="output_66_4.png" alt="png"></p>
<p><img src="output_66_5.png" alt="png"></p>
<p>Note that the left-to-right and right-to-left attention patterns are slightly different.  Also the attention pattern starts almost uniform, and then gets more concentrated after a few layers.</p>
<p>If we train the model for longer, we can see a clearer matching pattern.</p>
<pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># negative pair</span>
plt<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token string">'all'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
  _ <span class="token operator">=</span> plot_graph_matching_pair<span class="token punctuation">(</span>nx_graphs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nx_graphs<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span></code></pre>
<p><img src="output_68_0.png" alt="png"></p>
<p><img src="output_68_1.png" alt="png"></p>
<p><img src="output_68_2.png" alt="png"></p>
<p><img src="output_68_3.png" alt="png"></p>
<p><img src="output_68_4.png" alt="png"></p>
<p><img src="output_68_5.png" alt="png"></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">国祥</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zgx43790.github.io/2021/01/16/gmn-code/">https://zgx43790.github.io/2021/01/16/gmn-code/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">国祥</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">机器学习</span>
                                </a>
                            
                                <a href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/">
                                    <span class="chip bg-color">图模型</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">论文学习</span>
                                </a>
                            
                                <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                                    <span class="chip bg-color">图神经网络</span>
                                </a>
                            
                                <a href="/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">
                                    <span class="chip bg-color">论文复现</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.jpg" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2021/01/16/gmn-code/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/17.jpg" class="responsive-img" alt="GMN-complement-tensorflow">
                        
                        <span class="card-title">GMN-complement-tensorflow</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GMN-complement-tensorflow
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-01-16
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%9B%BE%E6%A8%A1%E5%9E%8B/" class="post-category">
                                    图模型
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/">
                        <span class="chip bg-color">图模型</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">论文学习</span>
                    </a>
                    
                    <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                        <span class="chip bg-color">图神经网络</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">
                        <span class="chip bg-color">论文复现</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/01/15/gmn/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/16.jpg" class="responsive-img" alt="GMN">
                        
                        <span class="card-title">GMN</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            GMN
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-01-15
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%9B%BE%E6%A8%A1%E5%9E%8B/" class="post-category">
                                    图模型
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">机器学习</span>
                    </a>
                    
                    <a href="/tags/%E5%9B%BE%E6%A8%A1%E5%9E%8B/">
                        <span class="chip bg-color">图模型</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">论文学习</span>
                    </a>
                    
                    <a href="/tags/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">
                        <span class="chip bg-color">图神经网络</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%BA%E6%96%87%E5%A4%8D%E7%8E%B0/">
                        <span class="chip bg-color">论文复现</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: Singularity&#39;s Blog<br />'
            + '文章作者: 国祥<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='true'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.06'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            &copy;2020-2023 GuoXiang. 版权所有


            <span id="year">2020</span>
            <a href="/about" target="_blank">国祥</a>
            
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2020";
                    var startMonth = "08";
                    var startDate = "21";
                    var startHour = "18";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffDays + " 天 " + diffHours +
                            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "本站已安全运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="ZGX43790" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:imsingularity@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=437904687" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 437904687" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>

</html>
